[{"username":"aspinuso","workflowId":"173","_id":"MISFIT_VERCE_orfeus-as-90123-b86d5f73-7f97-11e8-aa71-f45c89acf865","description":"test","modules":["apispec==0.31.0","appinst==2.1.2","appnope==0.1.0","apptools==4.2.0","argh==0.26.2","autopep8==1.2","avro==1.8.1","b2handle==1.1.1","babel==2.4.0","backports-abc==0.4","backports.ssl-match-hostname==3.5.0.1","basemap==1.0.7","blinker==1.4","cachecontrol==0.11.7","casuarius==1.1","certifi==2015.11.20.1","cffi==1.8.3","chaco==4.4.1","ckanapi==4.0","click==6.7","cloud==2.4.6","configargparse==0.10.0","configobj==4.7.2","construct==2.5.3","cryptography==1.3.4","cwlref-runner==1.0","cwltool==1.0.20170510165748","cython==0.23.4","datetime==4.2","decorator==4.0.4","dispel4py==0.0.1","distribute==0.6.49","docopt==0.6.2","dublincore==1.0","enable==4.3.0","enaml==0.6.8","encore==0.4.0","enum34==1.1.6","envisage==4.4.0","etsproxy==0.1.2","examples==7.3","flake8==2.3.0","flask-apispec==0.4.2","flask-cors==3.0.6","flask==0.12.1","freetype==2.4.4","functools32==3.2.3.post2","future==0.14.3","gevent==1.1.2","globusonline-transfer-api-client==0.10.18","gnureadline==6.3.3","greenlet==0.4.10","grequests==0.3.0","gunicorn==19.7.1","h2==2.4.1","h5py==2.5.0","hpack==2.3.0","html2text==2016.4.2","hyperframe==3.2.0","idle==2.7.3","idna==2.1","ipaddress==1.0.17","ipykernel==4.2.1","ipython-genutils==0.1.0","ipython==4.0.1","ipywidgets==4.1.1","isodate==0.5.4","itsdangerous==0.24","jinja2==2.9.6","jsonpatch==1.16","jsonpointer==1.10","jsonschema==2.5.1","jupyter-client==4.1.1","jupyter-console==4.0.3","jupyter-core==4.0.6","jupyter==1.0.0","kernmagic==0.2.0","libjpeg==7.0","libpng==1.2.40","lockfile==0.12.2","lxml==3.6.4","m2crypto==0.25.1","markupsafe==1.0","marshmallow==2.15.0","matplotlib==1.4.3","mccabe==0.3","mistune==0.7.4","mitmproxy==0.17","mpi4py==1.3.1","nbconvert==4.1.0","nbformat==4.0.1","netcdf4==1.2.2","networkx==1.11","nose==1.3.6","notebook==4.0.6","noworkflow==0.6.0","numpy==1.9.2","obspy==0.10.1","panda==0.3.1","pandas==0.17.1","passlib==1.6.5","path.py==8.1.2","pathtools==0.1.2","pep8==1.6.2","pexpect==4.0.1","pickleshare==0.5","pillow==3.2.0","pip==10.0.1","ply==3.4","ptyprocess==0.5","py==1.4.26","pyasn1==0.1.9","pycparser==2.14","pydotplus==2.0.2","pyface==4.4.0","pyflakes==0.8.1","pyflex==0.1.3","pyglet==1.1.4","pygments==1.6","pyinstaller==3.2.1","pymongo==3.4.0","pympler==0.4.2","pyopenssl==16.1.0","pyparsing==2.1.9","pyperclip==1.5.27","pytest==2.6.4","python-dateutil==2.4.2","python-levenshtein==0.12.0","pythondoc==2.7.3","pytz==2015.2","pyyaml==3.12","pyzmq==15.1.0","qtconsole==4.1.1","rdflib-jsonld==0.4.0","rdflib==4.2.2","readline==6.2.1","requests-futures==0.9.7","requests==2.9.2","ruamel.ordereddict==0.4.9","ruamel.yaml==0.14.11","schema-salad==2.5.20170428142041","scipy==0.15.1","scriptcwl==0.3.1","seaborn==0.7.1","setuptools==25.1.4","shellescape==3.4.1","sickle==0.6.1","simplegeneric==0.8.1","simplejson==3.11.1","singledispatch==3.4.0.3","six==1.10.0","sqlalchemy==0.9.9","suds==0.4","sympy==0.7.3","terminado==0.5","tornado==4.3","traitlets==4.0.0","traits==4.4.0","traitsui==4.4.0","twisted==16.2.0","txmongo==16.1.0","typing==3.5.3.0","ujson==1.35","urwid==1.3.1","watchdog==0.8.3","webargs==2.0.0","werkzeug==0.12.1","wheel==0.31.1","wxpython==2.9.2.4","xarray==0.7.1","zope.interface==4.0.5"],"mapping":"simple","source":{"WindowTaperingPE4":{"code":"    def __computewrapper(self, inputs):\n\n        try:\n            result = None\n\n            self.__markIteration()\n\n            if self.impcls is not None and isinstance(self, self.impcls):\n                try:\n                    if hasattr(self, 'params'):\n                        self.parameters = self.params\n                    result = self._process(inputs[self.impcls.INPUT_NAME])\n                    if result is not None:\n                        self.writeResults(self.impcls.OUTPUT_NAME, result)\n                except:\n                    result = self._process(inputs)\n            else:\n                result = self._process(inputs)\n\n            if result is not None:\n                return result\n\n        except Exception:\n            self.log(\" Compute Error: %s\" % traceback.format_exc())\n            self.error += \" Compute Error: %s\" % traceback.format_exc()\n            # self.endTime = datetime.datetime.utcnow()\n            self.writeResults('error', {'error': 'null'})\n\n    def __getUniqueId(self):\n        return socket.gethostname() + \"-\" + str(os.getpid()) + \\\n            \"-\" + str(uuid.uuid1())\n\n    def __importInputMetadata(self):\n        try:\n            self.inMetaStreams = self.input[\"metadata\"][\"streams\"]\n        except Exception:\n            None\n\n    def __markIteration(self):\n        self.startTime = datetime.datetime.utcnow()\n        self.iterationId = self.name + '-' + self.makeProcessId()\n\n    def __processwrapper(self, data):\n        try:\n\n            self.initParameters()\n\n            self.inputs = self.importInputData(data)\n            # self.__importInputMetadata()\n            return self.__computewrapper(self.inputs)\n\n        except:\n            self.log(traceback.format_exc())\n\n    def __init__(self,*args,**kwargs):\n        ProvenancePE.__init__(self,*args,**kwargs)\n        self.addNamespacePrefix(\"seis\",\"http:\/\/seis-prov.eu\/ns\/#\")\n\n    def _add_input(self, name, grouping=None, tuple_type=None):\n        '''\n        Declares an input for this PE.\n        This method may be used when initialising a PE instead of modifying\n        :py:attr:`~dispel4py.core.GenericPE.inputconnections` directly.\n\n        :param name: name of the input\n        :param grouping: the grouping type that this input expects (optional)\n        :param tuple_type: type of tuples accepted by this input (optional)\n        '''\n        self.inputconnections[name] = {NAME: name}\n        if grouping:\n            self.inputconnections[name][GROUPING] = grouping\n        if tuple_type:\n            self.inputconnections[name][TYPE] = tuple_type\n\n    def _add_output(self, name, tuple_type=None):\n        '''\n        Declares an output for this PE.\n        This method may be used when initialising a PE instead of modifying\n        :py:attr:`~dispel4py.core.GenericPE.outputconnections` directly.\n\n        :param name: name of the output\n        :param tuple_type: type of tuples produced by this output (optional)\n        '''\n        self.outputconnections[name] = {NAME: name}\n        if tuple_type:\n            self.outputconnections[name][TYPE] = tuple_type\n\n    def _postprocess(self):\n        None\n\n    def _preprocess(self):\n        self.instanceId = self.name + \"-Instance-\" + \\\n            \"-\" + self.makeProcessId()\n\n        super(ProvenancePE, self)._preprocess()\n\n    def _process(self, inputs):\n        ip = inputs[\"input\"]\n\n        data = ip[\"data_trace\"]\n        synthetic = ip[\"synthetic_trace\"]\n\n        c_data = data.copy()\n        c_synthetic = synthetic.copy()\n        c_data.data[:] = 0.0\n        c_synthetic.data[:] = 0.0\n\n        # Taper around each window.\n        for tr in (ip[\"data_trace\"], ip[\"synthetic_trace\"]):\n            c_tr = tr.copy()\n            c_tr.data[:] = 0.0\n            for window in ip[\"windows\"]:\n                tr2 = tr.copy()\n                tr2.trim(window[\"starttime\"], window[\"endtime\"])\n                tr2.taper(max_percentage=0.05, type=\"hann\")\n                tr2.trim(c_tr.stats.starttime, c_tr.stats.endtime,\n                         fill_value=0.0, pad=True)\n                c_tr.data += tr2.data\n            tr.data = c_tr.data\n\n        self.write(\"output\", ip)\n\n    def _updateState(self,name,id):\n        if name in self.stateCollection:\n                self.stateCollectionId.remove(self.stateCollection[name])\n        self.stateCollection[name]=id\n        self.stateCollectionId.append(id)\n\n    def _write(self, name, data, **kwargs):\n        '''\n        This writes the 'data' to the output pipe with name 'name' of this PE.\n        '''\n         \n        try:\n            output = self.outputconnections[name]\n            output[WRITER].write(data)\n        except KeyError:\n            raise Exception(\"Can't write data: Unknown output connection\\\n                            '%s' for PE '%s'\" % (name, type(self).__name__))\n\n    def addNamespacePrefix(self,prefix,url):\n        self.ns.update({prefix:url})\n\n    def apply_derivation_rule(self,event,voidInvocation,oport=None,iport=None,data=None,metadata=None):\n        \n        if (event=='end_invocation_event') and voidInvocation==True:\n            self.discardInFlow(discardState=True)\n        \n        if (event=='end_invocation_event') and voidInvocation==False:\n            self.discardInFlow(discardState=True)\n\n    def buildDerivation(self, data, port=\"\"):\n        \n        if data!=None and 'id' in data:\n\n            derivation = {'port': port, \n                          'DerivedFromDatasetID': data['id'], \n                          'TriggeredByProcessIterationID': data['TriggeredByProcessIterationID'], \n                          'prov_cluster': data['prov_cluster'],\n                          'iterationIndex':self.iterationIndex,\n                          \n\n\n\n                          }\n                          \n            if port==\"_d4p_state\": \n                derivation.update({'lookupterm':data['lookupterm']})\n                 \n\t\t    \n            if \"up:assertionType\" in data:\n                derivation.update({\"up:assertionType\":data[\"up:assertionType\"]})\n\n\n\n            self.derivationIds.append(derivation)\n\n        else:\n            \n            id=self.extractDataSourceId(data,port)\n            #traceback.print_exc(file=sys.stderr)\n            derivation = {'port': port, 'DerivedFromDatasetID':\n                          id, 'TriggeredByProcessIterationID':\n                          None, 'prov_cluster':\n                          None,\n                          'iterationIndex':self.iterationIndex\n                          }\n            self.derivationIds.append(derivation)\n            self.log(\"BUILDING INITIAL DERIVATION\")\n\n    def buildUserMetadata(self, data, **kwargs):\n        streamlist = list()\n\n        streamItem = {}\n        streammeta = []\n        settransfer=False\n        streammeta = self.extractItemMetadata(data,kwargs['output_port'])\n        \n        if not isinstance(streammeta, list):\n            streammeta = kwargs['metadata'] if isinstance(\n                kwargs['metadata'], list) else [kwargs['metadata']]\n        elif isinstance(streammeta, list):\n            try:\n                if isinstance(kwargs['metadata'], list):\n                    streammeta = streammeta + kwargs['metadata']\n                if isinstance(kwargs['metadata'], dict):\n                    for y in streammeta:\n                        y.update(kwargs['metadata'])\n            except:\n                traceback.print_exc(file=sys.stderr)\n                None\n        \n        if self.sel_rules!=None:\n            self.provon=self.checkSelectiveRule(streammeta)\n\n       \n        if not self.provon:\n            return streamItem\n        #self.log(kwargs)\n        streamItem.update({\"content\": streammeta,\n                           \"id\": self.getUniqueId(data,kwargs['output_port'],**kwargs),\n                           \"format\": \"\",\n                           \"location\": \"\",\n                           \"annotations\": [],\n                           \"port\": kwargs['output_port']})\n        # if (self.streamItemsControl!={,:\n        streamItem.update(kwargs['control'])\n        # if (self.streamItemsLocations!={,:\n        streamItem.update({\"location\": kwargs['location'],\n                          \"format\": kwargs['format']})\n        streamItem.update({\"size\": total_size(data)})\n        #streamItem.update({\"size\": 0})\n\n        if self.transfer_rules!=None:\n            settransfer=self.checkTransferRule(streammeta)\n\n\n        if settransfer:\n            streamItem[\"s-prov:immediateAccess\"]=True\n            streamItem[\"s-prov:first-known-destination\"]=self.transfer_rules[\"destination\"]\n\n        \n        \n        streamlist.append(streamItem)\n        return streamlist\n\n    def checkSelectiveRule(self,streammeta):\n        self.log(\"Checking Skip-Rules: \"+str(self.sel_rules))\n        rules=self.sel_rules[\"rules\"]\n\n        for key in rules:\n\n                for s in streammeta:\n                    if key in s: \n                        #self.log(\"A\"+str(self.sel_rules[key]))\n                        self.log(s[key]) \n                        self.log(type(s[key]))\n                         \n                        if '$eq' in rules[key] and s[key]==rules[key]['$eq']:\n                            return True\n                        elif '$gt' in rules[key] and '$lt' in rules[key]:\n                            if (s[key]>rules[key]['$gt'] and s[key]<rules[key]['$lt']):\n                                self.log(\"GT-LT\") \n                                return True\n                            else:\n                                return False\n                        elif '$gt' in rules[key] and s[key]>rules[key]['$gt']:\n                            self.log(\"GT\") \n                            return True\n                        elif '$lt' in rules[key] and s[key]<rules[key]['$lt']:\n                            self.log(\"LT\") \n                            return True\n                        else:\n                            return False\n        return self.provon\n\n    def checkTransferRule(self,streammeta):\n        self.log(\"Checking Transfer-Rules\")\n        for key in self.transfer_rules[\"rules\"]:\n                for s in streammeta:\n                    if key in s: \n                        #self.log(\"A\"+str(self.sel_rules[key]))\n                        self.log(s[key]) \n                        self.log(type(s[key]))\n                        \n                        if '$eq' in self.transfer_rules[\"rules\"][key] and s[key]==self.transfer_rules[\"rules\"][key]['$eq']:\n                             \n                            return True\n                        elif '$gt' in self.transfer_rules[\"rules\"][key] and '$lt' in self.transfer_rules[\"rules\"][key]:\n                            if (s[key]>self.transfer_rules[\"rules\"][key]['$gt'] and s[key]<self.transfer_rules[\"rules\"][key]['$lt']):\n                                self.log(\"GT-LT\")\n                                 \n                                return True\n                        elif '$gt' in self.transfer_rules[\"rules\"][key] and s[key]>self.transfer_rules[\"rules\"][key]['$gt']:\n                            self.log(\"GT\") \n                            \n                            return True\n                        elif '$lt' in self.transfer_rules[\"rules\"][key] and s[key]<self.transfer_rules[\"rules\"][key]['$lt']:\n                            self.log(\"LT\")\n                            \n                            return True\n                        else:\n                            return False\n        return False\n\n    def dicToKeyVal(self, dict, valueToString=False):\n        try:\n            alist = list()\n            for k, v in dict.iteritems():\n                adic = {}\n                adic.update({\"key\": str(k)})\n                if valueToString:\n                    adic.update({\"val\": str(v)})\n                else:\n\n                    try:\n                        v = num(v)\n                        adic.update({\"val\": v})\n                    except Exception:\n                        adic.update({\"val\": str(v)})\n\n                alist.append(adic)\n\n            return alist\n        except Exception as err:\n\n            self.error += self.name + \" dicToKeyVal output Error: \" + str(err)\n            sys.stderr.write(\n                'ERROR: ' +\n                self.name +\n                ' dicToKeyVal output Error: ' +\n                str(err))\n#                self.map.put(\"output\",\"\");\n            traceback.print_exc(file=sys.stderr)\n\n    def discardInFlow(self,wlength=None,discardState=False): \n        #self.log('BEFORE '+str(self.derivationIds))\n        \n        \n        if discardState==True:\n            if wlength==None:\n            #self.log(\"discarding\")\n                self.derivationIds=[]\n            else:\n                count=0\n                for x in self.derivationIds:\n                    if x!=None and x['port']!='_d4p_state' and count>=wlength-1:\n                        self.derivationIds.remove(x)\n                    count+=1\n                for x in self.derivationIds:\n                    if x!=None and x['port']=='_d4p_state':\n                        self.derivationIds.remove(x)\n                        \n\n\n\n        else:\n            maxit=0\n            state=None\n            #self.log(\"BEFORE\" +str(self.derivationIds))\n            for x in self.derivationIds:\n                 \n                if x!=None and x['port']=='_d4p_state' and x['iterationIndex']>=maxit:\n                    \n                    state=x\n                    maxit=x['iterationIndex']\n            \n            if wlength==None:\n                if state!=None:   \n                    self.derivationIds=[state]\n                else:\n                    self.derivationIds=[]\n            else:\n                count=0\n                for x in self.derivationIds:\n                    #self.log(\"COUNT: \"+str(count)+\" WLENTGH: \"+str(wlength))\n                    if x!=None and x['port']!='_d4p_state' and count>=wlength-1:\n                        #self.log(\"REMOVE: \"+str(x['iterationIndex']))\n                        del self.derivationIds[0]   \n                    count+=1\n\n               \n\n                if state!=None: \n                    self.derivationIds.append(state)\n\n    def discardState(self): \n        #self.log('BEFORE '+str(self.derivationIds))\n        \n        \n        derivations = [x for x in self.derivationIds if x['port']!='_d4p_state']\n        \n        self.derivationIds=derivations\n\n    def extractDataSourceId(self,data,port):\n        self.makeUniqueId(data,port)\n\n    def extractItemMetadata(self,data,port):\n        try:\n               \n            st=[]\n             \n            if type(data) == Trace:\n                st.append(data)\n                \n            elif type(data)==tuple:\n                for x in data:\n                    if type(x)==Stream:\n                        st=x\n            else:\n                st=data\n            streammeta=list()\n            for tr in st:\n                \n                metadic={}\n                metadic.update({\"prov:type\":\"waveform\"});    \n                metadic.update({\"id\":str(uuid.uuid1())});\n                \n                for attr, value in tr.stats.__dict__.iteritems():\n                    \n                    if attr==\"mseed\":\n                        mseed={}\n                        for a,v in value.__dict__.iteritems():\n                            try:\n                                if type(v)==UTCDateTime:\n                                    mseed.update({a:str(v)});\n                                else:\n                                    mseed.update({a:float(v)});\n                            except Exception,e:\n                                mseed.update({a:str(v)});\n                        metadic.update({\"mseed\":mseed});\n                    else:\n                        try:\n                            if type(value)==UTCDateTime:\n                                metadic.update({attr:str(value)});\n                            else:\n                                metadic.update({attr:float(value)});\n                        except Exception,e:\n                            metadic.update({attr:str(value)});\n                \n                streammeta.append(metadic);\n            \n            return streammeta   \n        except Exception, err:\n            self.log(\"Applying default metadata extraction\")\n            #self.error=self.error+\"Extract Metadata error: \"+str(traceback.format_exc())\n            return super(SeismoPE, self).extractItemMetadata(data,port);\n\n    def extractProvenance(\n            self,\n            data,\n            location=\"\",\n            format=\"\",\n            metadata={},\n            control={},\n            attributes={},\n            error=\"\",\n            output_port=\"\",\n            **kwargs):\n\n        self.error = error\n\n        if metadata==None:\n            metadata={}\n        elif isinstance(metadata, list):\n            metadata.append(attributes)\n        else:\n            metadata.update(attributes)\n\n        usermeta = {}\n\n        if 's-prov:skip' in control and bool(control['s-prov:skip']):\n            self.provon = False\n        else:\n            self.provon = True\n            usermeta= self.buildUserMetadata(\n                data,\n                location=location,\n                format=format,\n                metadata=metadata,\n                control=control,\n                attributes=attributes,\n                error=error,\n                output_port=output_port,\n                **kwargs)\n        \n         \n        \n        self.flushData(data, usermeta, output_port,**kwargs)\n\n        return usermeta\n\n    def flushData(self, data, metadata, port,**kwargs):\n        trace = {}\n        stream = data\n        try:\n            if self.provon:\n                self.endTime = datetime.datetime.utcnow()\n                trace = self.packageAll(metadata)\n            \n            stream = self.prepareOutputStream(data, trace, port,**kwargs)\n              \n            try:\n                if port is not None and port != '_d4p_state' \\\n                        and port != 'error':\n\n                    super(ProvenancePE, self).write(port, stream)\n#stream)\n\n            except:\n                self.log(traceback.format_exc())\n                'if cant write doesnt matter move on'\n                pass\n            try:\n                if self.provon:\n                    if (ProvenancePE.send_prov_to_sensor==True) or (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\n\n                            self.sendProvToSensor(trace['metadata'])\n                            \n                            \n                            #super(\n                            #      ProvenancePE,\n                            #      self).write(\n                            #                  OUTPUT_METADATA,\n                            #                  deepcopy(trace['metadata']))\n                            \n\n                    if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n                        \n                        self.sendProvToService(trace['metadata'])\n                    if self.save_mode==ProvenancePE.SAVE_MODE_FILE:\n                         self.writeProvToFile(trace['metadata'])\n                     \n            except:\n                self.log(traceback.format_exc())\n                'if cant write doesnt matter move on'\n                pass\n\n            return True\n\n        except Exception:\n            self.log(traceback.format_exc())\n            if self.provon:\n                self.error += \" FlushChunk Error: %s\" % traceback.format_exc()\n\n    def getDataStreams(self, inputs):\n        streams = {}\n        for inp in self.inputconnections:\n            if inp not in inputs:\n                continue\n            values = inputs[inp]\n            if isinstance(values, list):\n                data = values[0:]\n            else:\n                data = values\n            streams[\"streams\"].update({inp: data})\n        return streams\n\n    def getInputAt(self, port=\"input\", index=None):\n        if index==None:\n            return self.inputs[port]\n        else:\n            return self.inputs[port][index]\n\n    def getOutputTypes(self):\n        '''\n        Returns the output types of this PE, in the form of a dictionary.\n        This method may be overridden if output types are not static and\n        depend on input types.\n\n        .. note::\n\n            This method is only called after the input types have been\n            initialised in :py:func:`~dispel4py.core.GenericPE.setInputTypes`.\n\n        :rtype: a dictionary mapping each output name to its type\n\n        By default it returns a dictionary of the types defined in the\n        'outputconnections' instance variable.\n\n        Usage example::\n\n            def getOutputTypes(self):\n                output = { 'output1' : myInputs['input1'],\n                           'output2' : [ 'comment' ] }\n\n        '''\n        ret = {}\n        # print '%s: %s' % (self.id, self.outputconnections)\n        for name, output in self.outputconnections.items():\n            try:\n                ret[name] = output[TYPE]\n            except KeyError:\n                raise Exception(\"%s: No output type defined for '%s'\"\n                                % (self.id, name))\n        return ret\n\n    def getProvStateObjectId(self,name):\n        if name in self.stateCollection:\n            return self.stateCollection[name]\n        else:\n            return None\n\n    def getUniqueId(self,data,port,**kwargs):\n        data_id = self.makeUniqueId(data,port)\n        if 'name' in kwargs:\n            self._updateState(kwargs['name'],data_id)\n\n\n\n        return data_id\n\n    def ignorePastFlow(self):\n        self.ignore_past_flow=True\n\n    def ignoreState(self):\n        self.ignore_state=True\n\n    def importInputData(self, data):\n\n        inputs = {}\n\n        try:\n            if not isinstance(data, collections.Iterable):\n                return data\n            else:\n                for x in data:\n                    #self.log(data[x])\n                    self.buildDerivation(data[x], port=x)\n                    if type(data[x])==dict and '_d4p' in data[x]:\n                        inputs[x] = data[x]['_d4p']\n                    else:\n                        inputs[x] = data[x]\n                return inputs\n\n        except Exception:\n            self.output = \"\"\n            self.error += \"Reading Input Error: %s\" % traceback.format_exc()\n            raise\n\n    def initParameters(self):\n\n        self.error = ''\n        self.w3c_prov = {}\n        #self.resetflow = True\n        self.inMetaStreams = None\n        self.username = None\n        self.runId = None\n\n\n        try:\n                # self.iterationId = self.name + '-' + getUniqueId()\n            if \"username\" in self.controlParameters:\n                self.username = self.controlParameters[\"username\"]\n            if \"runId\" in self.controlParameters:\n                self.runId = self.controlParameters[\"runId\"]\n\n        except:\n                self.runId = \"\"\n                pass\n\n        self.outputdest = self.controlParameters[\n            'outputdest'] if 'outputdest' in self.controlParameters else 'None'\n        self.rootpath = self.controlParameters[\n            'inputrootpath'] \\\n            if 'inputrootpath' in self.controlParameters else 'None'\n        self.outputid = self.controlParameters[\n            'outputid'] \\\n            if 'outputid' in self.controlParameters else 'None'\n\n    def makeProcessId(self, **kwargs):\n        \n        return socket.gethostname() + \"-\" + \\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\n\n    def makeUniqueId(self,data,port):\n        #if ('data' in kwargs):\n        #    self.log(str(kwargs['data']))\n        \n        return socket.gethostname() + \"-\" + \\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\n\n    def packageAll (self, contentmeta):\n        metadata = {}\n        if self.provon:\n            try:\n\n                # identifies the actual iteration over the instance\n                metadata.update({'iterationId': self.iterationId,\n                # identifies the actual writing process'\n                'actedOnBehalfOf': self.behalfOf,\n                '_id': self.id + '_write_' + str(self.makeProcessId()),\n                'iterationIndex': self.iterationIndex,\n                'instanceId': self.instanceId,\n                'annotations': {}})\n\n                if self.feedbackIteration:\n                    metadata.update(\n                        {'_id': self.id + '_feedback_' + str(self.makeProcessId())})\n                elif self.stateful:\n                    metadata.update(\n                        {'_id': self.id + '_stateful_' + str(self.makeProcessId())})\n\n                else:\n                    metadata.update(\n                        {'_id': self.id + '_write_' + str(self.makeProcessId())})\n\n\n                metadata.update({'stateful': not self.resetflow,\n                'feedbackIteration': self.feedbackIteration,\n                'worker': socket.gethostname(),\n                'parameters': self.parameters,\n                'errors': self.error,\n                'pid': '%s' % os.getpid()})\n\n\n                 \n                if self.ignore_inputs==True:\n                    derivations = [x for x in self.derivationIds if x['port']=='_d4p_state' and x['DerivedFromDatasetID'] in self.stateCollectionId]\n                    metadata.update({'derivationIds': derivations})\n                    self.ignore_inputs = False\n                    \n                elif self.ignore_past_flow==True:\n                     \n                    derivations = [x for x in self.derivationIds if (x['iterationIndex'] == self.iterationIndex or x['port']=='_d4p_state')]\n                    metadata.update({'derivationIds': derivations})\n                    #self.log(\"IGNOREPAST \"+str(derivations))\n\n                elif self.ignore_state==True:\n                    \n                    derivations = [x for x in self.derivationIds if x['port']!='_d4p_state']\n                    metadata.update({'derivationIds': derivations})\n                    #self.log(\"In package \"+str(self.derivationIds))\n                    #self.ignore_past_flow = False\n                else:\n                     \n                    metadata.update({'derivationIds': self.derivationIds})\n                    self.ignore_past_flow = False\n\n\n                metadata.update({'name': self.name,\n                'runId': self.runId,\n                'username': self.username,\n                'startTime': str(self.startTime),\n                'endTime': str(self.endTime),\n                'type': 'lineage',\n\n                'streams': contentmeta,\n                'mapping': sys.argv[1]})\n                \n                if hasattr(self, 'prov_cluster'):\n                     \n                    metadata.update({'prov_cluster': self.prov_cluster})\n                \n\n                if self.creator is not None:\n                    metadata.update({'creator': self.creator})\n            except Exception:\n                self.error += \" Packaging Error: %s\" % traceback.format_exc()\n                self.log(traceback.format_exc())\n\n        output = {\n            \"metadata\": metadata,\n            \"error\": self.error,\n            #\"pid\": \"%s\" %\n            #os.getpid()\n             }\n\n\n        return output\n\n    def pe_init(self, *args, **kwargs):\n        #ProvenancePE.__init__(self,*args, **kwargs)\n\n        global _d4p_plan_sqn\n        self._add_input('_d4py_feedback', grouping='all')\n        self.stateCollection={}\n        self.stateCollectionId=[]\n        self.impcls = None\n        self.bulk_prov = []\n        self.stateful=False\n        self.stateDerivations=[]\n\n\n        if 'pe_class' in kwargs and kwargs['pe_class'] != GenericPE:\n            self.impcls = kwargs['pe_class']\n       \n        if 'sel_rules' in kwargs and self.name in kwargs['sel_rules']:\n            print(self.name+\" \"+str(kwargs['sel_rules'][self.name]))\n            self.sel_rules = kwargs['sel_rules'][self.name]\n        else:\n            self.sel_rules=None\n        \n        if 'transfer_rules' in kwargs and self.name in kwargs['transfer_rules']:\n            print(self.name+\" \"+str(kwargs['transfer_rules'][self.name]))\n            self.transfer_rules = kwargs['transfer_rules'][self.name]\n        else:\n            self.transfer_rules=None\n\n\n        if 'creator' not in kwargs:\n            self.creator = None\n        else:\n            self.creator = kwargs['creator']\n\n        self.error = ''\n\n        if not hasattr(self, 'parameters'):\n            self.parameters = {}\n        if not hasattr(self, 'controlParameters'):\n            self.controlParameters = {}\n\n        if 'controlParameters' in kwargs:\n            self.controlParameters = kwargs['controlParameters']\n\n        out_md = {}\n        out_md[NAME] = OUTPUT_METADATA\n\n        # self.outputconnections[OUTPUT_DATA] = out1\n        #print(OUTPUT_METADATA)\n        self._add_output(OUTPUT_METADATA)\n        ##self.outputconnections[OUTPUT_METADATA] = out_md\n        self.taskId = str(uuid.uuid1())\n\n        # self.appParameters = None\n        self.provon = True\n        \n\n        if 'save_mode' not in kwargs:\n            self.save_mode=ProvenancePE.SAVE_MODE_FILE\n        else:\n            self.save_mode=SAVE_MODE_FILE = kwargs['save_mode']\n\n        self.wcount=0\n        self.resetflow = False\n        self.stateUpdateIndex=0\n        self.ignore_inputs = False\n        self.ignore_state=False\n        self.ignore_past_flow = False\n        self.derivationIds = list()\n        self.iterationIndex = 0\n        \n        #name + '_' + str(_d4p_plan_sqn)\n        _d4p_plan_sqn = _d4p_plan_sqn + 1\n        self.countstatewrite=0\n        if not hasattr(self, 'comp_id'):\n            self.behalfOf=self.id\n        else:\n            self.behalfOf=self.comp_id\n        if not hasattr(self, 'prov_cluster'):\n            self.prov_cluster=self.behalfOf\n\n    def postprocess(self):\n\n        \n        if len(self.bulk_prov)>0:\n            \n            if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n                #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\n                params = urllib.urlencode({'prov': ujson.dumps(self.bulk_prov)})\n                headers = {\n                       \"Content-type\": \"application\/x-www-form-urlencoded\",\n                       \"Accept\": \"application\/json\"}\n                self.connection = httplib.HTTPConnection(\n                                                     self.provurl.netloc)\n                self.connection.request(\n                                    \"POST\",\n                                    self.provurl.path,\n                                    params,\n                                    headers)\n                response = self.connection.getresponse()\n                self.log(\"Postprocess: \" +\n                     str((response.status, response.reason, response.read())))\n#                    response.read())))\n                self.connection.close()\n                self.bulk_prov[:]=[]\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_FILE):\n                filep = open(ProvenancePE.PROV_PATH + \"\/bulk_\" + self.makeProcessId(), \"wr\")\n                ujson.dump(self.bulk_prov, filep)\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\n                super(\n                                  ProvenancePE,\n                                  self).write(\n                                              OUTPUT_METADATA,\n                                              {'prov_cluster':self.prov_cluster,'provenance':deepcopy(self.bulk_prov)})\n            #self.bulk_prov[:]=[]\n\n        self._postprocess()\n\n    def prepareOutputStream(self, data, trace,port,**kwargs):\n        try:\n            streamtransfer = {}\n            streamtransfer['_d4p'] = data\n            #self.log(\"PROVON: \"+str(self.provon))\n            \n            try:\n\n\n                streamtransfer[\"prov_cluster\"] = self.prov_cluster\n                streamtransfer[\"port\"] = port\n                \n\n                if self.provon:\n                    \n                    #self.log(\"lnking Component trace\")\n                    streamtransfer['id'] = trace[\n                        'metadata'][\"streams\"][0][\"id\"]\n                    streamtransfer[\n                        \"TriggeredByProcessIterationID\"] = self.iterationId\n                    \n                    if port=='_d4p_state':\n                        #self.log(''' Building SELF Derivation '''+str(trace))\n                        self._updateState(kwargs['lookupterm'],trace[\n                        'metadata'][\"streams\"][0]['id'])\n                        streamtransfer['lookupterm']=kwargs['lookupterm']\n                        self.buildDerivation(streamtransfer,port='_d4p_state')\n                        \n                else:\n                    \n                    #self.log(\"Skip Component trace\")\n                    streamtransfer[\"id\"] = self.derivationIds[0][\"DerivedFromDatasetID\"]\n                    streamtransfer[\"TriggeredByProcessIterationID\"] = self.derivationIds[0][\"TriggeredByProcessIterationID\"]\n                    streamtransfer[\"up:assertionType\"] = \"up:Incomplete\"\n                    #self.log(streamtransfer)\n                    \n            except:\n                #self.log(traceback.format_exc())\n                pass\n            return streamtransfer\n\n        except Exception:\n            self.error += self.name + \" Writing output Error: %s\" % \\\n                traceback.format_exc()\n            raise\n\n    def preprocess(self):\n        if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n            self.provurl = urlparse(ProvenancePE.REPOS_URL)\n            #self.connection = httplib.HTTPConnection(\n            #                                         self.provurl.netloc)\n        self._preprocess()\n\n    def process(self, inputs):\n        self.feedbackIteration = False\n        self.void_invocation = True\n        self.iterationIndex += 1\n\n         \n        \n\n        if '_d4py_feedback' in inputs:\n\n            'state could be used here to track the occurring changes'\n            self.process_feedback(inputs['_d4py_feedback'])\n        else:\n            self.__processwrapper(inputs)\n\n        for x in inputs:\n            data=inputs[x]\n            if type(data)==dict and '_d4p' in data:\n                self.apply_derivation_rule('end_invocation_event',self.void_invocation,iport=x,data=data['_d4p'])   \n            else:\n                self.apply_derivation_rule('end_invocation_event',self.void_invocation,iport=x,data=data)  \n\n    def process_feedback(self, feedback):\n        self.feedbackIteration = True\n        self._process_feedback(feedback)\n\n    def removeDerivation(self,**kwargs):\n        if 'name' in kwargs:\n            id = self.getProvStateObjectId(kwargs['name'])\n            for j in self.derivationIds:\n\n                if j['DerivedFromDatasetID']==id:\n\n                    del self.derivationIds[self.derivationIds.index(j)]\n        else:\n            if 'port' in kwargs:\n                for j in self.derivationIds:\n\n                    if j['port']==kwargs['port']:\n\n                        del self.derivationIds[self.derivationIds.index(j)]\n\n    def sendProvToSensor(self, prov):\n        \n\n        self.bulk_prov.append(deepcopy(prov))\n\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\n            super(\n                                  ProvenancePE,\n                                  self).write(\n                                              OUTPUT_METADATA,\n                                              {'prov_cluster':self.prov_cluster,'provenance':deepcopy(self.bulk_prov)})\n\n             \n            self.bulk_prov[:]=[]\n\n        return None\n\n    def sendProvToService(self, prov):\n\n        #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\n\n        if isinstance(prov, list) and \"data\" in prov[0]:\n            prov = prov[0][\"data\"]\n\n        self.bulk_prov.append(deepcopy(prov))\n        \n        if len(self.bulk_prov) > ProvenancePE.BULK_SIZE:\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\n            params = urllib.urlencode({'prov': ujson.dumps(self.bulk_prov)})\n            headers = {\n                \"Content-type\": \"application\/x-www-form-urlencoded\",\n                \"Accept\": \"application\/json\"}\n            self.connection = httplib.HTTPConnection(\n                                                     self.provurl.netloc)\n            self.connection.request(\n                \"POST\", self.provurl.path, params, headers)\n            response = self.connection.getresponse()\n            #self.log(\"progress: \" + str((response.status, response.reason,response.read())))\n            #                             response, response.read())))\n\n            self.bulk_prov[:]=[]\n\n        return None\n\n    def setInputTypes(self, types):\n        '''\n        Sets the input types of this PE, in the form of a dictionary.\n        It is meant to be overridden, e.g. if output types depend on input.\n\n        .. note::\n\n            This method is always called before\n            :py:func:`~dispel4py.core.GenericPE.getOutputTypes`.\n\n        :param types: object types for each input stream\n        :type types: dictionary mapping input name to input type\n\n        Usage example::\n\n            pe.setInputTypes({'input1':['t1', 't2', 't3'], \\\n                              'input2':['t4', 't5']})\n        '''\n        pass\n\n    def setStateDerivations(self,terms):\n        self.stateDerivations=terms\n\n    def update_prov_state(\n            self,\n            lookupterm,\n            data,\n            location=\"\",\n            format=\"\",\n            metadata={},\n            ignore_inputs=False,\n            ignore_state=True,\n            stateless=False,\n            **kwargs\n    ):\n\n        self.endTime = datetime.datetime.utcnow()\n        self.stateful = True\n        self.ignore_inputs = ignore_inputs\n        self.ignore_state = ignore_state\n        self.addprov=True\n        kwargs['lookupterm']=lookupterm\n        #self.apply_derivation_rule('state', None)\n        if self.provon:\n            if data == None:\n                    self._updateState(lookupterm,self.derivationIds[len(self.derivationIds)-1][\"DerivedFromDatasetID\"])\n\n            else:\n                \n                if 'dep' in kwargs and kwargs['dep']!=None:\n                #self.removeDerivation(port='_d4p_state')\n                \n                    for d in kwargs['dep']:\n                        did=self.getProvStateObjectId(d)\n                    \n                        if did!=None:\n                            self.buildDerivation({'id':did,'TriggeredByProcessIterationID':self.iterationId,'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n                        #self.ignore_state = False\n                        #self.log(\"DERI \"+str(did))\n                        #self.log(\"DERI2 \"+str(self.derivationIds))\n                        #\n\n            \n                self.extractProvenance(data,\n                               location,\n                               format,\n                               metadata,\n                               output_port=\"_d4p_state\",\n                               **kwargs)\n\n         \n\n\n        self.ignore_inputs = False\n        self.ignore_state = False\n\n\n\n        if 'dep' in kwargs and kwargs['dep']!=None:\n            for d in kwargs['dep']:\n                self.removeDerivation(name=d)\n        \n\n        self.stateful  = False\n\n    def write(self, name, data, **kwargs):\n        self.void_invocation=False\n        dep = []\n\n        iport=None\n\n        for i in self.inputs:\n            iport=i\n\n        if 'metadata' in kwargs:\n            dep = self.apply_derivation_rule('write',True,oport=name,iport=iport,data=data,metadata=kwargs['metadata'])\n        else:\n            dep = self.apply_derivation_rule('write',True,oport=name,iport=iport,data=data)\n        \n        self.endTime = datetime.datetime.utcnow()\n\n       \n        \n        if 'dep' in kwargs and kwargs['dep']!=None: \n            for d in kwargs['dep']:\n                self.buildDerivation({'id':self.getProvStateObjectId(d),'TriggeredByProcessIterationID':self.iterationId, 'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n        elif len(self.stateDerivations) > 0:\n            for d in self.stateDerivations:\n                self.buildDerivation({'id':self.getProvStateObjectId(d),'TriggeredByProcessIterationID':self.iterationId, 'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n\n        if 'ignore_inputs' in kwargs:\n            self.ignore_inputs=kwargs['ignore_inputs']\n        \n       \n        \n        self.extractProvenance(data, output_port=name, **kwargs)\n\n        if 'dep' in kwargs and kwargs['dep']!=None:\n            for d in kwargs['dep']:\n                self.removeDerivation(name=d)\n        elif len(self.stateDerivations) > 0:\n            for d in self.stateDerivations:\n                self.removeDerivation(name=d)\n\n\n        self.stateDerivations=[]\n\n    def writeProvToFile(self, prov):\n        \n        if isinstance(prov, list) and \"data\" in prov[0]:\n            prov = prov[0][\"data\"]\n        \n         \n        #self.log('PROCESS: '+str(prov))\n        self.bulk_prov.append(prov)\n        \n        \n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\n            filep = open(\n                ProvenancePE.PROV_PATH +\n                \"\/bulk_\" +\n                self.makeProcessId(),\n                \"wr\")\n            #self.log('PROCESS: '+str(filep))\n            ujson.dump(self.bulk_prov, filep)\n            #filep.write(json.dumps(self.bulk_prov))\n            self.bulk_prov[:]=[]\n\n        return None\n\n    def writeResults(self, name, result):\n\n        #self.resetflow = True\n        self.apply_derivation_rule('write',True,data=result,oport=name)\n        self.void_invocation=False\n        \n        \n\n        if isinstance(result, dict) and '_d4p_prov' in result:\n            meta = result['_d4p_prov']\n            result = (result['_d4p_data'])\n\n            if 'error' in meta:\n                self.extractProvenance(result, output_port=name, **meta)\n            else:\n\n                self.extractProvenance(\n                    result, error=self.error, output_port=name, **meta)\n\n        else:\n            self.extractProvenance(result, error=self.error, output_port=name)\n\n","type":"(<class 'dispel4py.seismo.seismo.SeismoPE'>, <class 'test.misfit_processing.misfit_processing_prov.WindowTaperingPE'>)","functionName":"WindowTaperingPE"},"MergeImagesPE5":{"code":"    def __computewrapper(self, inputs):\n\n        try:\n            result = None\n\n            self.__markIteration()\n\n            if self.impcls is not None and isinstance(self, self.impcls):\n                try:\n                    if hasattr(self, 'params'):\n                        self.parameters = self.params\n                    result = self._process(inputs[self.impcls.INPUT_NAME])\n                    if result is not None:\n                        self.writeResults(self.impcls.OUTPUT_NAME, result)\n                except:\n                    result = self._process(inputs)\n            else:\n                result = self._process(inputs)\n\n            if result is not None:\n                return result\n\n        except Exception:\n            self.log(\" Compute Error: %s\" % traceback.format_exc())\n            self.error += \" Compute Error: %s\" % traceback.format_exc()\n            # self.endTime = datetime.datetime.utcnow()\n            self.writeResults('error', {'error': 'null'})\n\n    def __getUniqueId(self):\n        return socket.gethostname() + \"-\" + str(os.getpid()) + \\\n            \"-\" + str(uuid.uuid1())\n\n    def __importInputMetadata(self):\n        try:\n            self.inMetaStreams = self.input[\"metadata\"][\"streams\"]\n        except Exception:\n            None\n\n    def __markIteration(self):\n        self.startTime = datetime.datetime.utcnow()\n        self.iterationId = self.name + '-' + self.makeProcessId()\n\n    def __processwrapper(self, data):\n        try:\n\n            self.initParameters()\n\n            self.inputs = self.importInputData(data)\n            # self.__importInputMetadata()\n            return self.__computewrapper(self.inputs)\n\n        except:\n            self.log(traceback.format_exc())\n\n    def __init__(self,*args,**kwargs):\n        ProvenancePE.__init__(self,*args,**kwargs)\n        self.addNamespacePrefix(\"seis\",\"http:\/\/seis-prov.eu\/ns\/#\")\n\n    def _add_input(self, name, grouping=None, tuple_type=None):\n        '''\n        Declares an input for this PE.\n        This method may be used when initialising a PE instead of modifying\n        :py:attr:`~dispel4py.core.GenericPE.inputconnections` directly.\n\n        :param name: name of the input\n        :param grouping: the grouping type that this input expects (optional)\n        :param tuple_type: type of tuples accepted by this input (optional)\n        '''\n        self.inputconnections[name] = {NAME: name}\n        if grouping:\n            self.inputconnections[name][GROUPING] = grouping\n        if tuple_type:\n            self.inputconnections[name][TYPE] = tuple_type\n\n    def _add_output(self, name, tuple_type=None):\n        '''\n        Declares an output for this PE.\n        This method may be used when initialising a PE instead of modifying\n        :py:attr:`~dispel4py.core.GenericPE.outputconnections` directly.\n\n        :param name: name of the output\n        :param tuple_type: type of tuples produced by this output (optional)\n        '''\n        self.outputconnections[name] = {NAME: name}\n        if tuple_type:\n            self.outputconnections[name][TYPE] = tuple_type\n\n    def _postprocess(self):\n        None\n\n    def _preprocess(self):\n        self.instanceId = self.name + \"-Instance-\" + \\\n            \"-\" + self.makeProcessId()\n\n        super(ProvenancePE, self)._preprocess()\n\n    def _process(self, data):\n        station_id, image_type, images, output_folder = data\n\n        self.log(\"Merging name %s type %s\" % (station_id, image_type))\n        result = stack_images(images)\n        filename = \"%s-%s.png\" % (image_type, station_id)\n        filename = os.path.join(output_folder, filename)\n        result.save(filename, \"PNG\")\n        #result.close()\n        self.write('output',filename,metadata={'station_id': station_id, 'image_type':image_type},format='image\/png',location=\"file:\/\/\"+socket.gethostname()+\"\/\"+str(filename))\n\n    def _updateState(self,name,id):\n        if name in self.stateCollection:\n                self.stateCollectionId.remove(self.stateCollection[name])\n        self.stateCollection[name]=id\n        self.stateCollectionId.append(id)\n\n    def _write(self, name, data, **kwargs):\n        '''\n        This writes the 'data' to the output pipe with name 'name' of this PE.\n        '''\n         \n        try:\n            output = self.outputconnections[name]\n            output[WRITER].write(data)\n        except KeyError:\n            raise Exception(\"Can't write data: Unknown output connection\\\n                            '%s' for PE '%s'\" % (name, type(self).__name__))\n\n    def addNamespacePrefix(self,prefix,url):\n        self.ns.update({prefix:url})\n\n    def apply_derivation_rule(self,event,voidInvocation,oport=None,iport=None,data=None,metadata=None):\n        \n        if (event=='end_invocation_event') and voidInvocation==True:\n            self.discardInFlow(discardState=True)\n        \n        if (event=='end_invocation_event') and voidInvocation==False:\n            self.discardInFlow(discardState=True)\n\n    def buildDerivation(self, data, port=\"\"):\n        \n        if data!=None and 'id' in data:\n\n            derivation = {'port': port, \n                          'DerivedFromDatasetID': data['id'], \n                          'TriggeredByProcessIterationID': data['TriggeredByProcessIterationID'], \n                          'prov_cluster': data['prov_cluster'],\n                          'iterationIndex':self.iterationIndex,\n                          \n\n\n\n                          }\n                          \n            if port==\"_d4p_state\": \n                derivation.update({'lookupterm':data['lookupterm']})\n                 \n\t\t    \n            if \"up:assertionType\" in data:\n                derivation.update({\"up:assertionType\":data[\"up:assertionType\"]})\n\n\n\n            self.derivationIds.append(derivation)\n\n        else:\n            \n            id=self.extractDataSourceId(data,port)\n            #traceback.print_exc(file=sys.stderr)\n            derivation = {'port': port, 'DerivedFromDatasetID':\n                          id, 'TriggeredByProcessIterationID':\n                          None, 'prov_cluster':\n                          None,\n                          'iterationIndex':self.iterationIndex\n                          }\n            self.derivationIds.append(derivation)\n            self.log(\"BUILDING INITIAL DERIVATION\")\n\n    def buildUserMetadata(self, data, **kwargs):\n        streamlist = list()\n\n        streamItem = {}\n        streammeta = []\n        settransfer=False\n        streammeta = self.extractItemMetadata(data,kwargs['output_port'])\n        \n        if not isinstance(streammeta, list):\n            streammeta = kwargs['metadata'] if isinstance(\n                kwargs['metadata'], list) else [kwargs['metadata']]\n        elif isinstance(streammeta, list):\n            try:\n                if isinstance(kwargs['metadata'], list):\n                    streammeta = streammeta + kwargs['metadata']\n                if isinstance(kwargs['metadata'], dict):\n                    for y in streammeta:\n                        y.update(kwargs['metadata'])\n            except:\n                traceback.print_exc(file=sys.stderr)\n                None\n        \n        if self.sel_rules!=None:\n            self.provon=self.checkSelectiveRule(streammeta)\n\n       \n        if not self.provon:\n            return streamItem\n        #self.log(kwargs)\n        streamItem.update({\"content\": streammeta,\n                           \"id\": self.getUniqueId(data,kwargs['output_port'],**kwargs),\n                           \"format\": \"\",\n                           \"location\": \"\",\n                           \"annotations\": [],\n                           \"port\": kwargs['output_port']})\n        # if (self.streamItemsControl!={,:\n        streamItem.update(kwargs['control'])\n        # if (self.streamItemsLocations!={,:\n        streamItem.update({\"location\": kwargs['location'],\n                          \"format\": kwargs['format']})\n        streamItem.update({\"size\": total_size(data)})\n        #streamItem.update({\"size\": 0})\n\n        if self.transfer_rules!=None:\n            settransfer=self.checkTransferRule(streammeta)\n\n\n        if settransfer:\n            streamItem[\"s-prov:immediateAccess\"]=True\n            streamItem[\"s-prov:first-known-destination\"]=self.transfer_rules[\"destination\"]\n\n        \n        \n        streamlist.append(streamItem)\n        return streamlist\n\n    def checkSelectiveRule(self,streammeta):\n        self.log(\"Checking Skip-Rules: \"+str(self.sel_rules))\n        rules=self.sel_rules[\"rules\"]\n\n        for key in rules:\n\n                for s in streammeta:\n                    if key in s: \n                        #self.log(\"A\"+str(self.sel_rules[key]))\n                        self.log(s[key]) \n                        self.log(type(s[key]))\n                         \n                        if '$eq' in rules[key] and s[key]==rules[key]['$eq']:\n                            return True\n                        elif '$gt' in rules[key] and '$lt' in rules[key]:\n                            if (s[key]>rules[key]['$gt'] and s[key]<rules[key]['$lt']):\n                                self.log(\"GT-LT\") \n                                return True\n                            else:\n                                return False\n                        elif '$gt' in rules[key] and s[key]>rules[key]['$gt']:\n                            self.log(\"GT\") \n                            return True\n                        elif '$lt' in rules[key] and s[key]<rules[key]['$lt']:\n                            self.log(\"LT\") \n                            return True\n                        else:\n                            return False\n        return self.provon\n\n    def checkTransferRule(self,streammeta):\n        self.log(\"Checking Transfer-Rules\")\n        for key in self.transfer_rules[\"rules\"]:\n                for s in streammeta:\n                    if key in s: \n                        #self.log(\"A\"+str(self.sel_rules[key]))\n                        self.log(s[key]) \n                        self.log(type(s[key]))\n                        \n                        if '$eq' in self.transfer_rules[\"rules\"][key] and s[key]==self.transfer_rules[\"rules\"][key]['$eq']:\n                             \n                            return True\n                        elif '$gt' in self.transfer_rules[\"rules\"][key] and '$lt' in self.transfer_rules[\"rules\"][key]:\n                            if (s[key]>self.transfer_rules[\"rules\"][key]['$gt'] and s[key]<self.transfer_rules[\"rules\"][key]['$lt']):\n                                self.log(\"GT-LT\")\n                                 \n                                return True\n                        elif '$gt' in self.transfer_rules[\"rules\"][key] and s[key]>self.transfer_rules[\"rules\"][key]['$gt']:\n                            self.log(\"GT\") \n                            \n                            return True\n                        elif '$lt' in self.transfer_rules[\"rules\"][key] and s[key]<self.transfer_rules[\"rules\"][key]['$lt']:\n                            self.log(\"LT\")\n                            \n                            return True\n                        else:\n                            return False\n        return False\n\n    def dicToKeyVal(self, dict, valueToString=False):\n        try:\n            alist = list()\n            for k, v in dict.iteritems():\n                adic = {}\n                adic.update({\"key\": str(k)})\n                if valueToString:\n                    adic.update({\"val\": str(v)})\n                else:\n\n                    try:\n                        v = num(v)\n                        adic.update({\"val\": v})\n                    except Exception:\n                        adic.update({\"val\": str(v)})\n\n                alist.append(adic)\n\n            return alist\n        except Exception as err:\n\n            self.error += self.name + \" dicToKeyVal output Error: \" + str(err)\n            sys.stderr.write(\n                'ERROR: ' +\n                self.name +\n                ' dicToKeyVal output Error: ' +\n                str(err))\n#                self.map.put(\"output\",\"\");\n            traceback.print_exc(file=sys.stderr)\n\n    def discardInFlow(self,wlength=None,discardState=False): \n        #self.log('BEFORE '+str(self.derivationIds))\n        \n        \n        if discardState==True:\n            if wlength==None:\n            #self.log(\"discarding\")\n                self.derivationIds=[]\n            else:\n                count=0\n                for x in self.derivationIds:\n                    if x!=None and x['port']!='_d4p_state' and count>=wlength-1:\n                        self.derivationIds.remove(x)\n                    count+=1\n                for x in self.derivationIds:\n                    if x!=None and x['port']=='_d4p_state':\n                        self.derivationIds.remove(x)\n                        \n\n\n\n        else:\n            maxit=0\n            state=None\n            #self.log(\"BEFORE\" +str(self.derivationIds))\n            for x in self.derivationIds:\n                 \n                if x!=None and x['port']=='_d4p_state' and x['iterationIndex']>=maxit:\n                    \n                    state=x\n                    maxit=x['iterationIndex']\n            \n            if wlength==None:\n                if state!=None:   \n                    self.derivationIds=[state]\n                else:\n                    self.derivationIds=[]\n            else:\n                count=0\n                for x in self.derivationIds:\n                    #self.log(\"COUNT: \"+str(count)+\" WLENTGH: \"+str(wlength))\n                    if x!=None and x['port']!='_d4p_state' and count>=wlength-1:\n                        #self.log(\"REMOVE: \"+str(x['iterationIndex']))\n                        del self.derivationIds[0]   \n                    count+=1\n\n               \n\n                if state!=None: \n                    self.derivationIds.append(state)\n\n    def discardState(self): \n        #self.log('BEFORE '+str(self.derivationIds))\n        \n        \n        derivations = [x for x in self.derivationIds if x['port']!='_d4p_state']\n        \n        self.derivationIds=derivations\n\n    def extractDataSourceId(self,data,port):\n        self.makeUniqueId(data,port)\n\n    def extractItemMetadata(self,data,port):\n        try:\n               \n            st=[]\n             \n            if type(data) == Trace:\n                st.append(data)\n                \n            elif type(data)==tuple:\n                for x in data:\n                    if type(x)==Stream:\n                        st=x\n            else:\n                st=data\n            streammeta=list()\n            for tr in st:\n                \n                metadic={}\n                metadic.update({\"prov:type\":\"waveform\"});    \n                metadic.update({\"id\":str(uuid.uuid1())});\n                \n                for attr, value in tr.stats.__dict__.iteritems():\n                    \n                    if attr==\"mseed\":\n                        mseed={}\n                        for a,v in value.__dict__.iteritems():\n                            try:\n                                if type(v)==UTCDateTime:\n                                    mseed.update({a:str(v)});\n                                else:\n                                    mseed.update({a:float(v)});\n                            except Exception,e:\n                                mseed.update({a:str(v)});\n                        metadic.update({\"mseed\":mseed});\n                    else:\n                        try:\n                            if type(value)==UTCDateTime:\n                                metadic.update({attr:str(value)});\n                            else:\n                                metadic.update({attr:float(value)});\n                        except Exception,e:\n                            metadic.update({attr:str(value)});\n                \n                streammeta.append(metadic);\n            \n            return streammeta   \n        except Exception, err:\n            self.log(\"Applying default metadata extraction\")\n            #self.error=self.error+\"Extract Metadata error: \"+str(traceback.format_exc())\n            return super(SeismoPE, self).extractItemMetadata(data,port);\n\n    def extractProvenance(\n            self,\n            data,\n            location=\"\",\n            format=\"\",\n            metadata={},\n            control={},\n            attributes={},\n            error=\"\",\n            output_port=\"\",\n            **kwargs):\n\n        self.error = error\n\n        if metadata==None:\n            metadata={}\n        elif isinstance(metadata, list):\n            metadata.append(attributes)\n        else:\n            metadata.update(attributes)\n\n        usermeta = {}\n\n        if 's-prov:skip' in control and bool(control['s-prov:skip']):\n            self.provon = False\n        else:\n            self.provon = True\n            usermeta= self.buildUserMetadata(\n                data,\n                location=location,\n                format=format,\n                metadata=metadata,\n                control=control,\n                attributes=attributes,\n                error=error,\n                output_port=output_port,\n                **kwargs)\n        \n         \n        \n        self.flushData(data, usermeta, output_port,**kwargs)\n\n        return usermeta\n\n    def flushData(self, data, metadata, port,**kwargs):\n        trace = {}\n        stream = data\n        try:\n            if self.provon:\n                self.endTime = datetime.datetime.utcnow()\n                trace = self.packageAll(metadata)\n            \n            stream = self.prepareOutputStream(data, trace, port,**kwargs)\n              \n            try:\n                if port is not None and port != '_d4p_state' \\\n                        and port != 'error':\n\n                    super(ProvenancePE, self).write(port, stream)\n#stream)\n\n            except:\n                self.log(traceback.format_exc())\n                'if cant write doesnt matter move on'\n                pass\n            try:\n                if self.provon:\n                    if (ProvenancePE.send_prov_to_sensor==True) or (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\n\n                            self.sendProvToSensor(trace['metadata'])\n                            \n                            \n                            #super(\n                            #      ProvenancePE,\n                            #      self).write(\n                            #                  OUTPUT_METADATA,\n                            #                  deepcopy(trace['metadata']))\n                            \n\n                    if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n                        \n                        self.sendProvToService(trace['metadata'])\n                    if self.save_mode==ProvenancePE.SAVE_MODE_FILE:\n                         self.writeProvToFile(trace['metadata'])\n                     \n            except:\n                self.log(traceback.format_exc())\n                'if cant write doesnt matter move on'\n                pass\n\n            return True\n\n        except Exception:\n            self.log(traceback.format_exc())\n            if self.provon:\n                self.error += \" FlushChunk Error: %s\" % traceback.format_exc()\n\n    def getDataStreams(self, inputs):\n        streams = {}\n        for inp in self.inputconnections:\n            if inp not in inputs:\n                continue\n            values = inputs[inp]\n            if isinstance(values, list):\n                data = values[0:]\n            else:\n                data = values\n            streams[\"streams\"].update({inp: data})\n        return streams\n\n    def getInputAt(self, port=\"input\", index=None):\n        if index==None:\n            return self.inputs[port]\n        else:\n            return self.inputs[port][index]\n\n    def getOutputTypes(self):\n        '''\n        Returns the output types of this PE, in the form of a dictionary.\n        This method may be overridden if output types are not static and\n        depend on input types.\n\n        .. note::\n\n            This method is only called after the input types have been\n            initialised in :py:func:`~dispel4py.core.GenericPE.setInputTypes`.\n\n        :rtype: a dictionary mapping each output name to its type\n\n        By default it returns a dictionary of the types defined in the\n        'outputconnections' instance variable.\n\n        Usage example::\n\n            def getOutputTypes(self):\n                output = { 'output1' : myInputs['input1'],\n                           'output2' : [ 'comment' ] }\n\n        '''\n        ret = {}\n        # print '%s: %s' % (self.id, self.outputconnections)\n        for name, output in self.outputconnections.items():\n            try:\n                ret[name] = output[TYPE]\n            except KeyError:\n                raise Exception(\"%s: No output type defined for '%s'\"\n                                % (self.id, name))\n        return ret\n\n    def getProvStateObjectId(self,name):\n        if name in self.stateCollection:\n            return self.stateCollection[name]\n        else:\n            return None\n\n    def getUniqueId(self,data,port,**kwargs):\n        data_id = self.makeUniqueId(data,port)\n        if 'name' in kwargs:\n            self._updateState(kwargs['name'],data_id)\n\n\n\n        return data_id\n\n    def ignorePastFlow(self):\n        self.ignore_past_flow=True\n\n    def ignoreState(self):\n        self.ignore_state=True\n\n    def importInputData(self, data):\n\n        inputs = {}\n\n        try:\n            if not isinstance(data, collections.Iterable):\n                return data\n            else:\n                for x in data:\n                    #self.log(data[x])\n                    self.buildDerivation(data[x], port=x)\n                    if type(data[x])==dict and '_d4p' in data[x]:\n                        inputs[x] = data[x]['_d4p']\n                    else:\n                        inputs[x] = data[x]\n                return inputs\n\n        except Exception:\n            self.output = \"\"\n            self.error += \"Reading Input Error: %s\" % traceback.format_exc()\n            raise\n\n    def initParameters(self):\n\n        self.error = ''\n        self.w3c_prov = {}\n        #self.resetflow = True\n        self.inMetaStreams = None\n        self.username = None\n        self.runId = None\n\n\n        try:\n                # self.iterationId = self.name + '-' + getUniqueId()\n            if \"username\" in self.controlParameters:\n                self.username = self.controlParameters[\"username\"]\n            if \"runId\" in self.controlParameters:\n                self.runId = self.controlParameters[\"runId\"]\n\n        except:\n                self.runId = \"\"\n                pass\n\n        self.outputdest = self.controlParameters[\n            'outputdest'] if 'outputdest' in self.controlParameters else 'None'\n        self.rootpath = self.controlParameters[\n            'inputrootpath'] \\\n            if 'inputrootpath' in self.controlParameters else 'None'\n        self.outputid = self.controlParameters[\n            'outputid'] \\\n            if 'outputid' in self.controlParameters else 'None'\n\n    def makeProcessId(self, **kwargs):\n        \n        return socket.gethostname() + \"-\" + \\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\n\n    def makeUniqueId(self,data,port):\n        #if ('data' in kwargs):\n        #    self.log(str(kwargs['data']))\n        \n        return socket.gethostname() + \"-\" + \\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\n\n    def packageAll (self, contentmeta):\n        metadata = {}\n        if self.provon:\n            try:\n\n                # identifies the actual iteration over the instance\n                metadata.update({'iterationId': self.iterationId,\n                # identifies the actual writing process'\n                'actedOnBehalfOf': self.behalfOf,\n                '_id': self.id + '_write_' + str(self.makeProcessId()),\n                'iterationIndex': self.iterationIndex,\n                'instanceId': self.instanceId,\n                'annotations': {}})\n\n                if self.feedbackIteration:\n                    metadata.update(\n                        {'_id': self.id + '_feedback_' + str(self.makeProcessId())})\n                elif self.stateful:\n                    metadata.update(\n                        {'_id': self.id + '_stateful_' + str(self.makeProcessId())})\n\n                else:\n                    metadata.update(\n                        {'_id': self.id + '_write_' + str(self.makeProcessId())})\n\n\n                metadata.update({'stateful': not self.resetflow,\n                'feedbackIteration': self.feedbackIteration,\n                'worker': socket.gethostname(),\n                'parameters': self.parameters,\n                'errors': self.error,\n                'pid': '%s' % os.getpid()})\n\n\n                 \n                if self.ignore_inputs==True:\n                    derivations = [x for x in self.derivationIds if x['port']=='_d4p_state' and x['DerivedFromDatasetID'] in self.stateCollectionId]\n                    metadata.update({'derivationIds': derivations})\n                    self.ignore_inputs = False\n                    \n                elif self.ignore_past_flow==True:\n                     \n                    derivations = [x for x in self.derivationIds if (x['iterationIndex'] == self.iterationIndex or x['port']=='_d4p_state')]\n                    metadata.update({'derivationIds': derivations})\n                    #self.log(\"IGNOREPAST \"+str(derivations))\n\n                elif self.ignore_state==True:\n                    \n                    derivations = [x for x in self.derivationIds if x['port']!='_d4p_state']\n                    metadata.update({'derivationIds': derivations})\n                    #self.log(\"In package \"+str(self.derivationIds))\n                    #self.ignore_past_flow = False\n                else:\n                     \n                    metadata.update({'derivationIds': self.derivationIds})\n                    self.ignore_past_flow = False\n\n\n                metadata.update({'name': self.name,\n                'runId': self.runId,\n                'username': self.username,\n                'startTime': str(self.startTime),\n                'endTime': str(self.endTime),\n                'type': 'lineage',\n\n                'streams': contentmeta,\n                'mapping': sys.argv[1]})\n                \n                if hasattr(self, 'prov_cluster'):\n                     \n                    metadata.update({'prov_cluster': self.prov_cluster})\n                \n\n                if self.creator is not None:\n                    metadata.update({'creator': self.creator})\n            except Exception:\n                self.error += \" Packaging Error: %s\" % traceback.format_exc()\n                self.log(traceback.format_exc())\n\n        output = {\n            \"metadata\": metadata,\n            \"error\": self.error,\n            #\"pid\": \"%s\" %\n            #os.getpid()\n             }\n\n\n        return output\n\n    def pe_init(self, *args, **kwargs):\n        #ProvenancePE.__init__(self,*args, **kwargs)\n\n        global _d4p_plan_sqn\n        self._add_input('_d4py_feedback', grouping='all')\n        self.stateCollection={}\n        self.stateCollectionId=[]\n        self.impcls = None\n        self.bulk_prov = []\n        self.stateful=False\n        self.stateDerivations=[]\n\n\n        if 'pe_class' in kwargs and kwargs['pe_class'] != GenericPE:\n            self.impcls = kwargs['pe_class']\n       \n        if 'sel_rules' in kwargs and self.name in kwargs['sel_rules']:\n            print(self.name+\" \"+str(kwargs['sel_rules'][self.name]))\n            self.sel_rules = kwargs['sel_rules'][self.name]\n        else:\n            self.sel_rules=None\n        \n        if 'transfer_rules' in kwargs and self.name in kwargs['transfer_rules']:\n            print(self.name+\" \"+str(kwargs['transfer_rules'][self.name]))\n            self.transfer_rules = kwargs['transfer_rules'][self.name]\n        else:\n            self.transfer_rules=None\n\n\n        if 'creator' not in kwargs:\n            self.creator = None\n        else:\n            self.creator = kwargs['creator']\n\n        self.error = ''\n\n        if not hasattr(self, 'parameters'):\n            self.parameters = {}\n        if not hasattr(self, 'controlParameters'):\n            self.controlParameters = {}\n\n        if 'controlParameters' in kwargs:\n            self.controlParameters = kwargs['controlParameters']\n\n        out_md = {}\n        out_md[NAME] = OUTPUT_METADATA\n\n        # self.outputconnections[OUTPUT_DATA] = out1\n        #print(OUTPUT_METADATA)\n        self._add_output(OUTPUT_METADATA)\n        ##self.outputconnections[OUTPUT_METADATA] = out_md\n        self.taskId = str(uuid.uuid1())\n\n        # self.appParameters = None\n        self.provon = True\n        \n\n        if 'save_mode' not in kwargs:\n            self.save_mode=ProvenancePE.SAVE_MODE_FILE\n        else:\n            self.save_mode=SAVE_MODE_FILE = kwargs['save_mode']\n\n        self.wcount=0\n        self.resetflow = False\n        self.stateUpdateIndex=0\n        self.ignore_inputs = False\n        self.ignore_state=False\n        self.ignore_past_flow = False\n        self.derivationIds = list()\n        self.iterationIndex = 0\n        \n        #name + '_' + str(_d4p_plan_sqn)\n        _d4p_plan_sqn = _d4p_plan_sqn + 1\n        self.countstatewrite=0\n        if not hasattr(self, 'comp_id'):\n            self.behalfOf=self.id\n        else:\n            self.behalfOf=self.comp_id\n        if not hasattr(self, 'prov_cluster'):\n            self.prov_cluster=self.behalfOf\n\n    def postprocess(self):\n\n        \n        if len(self.bulk_prov)>0:\n            \n            if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n                #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\n                params = urllib.urlencode({'prov': ujson.dumps(self.bulk_prov)})\n                headers = {\n                       \"Content-type\": \"application\/x-www-form-urlencoded\",\n                       \"Accept\": \"application\/json\"}\n                self.connection = httplib.HTTPConnection(\n                                                     self.provurl.netloc)\n                self.connection.request(\n                                    \"POST\",\n                                    self.provurl.path,\n                                    params,\n                                    headers)\n                response = self.connection.getresponse()\n                self.log(\"Postprocess: \" +\n                     str((response.status, response.reason, response.read())))\n#                    response.read())))\n                self.connection.close()\n                self.bulk_prov[:]=[]\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_FILE):\n                filep = open(ProvenancePE.PROV_PATH + \"\/bulk_\" + self.makeProcessId(), \"wr\")\n                ujson.dump(self.bulk_prov, filep)\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\n                super(\n                                  ProvenancePE,\n                                  self).write(\n                                              OUTPUT_METADATA,\n                                              {'prov_cluster':self.prov_cluster,'provenance':deepcopy(self.bulk_prov)})\n            #self.bulk_prov[:]=[]\n\n        self._postprocess()\n\n    def prepareOutputStream(self, data, trace,port,**kwargs):\n        try:\n            streamtransfer = {}\n            streamtransfer['_d4p'] = data\n            #self.log(\"PROVON: \"+str(self.provon))\n            \n            try:\n\n\n                streamtransfer[\"prov_cluster\"] = self.prov_cluster\n                streamtransfer[\"port\"] = port\n                \n\n                if self.provon:\n                    \n                    #self.log(\"lnking Component trace\")\n                    streamtransfer['id'] = trace[\n                        'metadata'][\"streams\"][0][\"id\"]\n                    streamtransfer[\n                        \"TriggeredByProcessIterationID\"] = self.iterationId\n                    \n                    if port=='_d4p_state':\n                        #self.log(''' Building SELF Derivation '''+str(trace))\n                        self._updateState(kwargs['lookupterm'],trace[\n                        'metadata'][\"streams\"][0]['id'])\n                        streamtransfer['lookupterm']=kwargs['lookupterm']\n                        self.buildDerivation(streamtransfer,port='_d4p_state')\n                        \n                else:\n                    \n                    #self.log(\"Skip Component trace\")\n                    streamtransfer[\"id\"] = self.derivationIds[0][\"DerivedFromDatasetID\"]\n                    streamtransfer[\"TriggeredByProcessIterationID\"] = self.derivationIds[0][\"TriggeredByProcessIterationID\"]\n                    streamtransfer[\"up:assertionType\"] = \"up:Incomplete\"\n                    #self.log(streamtransfer)\n                    \n            except:\n                #self.log(traceback.format_exc())\n                pass\n            return streamtransfer\n\n        except Exception:\n            self.error += self.name + \" Writing output Error: %s\" % \\\n                traceback.format_exc()\n            raise\n\n    def preprocess(self):\n        if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n            self.provurl = urlparse(ProvenancePE.REPOS_URL)\n            #self.connection = httplib.HTTPConnection(\n            #                                         self.provurl.netloc)\n        self._preprocess()\n\n    def process(self, inputs):\n        self.feedbackIteration = False\n        self.void_invocation = True\n        self.iterationIndex += 1\n\n         \n        \n\n        if '_d4py_feedback' in inputs:\n\n            'state could be used here to track the occurring changes'\n            self.process_feedback(inputs['_d4py_feedback'])\n        else:\n            self.__processwrapper(inputs)\n\n        for x in inputs:\n            data=inputs[x]\n            if type(data)==dict and '_d4p' in data:\n                self.apply_derivation_rule('end_invocation_event',self.void_invocation,iport=x,data=data['_d4p'])   \n            else:\n                self.apply_derivation_rule('end_invocation_event',self.void_invocation,iport=x,data=data)  \n\n    def process_feedback(self, feedback):\n        self.feedbackIteration = True\n        self._process_feedback(feedback)\n\n    def removeDerivation(self,**kwargs):\n        if 'name' in kwargs:\n            id = self.getProvStateObjectId(kwargs['name'])\n            for j in self.derivationIds:\n\n                if j['DerivedFromDatasetID']==id:\n\n                    del self.derivationIds[self.derivationIds.index(j)]\n        else:\n            if 'port' in kwargs:\n                for j in self.derivationIds:\n\n                    if j['port']==kwargs['port']:\n\n                        del self.derivationIds[self.derivationIds.index(j)]\n\n    def sendProvToSensor(self, prov):\n        \n\n        self.bulk_prov.append(deepcopy(prov))\n\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\n            super(\n                                  ProvenancePE,\n                                  self).write(\n                                              OUTPUT_METADATA,\n                                              {'prov_cluster':self.prov_cluster,'provenance':deepcopy(self.bulk_prov)})\n\n             \n            self.bulk_prov[:]=[]\n\n        return None\n\n    def sendProvToService(self, prov):\n\n        #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\n\n        if isinstance(prov, list) and \"data\" in prov[0]:\n            prov = prov[0][\"data\"]\n\n        self.bulk_prov.append(deepcopy(prov))\n        \n        if len(self.bulk_prov) > ProvenancePE.BULK_SIZE:\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\n            params = urllib.urlencode({'prov': ujson.dumps(self.bulk_prov)})\n            headers = {\n                \"Content-type\": \"application\/x-www-form-urlencoded\",\n                \"Accept\": \"application\/json\"}\n            self.connection = httplib.HTTPConnection(\n                                                     self.provurl.netloc)\n            self.connection.request(\n                \"POST\", self.provurl.path, params, headers)\n            response = self.connection.getresponse()\n            #self.log(\"progress: \" + str((response.status, response.reason,response.read())))\n            #                             response, response.read())))\n\n            self.bulk_prov[:]=[]\n\n        return None\n\n    def setInputTypes(self, types):\n        '''\n        Sets the input types of this PE, in the form of a dictionary.\n        It is meant to be overridden, e.g. if output types depend on input.\n\n        .. note::\n\n            This method is always called before\n            :py:func:`~dispel4py.core.GenericPE.getOutputTypes`.\n\n        :param types: object types for each input stream\n        :type types: dictionary mapping input name to input type\n\n        Usage example::\n\n            pe.setInputTypes({'input1':['t1', 't2', 't3'], \\\n                              'input2':['t4', 't5']})\n        '''\n        pass\n\n    def setStateDerivations(self,terms):\n        self.stateDerivations=terms\n\n    def update_prov_state(\n            self,\n            lookupterm,\n            data,\n            location=\"\",\n            format=\"\",\n            metadata={},\n            ignore_inputs=False,\n            ignore_state=True,\n            stateless=False,\n            **kwargs\n    ):\n\n        self.endTime = datetime.datetime.utcnow()\n        self.stateful = True\n        self.ignore_inputs = ignore_inputs\n        self.ignore_state = ignore_state\n        self.addprov=True\n        kwargs['lookupterm']=lookupterm\n        #self.apply_derivation_rule('state', None)\n        if self.provon:\n            if data == None:\n                    self._updateState(lookupterm,self.derivationIds[len(self.derivationIds)-1][\"DerivedFromDatasetID\"])\n\n            else:\n                \n                if 'dep' in kwargs and kwargs['dep']!=None:\n                #self.removeDerivation(port='_d4p_state')\n                \n                    for d in kwargs['dep']:\n                        did=self.getProvStateObjectId(d)\n                    \n                        if did!=None:\n                            self.buildDerivation({'id':did,'TriggeredByProcessIterationID':self.iterationId,'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n                        #self.ignore_state = False\n                        #self.log(\"DERI \"+str(did))\n                        #self.log(\"DERI2 \"+str(self.derivationIds))\n                        #\n\n            \n                self.extractProvenance(data,\n                               location,\n                               format,\n                               metadata,\n                               output_port=\"_d4p_state\",\n                               **kwargs)\n\n         \n\n\n        self.ignore_inputs = False\n        self.ignore_state = False\n\n\n\n        if 'dep' in kwargs and kwargs['dep']!=None:\n            for d in kwargs['dep']:\n                self.removeDerivation(name=d)\n        \n\n        self.stateful  = False\n\n    def write(self, name, data, **kwargs):\n        self.void_invocation=False\n        dep = []\n\n        iport=None\n\n        for i in self.inputs:\n            iport=i\n\n        if 'metadata' in kwargs:\n            dep = self.apply_derivation_rule('write',True,oport=name,iport=iport,data=data,metadata=kwargs['metadata'])\n        else:\n            dep = self.apply_derivation_rule('write',True,oport=name,iport=iport,data=data)\n        \n        self.endTime = datetime.datetime.utcnow()\n\n       \n        \n        if 'dep' in kwargs and kwargs['dep']!=None: \n            for d in kwargs['dep']:\n                self.buildDerivation({'id':self.getProvStateObjectId(d),'TriggeredByProcessIterationID':self.iterationId, 'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n        elif len(self.stateDerivations) > 0:\n            for d in self.stateDerivations:\n                self.buildDerivation({'id':self.getProvStateObjectId(d),'TriggeredByProcessIterationID':self.iterationId, 'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n\n        if 'ignore_inputs' in kwargs:\n            self.ignore_inputs=kwargs['ignore_inputs']\n        \n       \n        \n        self.extractProvenance(data, output_port=name, **kwargs)\n\n        if 'dep' in kwargs and kwargs['dep']!=None:\n            for d in kwargs['dep']:\n                self.removeDerivation(name=d)\n        elif len(self.stateDerivations) > 0:\n            for d in self.stateDerivations:\n                self.removeDerivation(name=d)\n\n\n        self.stateDerivations=[]\n\n    def writeProvToFile(self, prov):\n        \n        if isinstance(prov, list) and \"data\" in prov[0]:\n            prov = prov[0][\"data\"]\n        \n         \n        #self.log('PROCESS: '+str(prov))\n        self.bulk_prov.append(prov)\n        \n        \n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\n            filep = open(\n                ProvenancePE.PROV_PATH +\n                \"\/bulk_\" +\n                self.makeProcessId(),\n                \"wr\")\n            #self.log('PROCESS: '+str(filep))\n            ujson.dump(self.bulk_prov, filep)\n            #filep.write(json.dumps(self.bulk_prov))\n            self.bulk_prov[:]=[]\n\n        return None\n\n    def writeResults(self, name, result):\n\n        #self.resetflow = True\n        self.apply_derivation_rule('write',True,data=result,oport=name)\n        self.void_invocation=False\n        \n        \n\n        if isinstance(result, dict) and '_d4p_prov' in result:\n            meta = result['_d4p_prov']\n            result = (result['_d4p_data'])\n\n            if 'error' in meta:\n                self.extractProvenance(result, output_port=name, **meta)\n            else:\n\n                self.extractProvenance(\n                    result, error=self.error, output_port=name, **meta)\n\n        else:\n            self.extractProvenance(result, error=self.error, output_port=name)\n\n","type":"(<class 'dispel4py.seismo.seismo.SeismoPE'>, <class 'test.misfit_processing.misfit_processing_prov.MergeImagesPE'>)","functionName":"MergeImagesPE"},"MisfitPE2":{"code":"    def __computewrapper(self, inputs):\n\n        try:\n            result = None\n\n            self.__markIteration()\n\n            if self.impcls is not None and isinstance(self, self.impcls):\n                try:\n                    if hasattr(self, 'params'):\n                        self.parameters = self.params\n                    result = self._process(inputs[self.impcls.INPUT_NAME])\n                    if result is not None:\n                        self.writeResults(self.impcls.OUTPUT_NAME, result)\n                except:\n                    result = self._process(inputs)\n            else:\n                result = self._process(inputs)\n\n            if result is not None:\n                return result\n\n        except Exception:\n            self.log(\" Compute Error: %s\" % traceback.format_exc())\n            self.error += \" Compute Error: %s\" % traceback.format_exc()\n            # self.endTime = datetime.datetime.utcnow()\n            self.writeResults('error', {'error': 'null'})\n\n    def __getUniqueId(self):\n        return socket.gethostname() + \"-\" + str(os.getpid()) + \\\n            \"-\" + str(uuid.uuid1())\n\n    def __importInputMetadata(self):\n        try:\n            self.inMetaStreams = self.input[\"metadata\"][\"streams\"]\n        except Exception:\n            None\n\n    def __markIteration(self):\n        self.startTime = datetime.datetime.utcnow()\n        self.iterationId = self.name + '-' + self.makeProcessId()\n\n    def __processwrapper(self, data):\n        try:\n\n            self.initParameters()\n\n            self.inputs = self.importInputData(data)\n            # self.__importInputMetadata()\n            return self.__computewrapper(self.inputs)\n\n        except:\n            self.log(traceback.format_exc())\n\n    def __init__(self,*args,**kwargs):\n        ProvenancePE.__init__(self,*args,**kwargs)\n        self.addNamespacePrefix(\"seis\",\"http:\/\/seis-prov.eu\/ns\/#\")\n\n    def _add_input(self, name, grouping=None, tuple_type=None):\n        '''\n        Declares an input for this PE.\n        This method may be used when initialising a PE instead of modifying\n        :py:attr:`~dispel4py.core.GenericPE.inputconnections` directly.\n\n        :param name: name of the input\n        :param grouping: the grouping type that this input expects (optional)\n        :param tuple_type: type of tuples accepted by this input (optional)\n        '''\n        self.inputconnections[name] = {NAME: name}\n        if grouping:\n            self.inputconnections[name][GROUPING] = grouping\n        if tuple_type:\n            self.inputconnections[name][TYPE] = tuple_type\n\n    def _add_output(self, name, tuple_type=None):\n        '''\n        Declares an output for this PE.\n        This method may be used when initialising a PE instead of modifying\n        :py:attr:`~dispel4py.core.GenericPE.outputconnections` directly.\n\n        :param name: name of the output\n        :param tuple_type: type of tuples produced by this output (optional)\n        '''\n        self.outputconnections[name] = {NAME: name}\n        if tuple_type:\n            self.outputconnections[name][TYPE] = tuple_type\n\n    def _postprocess(self):\n        None\n\n    def _preprocess(self):\n        self.instanceId = self.name + \"-Instance-\" + \\\n            \"-\" + self.makeProcessId()\n\n        super(ProvenancePE, self)._preprocess()\n\n    def _process(self, inputs):\n        self.log(\"In process Misfit\")\n        ip = inputs[\"input\"]\n\n        syn = ip[\"synthetic_trace\"]\n        obs = ip[\"data_trace\"]\n        param = ip[\"parameters\"]\n\n        self.log(\"Starting misfit %s, freqmin %s freqmax %s\" %\n                 (obs.id, param[\"min_period\"], param[\"max_period\"]))\n        nf = 100\n\n        # Plot.\n        fig = plotTfMisfits(\n            obs.data, syn.data,\n            dt=obs.stats.delta,\n            nf=nf,\n            fmin=1.0 \/ param[\"max_period\"],\n            fmax=1.0 \/ param[\"min_period\"],\n            w0=param[\"wavelet_parameter\"],\n            show=False)\n\n        # Calculate misfit values again.\n        pm_inf = pm(\n            obs.data, syn.data,\n            dt=obs.stats.delta,\n            nf=nf,\n            fmin=1.0 \/ param[\"max_period\"],\n            fmax=1.0 \/ param[\"min_period\"],\n            w0=param[\"wavelet_parameter\"])\n\n        em_inf = em(\n            obs.data, syn.data,\n            dt=obs.stats.delta,\n            nf=nf,\n            fmin=1.0 \/ param[\"max_period\"],\n            fmax=1.0 \/ param[\"min_period\"],\n            w0=param[\"wavelet_parameter\"])\n        data = ip[\"data_trace\"]\n        station_id = \"%s.%s\" % (data.stats.network,\n                                data.stats.station)\n        component = data.stats.channel[-1]\n\n        # Metadata for Alessandro!\n        meta = [{\n            \"type\": \"time_frequency_misfit\",\n            \"station_id\": station_id,\n            \"component\": component,\n            \"phase_misfit\": pm_inf,\n            \"envelope_misfit\": em_inf\n        }]\n\n     #   self.write(\"misfit_values\", {\n     #       \"record_type\": \"time_frequency_misfit\",\n     #       \"output_folder\": ip[\"output_folder\"],\n     #       \"station_id\": station_id,\n     #       \"component\": component,\n     #       \"phase_misfit\": pm_inf,\n     #       \"envelope_misfit\": em_inf},metadata=metadata)\n        \n        fig.suptitle(\"Component:\" + component, fontsize=15)\n        with io.BytesIO() as buf:\n            fig.savefig(buf)\n            buf.seek(0, 0)\n            # Not Python 3 compatible but who cares.\n            image_string = buf.read()\n        plt.close(fig)\n        image_type = \"time_frequency_misfit\"\n        self.write(\n            \"image\",\n            ({\"image_string\": image_string, \"component\": component,\n              \"output_folder\": ip[\"output_folder\"]},\n             image_type, station_id),metadata=meta)\n\n    def _updateState(self,name,id):\n        if name in self.stateCollection:\n                self.stateCollectionId.remove(self.stateCollection[name])\n        self.stateCollection[name]=id\n        self.stateCollectionId.append(id)\n\n    def _write(self, name, data, **kwargs):\n        '''\n        This writes the 'data' to the output pipe with name 'name' of this PE.\n        '''\n         \n        try:\n            output = self.outputconnections[name]\n            output[WRITER].write(data)\n        except KeyError:\n            raise Exception(\"Can't write data: Unknown output connection\\\n                            '%s' for PE '%s'\" % (name, type(self).__name__))\n\n    def addNamespacePrefix(self,prefix,url):\n        self.ns.update({prefix:url})\n\n    def apply_derivation_rule(self,event,voidInvocation,oport=None,iport=None,data=None,metadata=None):\n        \n        if (event=='end_invocation_event') and voidInvocation==True:\n            self.discardInFlow(discardState=True)\n        \n        if (event=='end_invocation_event') and voidInvocation==False:\n            self.discardInFlow(discardState=True)\n\n    def buildDerivation(self, data, port=\"\"):\n        \n        if data!=None and 'id' in data:\n\n            derivation = {'port': port, \n                          'DerivedFromDatasetID': data['id'], \n                          'TriggeredByProcessIterationID': data['TriggeredByProcessIterationID'], \n                          'prov_cluster': data['prov_cluster'],\n                          'iterationIndex':self.iterationIndex,\n                          \n\n\n\n                          }\n                          \n            if port==\"_d4p_state\": \n                derivation.update({'lookupterm':data['lookupterm']})\n                 \n\t\t    \n            if \"up:assertionType\" in data:\n                derivation.update({\"up:assertionType\":data[\"up:assertionType\"]})\n\n\n\n            self.derivationIds.append(derivation)\n\n        else:\n            \n            id=self.extractDataSourceId(data,port)\n            #traceback.print_exc(file=sys.stderr)\n            derivation = {'port': port, 'DerivedFromDatasetID':\n                          id, 'TriggeredByProcessIterationID':\n                          None, 'prov_cluster':\n                          None,\n                          'iterationIndex':self.iterationIndex\n                          }\n            self.derivationIds.append(derivation)\n            self.log(\"BUILDING INITIAL DERIVATION\")\n\n    def buildUserMetadata(self, data, **kwargs):\n        streamlist = list()\n\n        streamItem = {}\n        streammeta = []\n        settransfer=False\n        streammeta = self.extractItemMetadata(data,kwargs['output_port'])\n        \n        if not isinstance(streammeta, list):\n            streammeta = kwargs['metadata'] if isinstance(\n                kwargs['metadata'], list) else [kwargs['metadata']]\n        elif isinstance(streammeta, list):\n            try:\n                if isinstance(kwargs['metadata'], list):\n                    streammeta = streammeta + kwargs['metadata']\n                if isinstance(kwargs['metadata'], dict):\n                    for y in streammeta:\n                        y.update(kwargs['metadata'])\n            except:\n                traceback.print_exc(file=sys.stderr)\n                None\n        \n        if self.sel_rules!=None:\n            self.provon=self.checkSelectiveRule(streammeta)\n\n       \n        if not self.provon:\n            return streamItem\n        #self.log(kwargs)\n        streamItem.update({\"content\": streammeta,\n                           \"id\": self.getUniqueId(data,kwargs['output_port'],**kwargs),\n                           \"format\": \"\",\n                           \"location\": \"\",\n                           \"annotations\": [],\n                           \"port\": kwargs['output_port']})\n        # if (self.streamItemsControl!={,:\n        streamItem.update(kwargs['control'])\n        # if (self.streamItemsLocations!={,:\n        streamItem.update({\"location\": kwargs['location'],\n                          \"format\": kwargs['format']})\n        streamItem.update({\"size\": total_size(data)})\n        #streamItem.update({\"size\": 0})\n\n        if self.transfer_rules!=None:\n            settransfer=self.checkTransferRule(streammeta)\n\n\n        if settransfer:\n            streamItem[\"s-prov:immediateAccess\"]=True\n            streamItem[\"s-prov:first-known-destination\"]=self.transfer_rules[\"destination\"]\n\n        \n        \n        streamlist.append(streamItem)\n        return streamlist\n\n    def checkSelectiveRule(self,streammeta):\n        self.log(\"Checking Skip-Rules: \"+str(self.sel_rules))\n        rules=self.sel_rules[\"rules\"]\n\n        for key in rules:\n\n                for s in streammeta:\n                    if key in s: \n                        #self.log(\"A\"+str(self.sel_rules[key]))\n                        self.log(s[key]) \n                        self.log(type(s[key]))\n                         \n                        if '$eq' in rules[key] and s[key]==rules[key]['$eq']:\n                            return True\n                        elif '$gt' in rules[key] and '$lt' in rules[key]:\n                            if (s[key]>rules[key]['$gt'] and s[key]<rules[key]['$lt']):\n                                self.log(\"GT-LT\") \n                                return True\n                            else:\n                                return False\n                        elif '$gt' in rules[key] and s[key]>rules[key]['$gt']:\n                            self.log(\"GT\") \n                            return True\n                        elif '$lt' in rules[key] and s[key]<rules[key]['$lt']:\n                            self.log(\"LT\") \n                            return True\n                        else:\n                            return False\n        return self.provon\n\n    def checkTransferRule(self,streammeta):\n        self.log(\"Checking Transfer-Rules\")\n        for key in self.transfer_rules[\"rules\"]:\n                for s in streammeta:\n                    if key in s: \n                        #self.log(\"A\"+str(self.sel_rules[key]))\n                        self.log(s[key]) \n                        self.log(type(s[key]))\n                        \n                        if '$eq' in self.transfer_rules[\"rules\"][key] and s[key]==self.transfer_rules[\"rules\"][key]['$eq']:\n                             \n                            return True\n                        elif '$gt' in self.transfer_rules[\"rules\"][key] and '$lt' in self.transfer_rules[\"rules\"][key]:\n                            if (s[key]>self.transfer_rules[\"rules\"][key]['$gt'] and s[key]<self.transfer_rules[\"rules\"][key]['$lt']):\n                                self.log(\"GT-LT\")\n                                 \n                                return True\n                        elif '$gt' in self.transfer_rules[\"rules\"][key] and s[key]>self.transfer_rules[\"rules\"][key]['$gt']:\n                            self.log(\"GT\") \n                            \n                            return True\n                        elif '$lt' in self.transfer_rules[\"rules\"][key] and s[key]<self.transfer_rules[\"rules\"][key]['$lt']:\n                            self.log(\"LT\")\n                            \n                            return True\n                        else:\n                            return False\n        return False\n\n    def dicToKeyVal(self, dict, valueToString=False):\n        try:\n            alist = list()\n            for k, v in dict.iteritems():\n                adic = {}\n                adic.update({\"key\": str(k)})\n                if valueToString:\n                    adic.update({\"val\": str(v)})\n                else:\n\n                    try:\n                        v = num(v)\n                        adic.update({\"val\": v})\n                    except Exception:\n                        adic.update({\"val\": str(v)})\n\n                alist.append(adic)\n\n            return alist\n        except Exception as err:\n\n            self.error += self.name + \" dicToKeyVal output Error: \" + str(err)\n            sys.stderr.write(\n                'ERROR: ' +\n                self.name +\n                ' dicToKeyVal output Error: ' +\n                str(err))\n#                self.map.put(\"output\",\"\");\n            traceback.print_exc(file=sys.stderr)\n\n    def discardInFlow(self,wlength=None,discardState=False): \n        #self.log('BEFORE '+str(self.derivationIds))\n        \n        \n        if discardState==True:\n            if wlength==None:\n            #self.log(\"discarding\")\n                self.derivationIds=[]\n            else:\n                count=0\n                for x in self.derivationIds:\n                    if x!=None and x['port']!='_d4p_state' and count>=wlength-1:\n                        self.derivationIds.remove(x)\n                    count+=1\n                for x in self.derivationIds:\n                    if x!=None and x['port']=='_d4p_state':\n                        self.derivationIds.remove(x)\n                        \n\n\n\n        else:\n            maxit=0\n            state=None\n            #self.log(\"BEFORE\" +str(self.derivationIds))\n            for x in self.derivationIds:\n                 \n                if x!=None and x['port']=='_d4p_state' and x['iterationIndex']>=maxit:\n                    \n                    state=x\n                    maxit=x['iterationIndex']\n            \n            if wlength==None:\n                if state!=None:   \n                    self.derivationIds=[state]\n                else:\n                    self.derivationIds=[]\n            else:\n                count=0\n                for x in self.derivationIds:\n                    #self.log(\"COUNT: \"+str(count)+\" WLENTGH: \"+str(wlength))\n                    if x!=None and x['port']!='_d4p_state' and count>=wlength-1:\n                        #self.log(\"REMOVE: \"+str(x['iterationIndex']))\n                        del self.derivationIds[0]   \n                    count+=1\n\n               \n\n                if state!=None: \n                    self.derivationIds.append(state)\n\n    def discardState(self): \n        #self.log('BEFORE '+str(self.derivationIds))\n        \n        \n        derivations = [x for x in self.derivationIds if x['port']!='_d4p_state']\n        \n        self.derivationIds=derivations\n\n    def extractDataSourceId(self,data,port):\n        self.makeUniqueId(data,port)\n\n    def extractItemMetadata(self,data,port):\n        try:\n               \n            st=[]\n             \n            if type(data) == Trace:\n                st.append(data)\n                \n            elif type(data)==tuple:\n                for x in data:\n                    if type(x)==Stream:\n                        st=x\n            else:\n                st=data\n            streammeta=list()\n            for tr in st:\n                \n                metadic={}\n                metadic.update({\"prov:type\":\"waveform\"});    \n                metadic.update({\"id\":str(uuid.uuid1())});\n                \n                for attr, value in tr.stats.__dict__.iteritems():\n                    \n                    if attr==\"mseed\":\n                        mseed={}\n                        for a,v in value.__dict__.iteritems():\n                            try:\n                                if type(v)==UTCDateTime:\n                                    mseed.update({a:str(v)});\n                                else:\n                                    mseed.update({a:float(v)});\n                            except Exception,e:\n                                mseed.update({a:str(v)});\n                        metadic.update({\"mseed\":mseed});\n                    else:\n                        try:\n                            if type(value)==UTCDateTime:\n                                metadic.update({attr:str(value)});\n                            else:\n                                metadic.update({attr:float(value)});\n                        except Exception,e:\n                            metadic.update({attr:str(value)});\n                \n                streammeta.append(metadic);\n            \n            return streammeta   \n        except Exception, err:\n            self.log(\"Applying default metadata extraction\")\n            #self.error=self.error+\"Extract Metadata error: \"+str(traceback.format_exc())\n            return super(SeismoPE, self).extractItemMetadata(data,port);\n\n    def extractProvenance(\n            self,\n            data,\n            location=\"\",\n            format=\"\",\n            metadata={},\n            control={},\n            attributes={},\n            error=\"\",\n            output_port=\"\",\n            **kwargs):\n\n        self.error = error\n\n        if metadata==None:\n            metadata={}\n        elif isinstance(metadata, list):\n            metadata.append(attributes)\n        else:\n            metadata.update(attributes)\n\n        usermeta = {}\n\n        if 's-prov:skip' in control and bool(control['s-prov:skip']):\n            self.provon = False\n        else:\n            self.provon = True\n            usermeta= self.buildUserMetadata(\n                data,\n                location=location,\n                format=format,\n                metadata=metadata,\n                control=control,\n                attributes=attributes,\n                error=error,\n                output_port=output_port,\n                **kwargs)\n        \n         \n        \n        self.flushData(data, usermeta, output_port,**kwargs)\n\n        return usermeta\n\n    def flushData(self, data, metadata, port,**kwargs):\n        trace = {}\n        stream = data\n        try:\n            if self.provon:\n                self.endTime = datetime.datetime.utcnow()\n                trace = self.packageAll(metadata)\n            \n            stream = self.prepareOutputStream(data, trace, port,**kwargs)\n              \n            try:\n                if port is not None and port != '_d4p_state' \\\n                        and port != 'error':\n\n                    super(ProvenancePE, self).write(port, stream)\n#stream)\n\n            except:\n                self.log(traceback.format_exc())\n                'if cant write doesnt matter move on'\n                pass\n            try:\n                if self.provon:\n                    if (ProvenancePE.send_prov_to_sensor==True) or (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\n\n                            self.sendProvToSensor(trace['metadata'])\n                            \n                            \n                            #super(\n                            #      ProvenancePE,\n                            #      self).write(\n                            #                  OUTPUT_METADATA,\n                            #                  deepcopy(trace['metadata']))\n                            \n\n                    if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n                        \n                        self.sendProvToService(trace['metadata'])\n                    if self.save_mode==ProvenancePE.SAVE_MODE_FILE:\n                         self.writeProvToFile(trace['metadata'])\n                     \n            except:\n                self.log(traceback.format_exc())\n                'if cant write doesnt matter move on'\n                pass\n\n            return True\n\n        except Exception:\n            self.log(traceback.format_exc())\n            if self.provon:\n                self.error += \" FlushChunk Error: %s\" % traceback.format_exc()\n\n    def getDataStreams(self, inputs):\n        streams = {}\n        for inp in self.inputconnections:\n            if inp not in inputs:\n                continue\n            values = inputs[inp]\n            if isinstance(values, list):\n                data = values[0:]\n            else:\n                data = values\n            streams[\"streams\"].update({inp: data})\n        return streams\n\n    def getInputAt(self, port=\"input\", index=None):\n        if index==None:\n            return self.inputs[port]\n        else:\n            return self.inputs[port][index]\n\n    def getOutputTypes(self):\n        '''\n        Returns the output types of this PE, in the form of a dictionary.\n        This method may be overridden if output types are not static and\n        depend on input types.\n\n        .. note::\n\n            This method is only called after the input types have been\n            initialised in :py:func:`~dispel4py.core.GenericPE.setInputTypes`.\n\n        :rtype: a dictionary mapping each output name to its type\n\n        By default it returns a dictionary of the types defined in the\n        'outputconnections' instance variable.\n\n        Usage example::\n\n            def getOutputTypes(self):\n                output = { 'output1' : myInputs['input1'],\n                           'output2' : [ 'comment' ] }\n\n        '''\n        ret = {}\n        # print '%s: %s' % (self.id, self.outputconnections)\n        for name, output in self.outputconnections.items():\n            try:\n                ret[name] = output[TYPE]\n            except KeyError:\n                raise Exception(\"%s: No output type defined for '%s'\"\n                                % (self.id, name))\n        return ret\n\n    def getProvStateObjectId(self,name):\n        if name in self.stateCollection:\n            return self.stateCollection[name]\n        else:\n            return None\n\n    def getUniqueId(self,data,port,**kwargs):\n        data_id = self.makeUniqueId(data,port)\n        if 'name' in kwargs:\n            self._updateState(kwargs['name'],data_id)\n\n\n\n        return data_id\n\n    def ignorePastFlow(self):\n        self.ignore_past_flow=True\n\n    def ignoreState(self):\n        self.ignore_state=True\n\n    def importInputData(self, data):\n\n        inputs = {}\n\n        try:\n            if not isinstance(data, collections.Iterable):\n                return data\n            else:\n                for x in data:\n                    #self.log(data[x])\n                    self.buildDerivation(data[x], port=x)\n                    if type(data[x])==dict and '_d4p' in data[x]:\n                        inputs[x] = data[x]['_d4p']\n                    else:\n                        inputs[x] = data[x]\n                return inputs\n\n        except Exception:\n            self.output = \"\"\n            self.error += \"Reading Input Error: %s\" % traceback.format_exc()\n            raise\n\n    def initParameters(self):\n\n        self.error = ''\n        self.w3c_prov = {}\n        #self.resetflow = True\n        self.inMetaStreams = None\n        self.username = None\n        self.runId = None\n\n\n        try:\n                # self.iterationId = self.name + '-' + getUniqueId()\n            if \"username\" in self.controlParameters:\n                self.username = self.controlParameters[\"username\"]\n            if \"runId\" in self.controlParameters:\n                self.runId = self.controlParameters[\"runId\"]\n\n        except:\n                self.runId = \"\"\n                pass\n\n        self.outputdest = self.controlParameters[\n            'outputdest'] if 'outputdest' in self.controlParameters else 'None'\n        self.rootpath = self.controlParameters[\n            'inputrootpath'] \\\n            if 'inputrootpath' in self.controlParameters else 'None'\n        self.outputid = self.controlParameters[\n            'outputid'] \\\n            if 'outputid' in self.controlParameters else 'None'\n\n    def makeProcessId(self, **kwargs):\n        \n        return socket.gethostname() + \"-\" + \\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\n\n    def makeUniqueId(self,data,port):\n        #if ('data' in kwargs):\n        #    self.log(str(kwargs['data']))\n        \n        return socket.gethostname() + \"-\" + \\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\n\n    def packageAll (self, contentmeta):\n        metadata = {}\n        if self.provon:\n            try:\n\n                # identifies the actual iteration over the instance\n                metadata.update({'iterationId': self.iterationId,\n                # identifies the actual writing process'\n                'actedOnBehalfOf': self.behalfOf,\n                '_id': self.id + '_write_' + str(self.makeProcessId()),\n                'iterationIndex': self.iterationIndex,\n                'instanceId': self.instanceId,\n                'annotations': {}})\n\n                if self.feedbackIteration:\n                    metadata.update(\n                        {'_id': self.id + '_feedback_' + str(self.makeProcessId())})\n                elif self.stateful:\n                    metadata.update(\n                        {'_id': self.id + '_stateful_' + str(self.makeProcessId())})\n\n                else:\n                    metadata.update(\n                        {'_id': self.id + '_write_' + str(self.makeProcessId())})\n\n\n                metadata.update({'stateful': not self.resetflow,\n                'feedbackIteration': self.feedbackIteration,\n                'worker': socket.gethostname(),\n                'parameters': self.parameters,\n                'errors': self.error,\n                'pid': '%s' % os.getpid()})\n\n\n                 \n                if self.ignore_inputs==True:\n                    derivations = [x for x in self.derivationIds if x['port']=='_d4p_state' and x['DerivedFromDatasetID'] in self.stateCollectionId]\n                    metadata.update({'derivationIds': derivations})\n                    self.ignore_inputs = False\n                    \n                elif self.ignore_past_flow==True:\n                     \n                    derivations = [x for x in self.derivationIds if (x['iterationIndex'] == self.iterationIndex or x['port']=='_d4p_state')]\n                    metadata.update({'derivationIds': derivations})\n                    #self.log(\"IGNOREPAST \"+str(derivations))\n\n                elif self.ignore_state==True:\n                    \n                    derivations = [x for x in self.derivationIds if x['port']!='_d4p_state']\n                    metadata.update({'derivationIds': derivations})\n                    #self.log(\"In package \"+str(self.derivationIds))\n                    #self.ignore_past_flow = False\n                else:\n                     \n                    metadata.update({'derivationIds': self.derivationIds})\n                    self.ignore_past_flow = False\n\n\n                metadata.update({'name': self.name,\n                'runId': self.runId,\n                'username': self.username,\n                'startTime': str(self.startTime),\n                'endTime': str(self.endTime),\n                'type': 'lineage',\n\n                'streams': contentmeta,\n                'mapping': sys.argv[1]})\n                \n                if hasattr(self, 'prov_cluster'):\n                     \n                    metadata.update({'prov_cluster': self.prov_cluster})\n                \n\n                if self.creator is not None:\n                    metadata.update({'creator': self.creator})\n            except Exception:\n                self.error += \" Packaging Error: %s\" % traceback.format_exc()\n                self.log(traceback.format_exc())\n\n        output = {\n            \"metadata\": metadata,\n            \"error\": self.error,\n            #\"pid\": \"%s\" %\n            #os.getpid()\n             }\n\n\n        return output\n\n    def pe_init(self, *args, **kwargs):\n        #ProvenancePE.__init__(self,*args, **kwargs)\n\n        global _d4p_plan_sqn\n        self._add_input('_d4py_feedback', grouping='all')\n        self.stateCollection={}\n        self.stateCollectionId=[]\n        self.impcls = None\n        self.bulk_prov = []\n        self.stateful=False\n        self.stateDerivations=[]\n\n\n        if 'pe_class' in kwargs and kwargs['pe_class'] != GenericPE:\n            self.impcls = kwargs['pe_class']\n       \n        if 'sel_rules' in kwargs and self.name in kwargs['sel_rules']:\n            print(self.name+\" \"+str(kwargs['sel_rules'][self.name]))\n            self.sel_rules = kwargs['sel_rules'][self.name]\n        else:\n            self.sel_rules=None\n        \n        if 'transfer_rules' in kwargs and self.name in kwargs['transfer_rules']:\n            print(self.name+\" \"+str(kwargs['transfer_rules'][self.name]))\n            self.transfer_rules = kwargs['transfer_rules'][self.name]\n        else:\n            self.transfer_rules=None\n\n\n        if 'creator' not in kwargs:\n            self.creator = None\n        else:\n            self.creator = kwargs['creator']\n\n        self.error = ''\n\n        if not hasattr(self, 'parameters'):\n            self.parameters = {}\n        if not hasattr(self, 'controlParameters'):\n            self.controlParameters = {}\n\n        if 'controlParameters' in kwargs:\n            self.controlParameters = kwargs['controlParameters']\n\n        out_md = {}\n        out_md[NAME] = OUTPUT_METADATA\n\n        # self.outputconnections[OUTPUT_DATA] = out1\n        #print(OUTPUT_METADATA)\n        self._add_output(OUTPUT_METADATA)\n        ##self.outputconnections[OUTPUT_METADATA] = out_md\n        self.taskId = str(uuid.uuid1())\n\n        # self.appParameters = None\n        self.provon = True\n        \n\n        if 'save_mode' not in kwargs:\n            self.save_mode=ProvenancePE.SAVE_MODE_FILE\n        else:\n            self.save_mode=SAVE_MODE_FILE = kwargs['save_mode']\n\n        self.wcount=0\n        self.resetflow = False\n        self.stateUpdateIndex=0\n        self.ignore_inputs = False\n        self.ignore_state=False\n        self.ignore_past_flow = False\n        self.derivationIds = list()\n        self.iterationIndex = 0\n        \n        #name + '_' + str(_d4p_plan_sqn)\n        _d4p_plan_sqn = _d4p_plan_sqn + 1\n        self.countstatewrite=0\n        if not hasattr(self, 'comp_id'):\n            self.behalfOf=self.id\n        else:\n            self.behalfOf=self.comp_id\n        if not hasattr(self, 'prov_cluster'):\n            self.prov_cluster=self.behalfOf\n\n    def postprocess(self):\n\n        \n        if len(self.bulk_prov)>0:\n            \n            if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n                #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\n                params = urllib.urlencode({'prov': ujson.dumps(self.bulk_prov)})\n                headers = {\n                       \"Content-type\": \"application\/x-www-form-urlencoded\",\n                       \"Accept\": \"application\/json\"}\n                self.connection = httplib.HTTPConnection(\n                                                     self.provurl.netloc)\n                self.connection.request(\n                                    \"POST\",\n                                    self.provurl.path,\n                                    params,\n                                    headers)\n                response = self.connection.getresponse()\n                self.log(\"Postprocess: \" +\n                     str((response.status, response.reason, response.read())))\n#                    response.read())))\n                self.connection.close()\n                self.bulk_prov[:]=[]\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_FILE):\n                filep = open(ProvenancePE.PROV_PATH + \"\/bulk_\" + self.makeProcessId(), \"wr\")\n                ujson.dump(self.bulk_prov, filep)\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\n                super(\n                                  ProvenancePE,\n                                  self).write(\n                                              OUTPUT_METADATA,\n                                              {'prov_cluster':self.prov_cluster,'provenance':deepcopy(self.bulk_prov)})\n            #self.bulk_prov[:]=[]\n\n        self._postprocess()\n\n    def prepareOutputStream(self, data, trace,port,**kwargs):\n        try:\n            streamtransfer = {}\n            streamtransfer['_d4p'] = data\n            #self.log(\"PROVON: \"+str(self.provon))\n            \n            try:\n\n\n                streamtransfer[\"prov_cluster\"] = self.prov_cluster\n                streamtransfer[\"port\"] = port\n                \n\n                if self.provon:\n                    \n                    #self.log(\"lnking Component trace\")\n                    streamtransfer['id'] = trace[\n                        'metadata'][\"streams\"][0][\"id\"]\n                    streamtransfer[\n                        \"TriggeredByProcessIterationID\"] = self.iterationId\n                    \n                    if port=='_d4p_state':\n                        #self.log(''' Building SELF Derivation '''+str(trace))\n                        self._updateState(kwargs['lookupterm'],trace[\n                        'metadata'][\"streams\"][0]['id'])\n                        streamtransfer['lookupterm']=kwargs['lookupterm']\n                        self.buildDerivation(streamtransfer,port='_d4p_state')\n                        \n                else:\n                    \n                    #self.log(\"Skip Component trace\")\n                    streamtransfer[\"id\"] = self.derivationIds[0][\"DerivedFromDatasetID\"]\n                    streamtransfer[\"TriggeredByProcessIterationID\"] = self.derivationIds[0][\"TriggeredByProcessIterationID\"]\n                    streamtransfer[\"up:assertionType\"] = \"up:Incomplete\"\n                    #self.log(streamtransfer)\n                    \n            except:\n                #self.log(traceback.format_exc())\n                pass\n            return streamtransfer\n\n        except Exception:\n            self.error += self.name + \" Writing output Error: %s\" % \\\n                traceback.format_exc()\n            raise\n\n    def preprocess(self):\n        if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n            self.provurl = urlparse(ProvenancePE.REPOS_URL)\n            #self.connection = httplib.HTTPConnection(\n            #                                         self.provurl.netloc)\n        self._preprocess()\n\n    def process(self, inputs):\n        self.feedbackIteration = False\n        self.void_invocation = True\n        self.iterationIndex += 1\n\n         \n        \n\n        if '_d4py_feedback' in inputs:\n\n            'state could be used here to track the occurring changes'\n            self.process_feedback(inputs['_d4py_feedback'])\n        else:\n            self.__processwrapper(inputs)\n\n        for x in inputs:\n            data=inputs[x]\n            if type(data)==dict and '_d4p' in data:\n                self.apply_derivation_rule('end_invocation_event',self.void_invocation,iport=x,data=data['_d4p'])   \n            else:\n                self.apply_derivation_rule('end_invocation_event',self.void_invocation,iport=x,data=data)  \n\n    def process_feedback(self, feedback):\n        self.feedbackIteration = True\n        self._process_feedback(feedback)\n\n    def removeDerivation(self,**kwargs):\n        if 'name' in kwargs:\n            id = self.getProvStateObjectId(kwargs['name'])\n            for j in self.derivationIds:\n\n                if j['DerivedFromDatasetID']==id:\n\n                    del self.derivationIds[self.derivationIds.index(j)]\n        else:\n            if 'port' in kwargs:\n                for j in self.derivationIds:\n\n                    if j['port']==kwargs['port']:\n\n                        del self.derivationIds[self.derivationIds.index(j)]\n\n    def sendProvToSensor(self, prov):\n        \n\n        self.bulk_prov.append(deepcopy(prov))\n\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\n            super(\n                                  ProvenancePE,\n                                  self).write(\n                                              OUTPUT_METADATA,\n                                              {'prov_cluster':self.prov_cluster,'provenance':deepcopy(self.bulk_prov)})\n\n             \n            self.bulk_prov[:]=[]\n\n        return None\n\n    def sendProvToService(self, prov):\n\n        #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\n\n        if isinstance(prov, list) and \"data\" in prov[0]:\n            prov = prov[0][\"data\"]\n\n        self.bulk_prov.append(deepcopy(prov))\n        \n        if len(self.bulk_prov) > ProvenancePE.BULK_SIZE:\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\n            params = urllib.urlencode({'prov': ujson.dumps(self.bulk_prov)})\n            headers = {\n                \"Content-type\": \"application\/x-www-form-urlencoded\",\n                \"Accept\": \"application\/json\"}\n            self.connection = httplib.HTTPConnection(\n                                                     self.provurl.netloc)\n            self.connection.request(\n                \"POST\", self.provurl.path, params, headers)\n            response = self.connection.getresponse()\n            #self.log(\"progress: \" + str((response.status, response.reason,response.read())))\n            #                             response, response.read())))\n\n            self.bulk_prov[:]=[]\n\n        return None\n\n    def setInputTypes(self, types):\n        '''\n        Sets the input types of this PE, in the form of a dictionary.\n        It is meant to be overridden, e.g. if output types depend on input.\n\n        .. note::\n\n            This method is always called before\n            :py:func:`~dispel4py.core.GenericPE.getOutputTypes`.\n\n        :param types: object types for each input stream\n        :type types: dictionary mapping input name to input type\n\n        Usage example::\n\n            pe.setInputTypes({'input1':['t1', 't2', 't3'], \\\n                              'input2':['t4', 't5']})\n        '''\n        pass\n\n    def setStateDerivations(self,terms):\n        self.stateDerivations=terms\n\n    def update_prov_state(\n            self,\n            lookupterm,\n            data,\n            location=\"\",\n            format=\"\",\n            metadata={},\n            ignore_inputs=False,\n            ignore_state=True,\n            stateless=False,\n            **kwargs\n    ):\n\n        self.endTime = datetime.datetime.utcnow()\n        self.stateful = True\n        self.ignore_inputs = ignore_inputs\n        self.ignore_state = ignore_state\n        self.addprov=True\n        kwargs['lookupterm']=lookupterm\n        #self.apply_derivation_rule('state', None)\n        if self.provon:\n            if data == None:\n                    self._updateState(lookupterm,self.derivationIds[len(self.derivationIds)-1][\"DerivedFromDatasetID\"])\n\n            else:\n                \n                if 'dep' in kwargs and kwargs['dep']!=None:\n                #self.removeDerivation(port='_d4p_state')\n                \n                    for d in kwargs['dep']:\n                        did=self.getProvStateObjectId(d)\n                    \n                        if did!=None:\n                            self.buildDerivation({'id':did,'TriggeredByProcessIterationID':self.iterationId,'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n                        #self.ignore_state = False\n                        #self.log(\"DERI \"+str(did))\n                        #self.log(\"DERI2 \"+str(self.derivationIds))\n                        #\n\n            \n                self.extractProvenance(data,\n                               location,\n                               format,\n                               metadata,\n                               output_port=\"_d4p_state\",\n                               **kwargs)\n\n         \n\n\n        self.ignore_inputs = False\n        self.ignore_state = False\n\n\n\n        if 'dep' in kwargs and kwargs['dep']!=None:\n            for d in kwargs['dep']:\n                self.removeDerivation(name=d)\n        \n\n        self.stateful  = False\n\n    def write(self, name, data, **kwargs):\n        self.void_invocation=False\n        dep = []\n\n        iport=None\n\n        for i in self.inputs:\n            iport=i\n\n        if 'metadata' in kwargs:\n            dep = self.apply_derivation_rule('write',True,oport=name,iport=iport,data=data,metadata=kwargs['metadata'])\n        else:\n            dep = self.apply_derivation_rule('write',True,oport=name,iport=iport,data=data)\n        \n        self.endTime = datetime.datetime.utcnow()\n\n       \n        \n        if 'dep' in kwargs and kwargs['dep']!=None: \n            for d in kwargs['dep']:\n                self.buildDerivation({'id':self.getProvStateObjectId(d),'TriggeredByProcessIterationID':self.iterationId, 'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n        elif len(self.stateDerivations) > 0:\n            for d in self.stateDerivations:\n                self.buildDerivation({'id':self.getProvStateObjectId(d),'TriggeredByProcessIterationID':self.iterationId, 'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n\n        if 'ignore_inputs' in kwargs:\n            self.ignore_inputs=kwargs['ignore_inputs']\n        \n       \n        \n        self.extractProvenance(data, output_port=name, **kwargs)\n\n        if 'dep' in kwargs and kwargs['dep']!=None:\n            for d in kwargs['dep']:\n                self.removeDerivation(name=d)\n        elif len(self.stateDerivations) > 0:\n            for d in self.stateDerivations:\n                self.removeDerivation(name=d)\n\n\n        self.stateDerivations=[]\n\n    def writeProvToFile(self, prov):\n        \n        if isinstance(prov, list) and \"data\" in prov[0]:\n            prov = prov[0][\"data\"]\n        \n         \n        #self.log('PROCESS: '+str(prov))\n        self.bulk_prov.append(prov)\n        \n        \n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\n            filep = open(\n                ProvenancePE.PROV_PATH +\n                \"\/bulk_\" +\n                self.makeProcessId(),\n                \"wr\")\n            #self.log('PROCESS: '+str(filep))\n            ujson.dump(self.bulk_prov, filep)\n            #filep.write(json.dumps(self.bulk_prov))\n            self.bulk_prov[:]=[]\n\n        return None\n\n    def writeResults(self, name, result):\n\n        #self.resetflow = True\n        self.apply_derivation_rule('write',True,data=result,oport=name)\n        self.void_invocation=False\n        \n        \n\n        if isinstance(result, dict) and '_d4p_prov' in result:\n            meta = result['_d4p_prov']\n            result = (result['_d4p_data'])\n\n            if 'error' in meta:\n                self.extractProvenance(result, output_port=name, **meta)\n            else:\n\n                self.extractProvenance(\n                    result, error=self.error, output_port=name, **meta)\n\n        else:\n            self.extractProvenance(result, error=self.error, output_port=name)\n\n","type":"(<class 'dispel4py.seismo.seismo.SeismoPE'>, <class 'test.misfit_processing.misfit_processing_prov.MisfitPE'>)","functionName":"MisfitPE"},"PyflexPE1":{"code":"    def __computewrapper(self, inputs):\n\n        try:\n            result = None\n\n            self.__markIteration()\n\n            if self.impcls is not None and isinstance(self, self.impcls):\n                try:\n                    if hasattr(self, 'params'):\n                        self.parameters = self.params\n                    result = self._process(inputs[self.impcls.INPUT_NAME])\n                    if result is not None:\n                        self.writeResults(self.impcls.OUTPUT_NAME, result)\n                except:\n                    result = self._process(inputs)\n            else:\n                result = self._process(inputs)\n\n            if result is not None:\n                return result\n\n        except Exception:\n            self.log(\" Compute Error: %s\" % traceback.format_exc())\n            self.error += \" Compute Error: %s\" % traceback.format_exc()\n            # self.endTime = datetime.datetime.utcnow()\n            self.writeResults('error', {'error': 'null'})\n\n    def __getUniqueId(self):\n        return socket.gethostname() + \"-\" + str(os.getpid()) + \\\n            \"-\" + str(uuid.uuid1())\n\n    def __importInputMetadata(self):\n        try:\n            self.inMetaStreams = self.input[\"metadata\"][\"streams\"]\n        except Exception:\n            None\n\n    def __markIteration(self):\n        self.startTime = datetime.datetime.utcnow()\n        self.iterationId = self.name + '-' + self.makeProcessId()\n\n    def __processwrapper(self, data):\n        try:\n\n            self.initParameters()\n\n            self.inputs = self.importInputData(data)\n            # self.__importInputMetadata()\n            return self.__computewrapper(self.inputs)\n\n        except:\n            self.log(traceback.format_exc())\n\n    def __init__(self,*args,**kwargs):\n        ProvenancePE.__init__(self,*args,**kwargs)\n        self.addNamespacePrefix(\"seis\",\"http:\/\/seis-prov.eu\/ns\/#\")\n\n    def _add_input(self, name, grouping=None, tuple_type=None):\n        '''\n        Declares an input for this PE.\n        This method may be used when initialising a PE instead of modifying\n        :py:attr:`~dispel4py.core.GenericPE.inputconnections` directly.\n\n        :param name: name of the input\n        :param grouping: the grouping type that this input expects (optional)\n        :param tuple_type: type of tuples accepted by this input (optional)\n        '''\n        self.inputconnections[name] = {NAME: name}\n        if grouping:\n            self.inputconnections[name][GROUPING] = grouping\n        if tuple_type:\n            self.inputconnections[name][TYPE] = tuple_type\n\n    def _add_output(self, name, tuple_type=None):\n        '''\n        Declares an output for this PE.\n        This method may be used when initialising a PE instead of modifying\n        :py:attr:`~dispel4py.core.GenericPE.outputconnections` directly.\n\n        :param name: name of the output\n        :param tuple_type: type of tuples produced by this output (optional)\n        '''\n        self.outputconnections[name] = {NAME: name}\n        if tuple_type:\n            self.outputconnections[name][TYPE] = tuple_type\n\n    def _postprocess(self):\n        None\n\n    def _preprocess(self):\n        self.instanceId = self.name + \"-Instance-\" + \\\n            \"-\" + self.makeProcessId()\n\n        super(ProvenancePE, self)._preprocess()\n\n    def _process(self, inputs):\n\n        # Weighting function for the windows. This particular choice will tend\n        # to favor lots of smaller windows if \"interval_scheduling\" is chosen\n        # as overlap resolution strategy.\n        \n\n        ip = inputs[\"input\"]\n        param = ip[\"parameters\"]\n        \n\n        config = pyflex.Config(\n            min_period=param[\"min_period\"],\n            max_period=param[\"max_period\"],\n            stalta_waterlevel=param[\"stalta_waterlevel\"],\n            s2n_limit=param[\"s2n_limit\"],\n            snr_max_base=param[\"snr_max_base\"],\n            tshift_acceptance_level=param[\"tshift_acceptance_level\"],\n            tshift_reference=param[\"tshift_reference\"],\n            dlna_acceptance_level=param[\"dlna_acceptance_level\"],\n            dlna_reference=param[\"dlna_reference\"],\n            cc_acceptance_level=param[\"cc_acceptance_level\"],\n            earth_model=param[\"earth_model\"],\n            min_surface_wave_velocity=param[\"min_surface_wave_velocity\"],\n            max_time_before_first_arrival=param[\n                \"max_time_before_first_arrival\"],\n            c_0=param[\"c_0\"],\n            c_1=param[\"c_1\"],\n            c_2=param[\"c_2\"],\n            c_3a=param[\"c_3a\"],\n            c_3b=param[\"c_3b\"],\n            c_4a=param[\"c_4a\"],\n            c_4b=param[\"c_4b\"],\n            check_global_data_quality=param[\"check_global_data_quality\"],\n            snr_integrate_base=param[\"snr_integrate_base\"],\n            noise_start_index=param[\"noise_start_index\"],\n            noise_end_index=param[\"noise_end_index\"],\n            signal_start_index=param[\"signal_start_index\"],\n            signal_end_index=param[\"signal_end_index\"],\n            window_signal_to_noise_type=param[\"window_signal_to_noise_type\"],\n            resolution_strategy=param[\"resolution_strategy\"],\n            window_weight_fct=weighting_function)\n\n        ws = WindowSelector(observed=ip[\"data_trace\"],\n                            synthetic=ip[\"synthetic_trace\"],\n                            config=config,\n                            event=[_i for _i in obspy.readEvents(ip[\"quakeml\"])\n                                   if _i.resource_id.id == ip[\"event_id\"]][0],\n                            station=obspy.read_inventory(\n                                ip[\"stationxml\"], format=\"stationxml\"))\n        \n        windows = ws.select_windows()\n\n        data = ip[\"data_trace\"]\n        station_id = \"%s.%s\" % (data.stats.network,\n                                data.stats.station)\n        component = data.stats.channel[-1]\n\n        # HACK!\n        with io.BytesIO() as _:\n            ws.plot(_)\n        fig = plt.gcf()\n        fig.suptitle(\"Component: %s\" % component, fontsize=15,\n                     horizontalalignment=\"center\", x=0.8, y=1)\n        with io.BytesIO() as buf:\n            fig.savefig(buf)\n            buf.seek(0, 0)\n            # Not Python 3 compatible but who cares.\n            image_string = buf.read()\n        \n        plt.close(fig)\n        image_type = \"pyflex_windows\"\n\n        # Metadata for Alessandro!\n        metadata = [{\"type\": \"pyflex\",\n                 \"station_id\": station_id,\n                 \"component\": component,\n                 \"channel_id\": win.channel_id,\n                 \"starttime\": str(win.absolute_starttime),\n                 \"endtime\": str(win.absolute_endtime),\n                 \"max_cc_value\": win.max_cc_value,\n                 \"cc_shift\": win.cc_shift,\n                 \"dlnA\": win.dlnA} for win in windows]\n        \n        self.parameters=param\n        self.write(\n            \"image\",\n            ({\"image_string\": image_string, \"component\": component,\n              \"output_folder\": ip[\"output_folder\"]},\n             image_type, station_id),metadata=metadata)\n        #control={'con:skip':True}\n\n      #  self.write(\n      #      \"windows\", {\n      #          \"record_type\": \"pyflex_windows\",\n      #          \"output_folder\": ip[\"output_folder\"],\n      #          \"windows\": windows,\n      #          \"station_id\": station_id,\n      #          \"component\": component},metadata=metadata)\n\n        if ip[\"misfit_type\"] == \"pyflex_and_time_frequency\":\n            ip[\"windows\"] = [{\n                \"starttime\": win.absolute_starttime,\n                \"endtime\": win.absolute_endtime} for win in windows]\n            self.write(\"window_tapering\", ip, metadata=metadata)\n\n    def _updateState(self,name,id):\n        if name in self.stateCollection:\n                self.stateCollectionId.remove(self.stateCollection[name])\n        self.stateCollection[name]=id\n        self.stateCollectionId.append(id)\n\n    def _write(self, name, data, **kwargs):\n        '''\n        This writes the 'data' to the output pipe with name 'name' of this PE.\n        '''\n         \n        try:\n            output = self.outputconnections[name]\n            output[WRITER].write(data)\n        except KeyError:\n            raise Exception(\"Can't write data: Unknown output connection\\\n                            '%s' for PE '%s'\" % (name, type(self).__name__))\n\n    def addNamespacePrefix(self,prefix,url):\n        self.ns.update({prefix:url})\n\n    def apply_derivation_rule(self,event,voidInvocation,oport=None,iport=None,data=None,metadata=None):\n        \n        if (event=='end_invocation_event') and voidInvocation==True:\n            self.discardInFlow(discardState=True)\n        \n        if (event=='end_invocation_event') and voidInvocation==False:\n            self.discardInFlow(discardState=True)\n\n    def buildDerivation(self, data, port=\"\"):\n        \n        if data!=None and 'id' in data:\n\n            derivation = {'port': port, \n                          'DerivedFromDatasetID': data['id'], \n                          'TriggeredByProcessIterationID': data['TriggeredByProcessIterationID'], \n                          'prov_cluster': data['prov_cluster'],\n                          'iterationIndex':self.iterationIndex,\n                          \n\n\n\n                          }\n                          \n            if port==\"_d4p_state\": \n                derivation.update({'lookupterm':data['lookupterm']})\n                 \n\t\t    \n            if \"up:assertionType\" in data:\n                derivation.update({\"up:assertionType\":data[\"up:assertionType\"]})\n\n\n\n            self.derivationIds.append(derivation)\n\n        else:\n            \n            id=self.extractDataSourceId(data,port)\n            #traceback.print_exc(file=sys.stderr)\n            derivation = {'port': port, 'DerivedFromDatasetID':\n                          id, 'TriggeredByProcessIterationID':\n                          None, 'prov_cluster':\n                          None,\n                          'iterationIndex':self.iterationIndex\n                          }\n            self.derivationIds.append(derivation)\n            self.log(\"BUILDING INITIAL DERIVATION\")\n\n    def buildUserMetadata(self, data, **kwargs):\n        streamlist = list()\n\n        streamItem = {}\n        streammeta = []\n        settransfer=False\n        streammeta = self.extractItemMetadata(data,kwargs['output_port'])\n        \n        if not isinstance(streammeta, list):\n            streammeta = kwargs['metadata'] if isinstance(\n                kwargs['metadata'], list) else [kwargs['metadata']]\n        elif isinstance(streammeta, list):\n            try:\n                if isinstance(kwargs['metadata'], list):\n                    streammeta = streammeta + kwargs['metadata']\n                if isinstance(kwargs['metadata'], dict):\n                    for y in streammeta:\n                        y.update(kwargs['metadata'])\n            except:\n                traceback.print_exc(file=sys.stderr)\n                None\n        \n        if self.sel_rules!=None:\n            self.provon=self.checkSelectiveRule(streammeta)\n\n       \n        if not self.provon:\n            return streamItem\n        #self.log(kwargs)\n        streamItem.update({\"content\": streammeta,\n                           \"id\": self.getUniqueId(data,kwargs['output_port'],**kwargs),\n                           \"format\": \"\",\n                           \"location\": \"\",\n                           \"annotations\": [],\n                           \"port\": kwargs['output_port']})\n        # if (self.streamItemsControl!={,:\n        streamItem.update(kwargs['control'])\n        # if (self.streamItemsLocations!={,:\n        streamItem.update({\"location\": kwargs['location'],\n                          \"format\": kwargs['format']})\n        streamItem.update({\"size\": total_size(data)})\n        #streamItem.update({\"size\": 0})\n\n        if self.transfer_rules!=None:\n            settransfer=self.checkTransferRule(streammeta)\n\n\n        if settransfer:\n            streamItem[\"s-prov:immediateAccess\"]=True\n            streamItem[\"s-prov:first-known-destination\"]=self.transfer_rules[\"destination\"]\n\n        \n        \n        streamlist.append(streamItem)\n        return streamlist\n\n    def checkSelectiveRule(self,streammeta):\n        self.log(\"Checking Skip-Rules: \"+str(self.sel_rules))\n        rules=self.sel_rules[\"rules\"]\n\n        for key in rules:\n\n                for s in streammeta:\n                    if key in s: \n                        #self.log(\"A\"+str(self.sel_rules[key]))\n                        self.log(s[key]) \n                        self.log(type(s[key]))\n                         \n                        if '$eq' in rules[key] and s[key]==rules[key]['$eq']:\n                            return True\n                        elif '$gt' in rules[key] and '$lt' in rules[key]:\n                            if (s[key]>rules[key]['$gt'] and s[key]<rules[key]['$lt']):\n                                self.log(\"GT-LT\") \n                                return True\n                            else:\n                                return False\n                        elif '$gt' in rules[key] and s[key]>rules[key]['$gt']:\n                            self.log(\"GT\") \n                            return True\n                        elif '$lt' in rules[key] and s[key]<rules[key]['$lt']:\n                            self.log(\"LT\") \n                            return True\n                        else:\n                            return False\n        return self.provon\n\n    def checkTransferRule(self,streammeta):\n        self.log(\"Checking Transfer-Rules\")\n        for key in self.transfer_rules[\"rules\"]:\n                for s in streammeta:\n                    if key in s: \n                        #self.log(\"A\"+str(self.sel_rules[key]))\n                        self.log(s[key]) \n                        self.log(type(s[key]))\n                        \n                        if '$eq' in self.transfer_rules[\"rules\"][key] and s[key]==self.transfer_rules[\"rules\"][key]['$eq']:\n                             \n                            return True\n                        elif '$gt' in self.transfer_rules[\"rules\"][key] and '$lt' in self.transfer_rules[\"rules\"][key]:\n                            if (s[key]>self.transfer_rules[\"rules\"][key]['$gt'] and s[key]<self.transfer_rules[\"rules\"][key]['$lt']):\n                                self.log(\"GT-LT\")\n                                 \n                                return True\n                        elif '$gt' in self.transfer_rules[\"rules\"][key] and s[key]>self.transfer_rules[\"rules\"][key]['$gt']:\n                            self.log(\"GT\") \n                            \n                            return True\n                        elif '$lt' in self.transfer_rules[\"rules\"][key] and s[key]<self.transfer_rules[\"rules\"][key]['$lt']:\n                            self.log(\"LT\")\n                            \n                            return True\n                        else:\n                            return False\n        return False\n\n    def dicToKeyVal(self, dict, valueToString=False):\n        try:\n            alist = list()\n            for k, v in dict.iteritems():\n                adic = {}\n                adic.update({\"key\": str(k)})\n                if valueToString:\n                    adic.update({\"val\": str(v)})\n                else:\n\n                    try:\n                        v = num(v)\n                        adic.update({\"val\": v})\n                    except Exception:\n                        adic.update({\"val\": str(v)})\n\n                alist.append(adic)\n\n            return alist\n        except Exception as err:\n\n            self.error += self.name + \" dicToKeyVal output Error: \" + str(err)\n            sys.stderr.write(\n                'ERROR: ' +\n                self.name +\n                ' dicToKeyVal output Error: ' +\n                str(err))\n#                self.map.put(\"output\",\"\");\n            traceback.print_exc(file=sys.stderr)\n\n    def discardInFlow(self,wlength=None,discardState=False): \n        #self.log('BEFORE '+str(self.derivationIds))\n        \n        \n        if discardState==True:\n            if wlength==None:\n            #self.log(\"discarding\")\n                self.derivationIds=[]\n            else:\n                count=0\n                for x in self.derivationIds:\n                    if x!=None and x['port']!='_d4p_state' and count>=wlength-1:\n                        self.derivationIds.remove(x)\n                    count+=1\n                for x in self.derivationIds:\n                    if x!=None and x['port']=='_d4p_state':\n                        self.derivationIds.remove(x)\n                        \n\n\n\n        else:\n            maxit=0\n            state=None\n            #self.log(\"BEFORE\" +str(self.derivationIds))\n            for x in self.derivationIds:\n                 \n                if x!=None and x['port']=='_d4p_state' and x['iterationIndex']>=maxit:\n                    \n                    state=x\n                    maxit=x['iterationIndex']\n            \n            if wlength==None:\n                if state!=None:   \n                    self.derivationIds=[state]\n                else:\n                    self.derivationIds=[]\n            else:\n                count=0\n                for x in self.derivationIds:\n                    #self.log(\"COUNT: \"+str(count)+\" WLENTGH: \"+str(wlength))\n                    if x!=None and x['port']!='_d4p_state' and count>=wlength-1:\n                        #self.log(\"REMOVE: \"+str(x['iterationIndex']))\n                        del self.derivationIds[0]   \n                    count+=1\n\n               \n\n                if state!=None: \n                    self.derivationIds.append(state)\n\n    def discardState(self): \n        #self.log('BEFORE '+str(self.derivationIds))\n        \n        \n        derivations = [x for x in self.derivationIds if x['port']!='_d4p_state']\n        \n        self.derivationIds=derivations\n\n    def extractDataSourceId(self,data,port):\n        self.makeUniqueId(data,port)\n\n    def extractItemMetadata(self,data,port):\n        try:\n               \n            st=[]\n             \n            if type(data) == Trace:\n                st.append(data)\n                \n            elif type(data)==tuple:\n                for x in data:\n                    if type(x)==Stream:\n                        st=x\n            else:\n                st=data\n            streammeta=list()\n            for tr in st:\n                \n                metadic={}\n                metadic.update({\"prov:type\":\"waveform\"});    \n                metadic.update({\"id\":str(uuid.uuid1())});\n                \n                for attr, value in tr.stats.__dict__.iteritems():\n                    \n                    if attr==\"mseed\":\n                        mseed={}\n                        for a,v in value.__dict__.iteritems():\n                            try:\n                                if type(v)==UTCDateTime:\n                                    mseed.update({a:str(v)});\n                                else:\n                                    mseed.update({a:float(v)});\n                            except Exception,e:\n                                mseed.update({a:str(v)});\n                        metadic.update({\"mseed\":mseed});\n                    else:\n                        try:\n                            if type(value)==UTCDateTime:\n                                metadic.update({attr:str(value)});\n                            else:\n                                metadic.update({attr:float(value)});\n                        except Exception,e:\n                            metadic.update({attr:str(value)});\n                \n                streammeta.append(metadic);\n            \n            return streammeta   \n        except Exception, err:\n            self.log(\"Applying default metadata extraction\")\n            #self.error=self.error+\"Extract Metadata error: \"+str(traceback.format_exc())\n            return super(SeismoPE, self).extractItemMetadata(data,port);\n\n    def extractProvenance(\n            self,\n            data,\n            location=\"\",\n            format=\"\",\n            metadata={},\n            control={},\n            attributes={},\n            error=\"\",\n            output_port=\"\",\n            **kwargs):\n\n        self.error = error\n\n        if metadata==None:\n            metadata={}\n        elif isinstance(metadata, list):\n            metadata.append(attributes)\n        else:\n            metadata.update(attributes)\n\n        usermeta = {}\n\n        if 's-prov:skip' in control and bool(control['s-prov:skip']):\n            self.provon = False\n        else:\n            self.provon = True\n            usermeta= self.buildUserMetadata(\n                data,\n                location=location,\n                format=format,\n                metadata=metadata,\n                control=control,\n                attributes=attributes,\n                error=error,\n                output_port=output_port,\n                **kwargs)\n        \n         \n        \n        self.flushData(data, usermeta, output_port,**kwargs)\n\n        return usermeta\n\n    def flushData(self, data, metadata, port,**kwargs):\n        trace = {}\n        stream = data\n        try:\n            if self.provon:\n                self.endTime = datetime.datetime.utcnow()\n                trace = self.packageAll(metadata)\n            \n            stream = self.prepareOutputStream(data, trace, port,**kwargs)\n              \n            try:\n                if port is not None and port != '_d4p_state' \\\n                        and port != 'error':\n\n                    super(ProvenancePE, self).write(port, stream)\n#stream)\n\n            except:\n                self.log(traceback.format_exc())\n                'if cant write doesnt matter move on'\n                pass\n            try:\n                if self.provon:\n                    if (ProvenancePE.send_prov_to_sensor==True) or (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\n\n                            self.sendProvToSensor(trace['metadata'])\n                            \n                            \n                            #super(\n                            #      ProvenancePE,\n                            #      self).write(\n                            #                  OUTPUT_METADATA,\n                            #                  deepcopy(trace['metadata']))\n                            \n\n                    if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n                        \n                        self.sendProvToService(trace['metadata'])\n                    if self.save_mode==ProvenancePE.SAVE_MODE_FILE:\n                         self.writeProvToFile(trace['metadata'])\n                     \n            except:\n                self.log(traceback.format_exc())\n                'if cant write doesnt matter move on'\n                pass\n\n            return True\n\n        except Exception:\n            self.log(traceback.format_exc())\n            if self.provon:\n                self.error += \" FlushChunk Error: %s\" % traceback.format_exc()\n\n    def getDataStreams(self, inputs):\n        streams = {}\n        for inp in self.inputconnections:\n            if inp not in inputs:\n                continue\n            values = inputs[inp]\n            if isinstance(values, list):\n                data = values[0:]\n            else:\n                data = values\n            streams[\"streams\"].update({inp: data})\n        return streams\n\n    def getInputAt(self, port=\"input\", index=None):\n        if index==None:\n            return self.inputs[port]\n        else:\n            return self.inputs[port][index]\n\n    def getOutputTypes(self):\n        '''\n        Returns the output types of this PE, in the form of a dictionary.\n        This method may be overridden if output types are not static and\n        depend on input types.\n\n        .. note::\n\n            This method is only called after the input types have been\n            initialised in :py:func:`~dispel4py.core.GenericPE.setInputTypes`.\n\n        :rtype: a dictionary mapping each output name to its type\n\n        By default it returns a dictionary of the types defined in the\n        'outputconnections' instance variable.\n\n        Usage example::\n\n            def getOutputTypes(self):\n                output = { 'output1' : myInputs['input1'],\n                           'output2' : [ 'comment' ] }\n\n        '''\n        ret = {}\n        # print '%s: %s' % (self.id, self.outputconnections)\n        for name, output in self.outputconnections.items():\n            try:\n                ret[name] = output[TYPE]\n            except KeyError:\n                raise Exception(\"%s: No output type defined for '%s'\"\n                                % (self.id, name))\n        return ret\n\n    def getProvStateObjectId(self,name):\n        if name in self.stateCollection:\n            return self.stateCollection[name]\n        else:\n            return None\n\n    def getUniqueId(self,data,port,**kwargs):\n        data_id = self.makeUniqueId(data,port)\n        if 'name' in kwargs:\n            self._updateState(kwargs['name'],data_id)\n\n\n\n        return data_id\n\n    def ignorePastFlow(self):\n        self.ignore_past_flow=True\n\n    def ignoreState(self):\n        self.ignore_state=True\n\n    def importInputData(self, data):\n\n        inputs = {}\n\n        try:\n            if not isinstance(data, collections.Iterable):\n                return data\n            else:\n                for x in data:\n                    #self.log(data[x])\n                    self.buildDerivation(data[x], port=x)\n                    if type(data[x])==dict and '_d4p' in data[x]:\n                        inputs[x] = data[x]['_d4p']\n                    else:\n                        inputs[x] = data[x]\n                return inputs\n\n        except Exception:\n            self.output = \"\"\n            self.error += \"Reading Input Error: %s\" % traceback.format_exc()\n            raise\n\n    def initParameters(self):\n\n        self.error = ''\n        self.w3c_prov = {}\n        #self.resetflow = True\n        self.inMetaStreams = None\n        self.username = None\n        self.runId = None\n\n\n        try:\n                # self.iterationId = self.name + '-' + getUniqueId()\n            if \"username\" in self.controlParameters:\n                self.username = self.controlParameters[\"username\"]\n            if \"runId\" in self.controlParameters:\n                self.runId = self.controlParameters[\"runId\"]\n\n        except:\n                self.runId = \"\"\n                pass\n\n        self.outputdest = self.controlParameters[\n            'outputdest'] if 'outputdest' in self.controlParameters else 'None'\n        self.rootpath = self.controlParameters[\n            'inputrootpath'] \\\n            if 'inputrootpath' in self.controlParameters else 'None'\n        self.outputid = self.controlParameters[\n            'outputid'] \\\n            if 'outputid' in self.controlParameters else 'None'\n\n    def makeProcessId(self, **kwargs):\n        \n        return socket.gethostname() + \"-\" + \\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\n\n    def makeUniqueId(self,data,port):\n        #if ('data' in kwargs):\n        #    self.log(str(kwargs['data']))\n        \n        return socket.gethostname() + \"-\" + \\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\n\n    def packageAll (self, contentmeta):\n        metadata = {}\n        if self.provon:\n            try:\n\n                # identifies the actual iteration over the instance\n                metadata.update({'iterationId': self.iterationId,\n                # identifies the actual writing process'\n                'actedOnBehalfOf': self.behalfOf,\n                '_id': self.id + '_write_' + str(self.makeProcessId()),\n                'iterationIndex': self.iterationIndex,\n                'instanceId': self.instanceId,\n                'annotations': {}})\n\n                if self.feedbackIteration:\n                    metadata.update(\n                        {'_id': self.id + '_feedback_' + str(self.makeProcessId())})\n                elif self.stateful:\n                    metadata.update(\n                        {'_id': self.id + '_stateful_' + str(self.makeProcessId())})\n\n                else:\n                    metadata.update(\n                        {'_id': self.id + '_write_' + str(self.makeProcessId())})\n\n\n                metadata.update({'stateful': not self.resetflow,\n                'feedbackIteration': self.feedbackIteration,\n                'worker': socket.gethostname(),\n                'parameters': self.parameters,\n                'errors': self.error,\n                'pid': '%s' % os.getpid()})\n\n\n                 \n                if self.ignore_inputs==True:\n                    derivations = [x for x in self.derivationIds if x['port']=='_d4p_state' and x['DerivedFromDatasetID'] in self.stateCollectionId]\n                    metadata.update({'derivationIds': derivations})\n                    self.ignore_inputs = False\n                    \n                elif self.ignore_past_flow==True:\n                     \n                    derivations = [x for x in self.derivationIds if (x['iterationIndex'] == self.iterationIndex or x['port']=='_d4p_state')]\n                    metadata.update({'derivationIds': derivations})\n                    #self.log(\"IGNOREPAST \"+str(derivations))\n\n                elif self.ignore_state==True:\n                    \n                    derivations = [x for x in self.derivationIds if x['port']!='_d4p_state']\n                    metadata.update({'derivationIds': derivations})\n                    #self.log(\"In package \"+str(self.derivationIds))\n                    #self.ignore_past_flow = False\n                else:\n                     \n                    metadata.update({'derivationIds': self.derivationIds})\n                    self.ignore_past_flow = False\n\n\n                metadata.update({'name': self.name,\n                'runId': self.runId,\n                'username': self.username,\n                'startTime': str(self.startTime),\n                'endTime': str(self.endTime),\n                'type': 'lineage',\n\n                'streams': contentmeta,\n                'mapping': sys.argv[1]})\n                \n                if hasattr(self, 'prov_cluster'):\n                     \n                    metadata.update({'prov_cluster': self.prov_cluster})\n                \n\n                if self.creator is not None:\n                    metadata.update({'creator': self.creator})\n            except Exception:\n                self.error += \" Packaging Error: %s\" % traceback.format_exc()\n                self.log(traceback.format_exc())\n\n        output = {\n            \"metadata\": metadata,\n            \"error\": self.error,\n            #\"pid\": \"%s\" %\n            #os.getpid()\n             }\n\n\n        return output\n\n    def pe_init(self, *args, **kwargs):\n        #ProvenancePE.__init__(self,*args, **kwargs)\n\n        global _d4p_plan_sqn\n        self._add_input('_d4py_feedback', grouping='all')\n        self.stateCollection={}\n        self.stateCollectionId=[]\n        self.impcls = None\n        self.bulk_prov = []\n        self.stateful=False\n        self.stateDerivations=[]\n\n\n        if 'pe_class' in kwargs and kwargs['pe_class'] != GenericPE:\n            self.impcls = kwargs['pe_class']\n       \n        if 'sel_rules' in kwargs and self.name in kwargs['sel_rules']:\n            print(self.name+\" \"+str(kwargs['sel_rules'][self.name]))\n            self.sel_rules = kwargs['sel_rules'][self.name]\n        else:\n            self.sel_rules=None\n        \n        if 'transfer_rules' in kwargs and self.name in kwargs['transfer_rules']:\n            print(self.name+\" \"+str(kwargs['transfer_rules'][self.name]))\n            self.transfer_rules = kwargs['transfer_rules'][self.name]\n        else:\n            self.transfer_rules=None\n\n\n        if 'creator' not in kwargs:\n            self.creator = None\n        else:\n            self.creator = kwargs['creator']\n\n        self.error = ''\n\n        if not hasattr(self, 'parameters'):\n            self.parameters = {}\n        if not hasattr(self, 'controlParameters'):\n            self.controlParameters = {}\n\n        if 'controlParameters' in kwargs:\n            self.controlParameters = kwargs['controlParameters']\n\n        out_md = {}\n        out_md[NAME] = OUTPUT_METADATA\n\n        # self.outputconnections[OUTPUT_DATA] = out1\n        #print(OUTPUT_METADATA)\n        self._add_output(OUTPUT_METADATA)\n        ##self.outputconnections[OUTPUT_METADATA] = out_md\n        self.taskId = str(uuid.uuid1())\n\n        # self.appParameters = None\n        self.provon = True\n        \n\n        if 'save_mode' not in kwargs:\n            self.save_mode=ProvenancePE.SAVE_MODE_FILE\n        else:\n            self.save_mode=SAVE_MODE_FILE = kwargs['save_mode']\n\n        self.wcount=0\n        self.resetflow = False\n        self.stateUpdateIndex=0\n        self.ignore_inputs = False\n        self.ignore_state=False\n        self.ignore_past_flow = False\n        self.derivationIds = list()\n        self.iterationIndex = 0\n        \n        #name + '_' + str(_d4p_plan_sqn)\n        _d4p_plan_sqn = _d4p_plan_sqn + 1\n        self.countstatewrite=0\n        if not hasattr(self, 'comp_id'):\n            self.behalfOf=self.id\n        else:\n            self.behalfOf=self.comp_id\n        if not hasattr(self, 'prov_cluster'):\n            self.prov_cluster=self.behalfOf\n\n    def postprocess(self):\n\n        \n        if len(self.bulk_prov)>0:\n            \n            if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n                #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\n                params = urllib.urlencode({'prov': ujson.dumps(self.bulk_prov)})\n                headers = {\n                       \"Content-type\": \"application\/x-www-form-urlencoded\",\n                       \"Accept\": \"application\/json\"}\n                self.connection = httplib.HTTPConnection(\n                                                     self.provurl.netloc)\n                self.connection.request(\n                                    \"POST\",\n                                    self.provurl.path,\n                                    params,\n                                    headers)\n                response = self.connection.getresponse()\n                self.log(\"Postprocess: \" +\n                     str((response.status, response.reason, response.read())))\n#                    response.read())))\n                self.connection.close()\n                self.bulk_prov[:]=[]\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_FILE):\n                filep = open(ProvenancePE.PROV_PATH + \"\/bulk_\" + self.makeProcessId(), \"wr\")\n                ujson.dump(self.bulk_prov, filep)\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\n                super(\n                                  ProvenancePE,\n                                  self).write(\n                                              OUTPUT_METADATA,\n                                              {'prov_cluster':self.prov_cluster,'provenance':deepcopy(self.bulk_prov)})\n            #self.bulk_prov[:]=[]\n\n        self._postprocess()\n\n    def prepareOutputStream(self, data, trace,port,**kwargs):\n        try:\n            streamtransfer = {}\n            streamtransfer['_d4p'] = data\n            #self.log(\"PROVON: \"+str(self.provon))\n            \n            try:\n\n\n                streamtransfer[\"prov_cluster\"] = self.prov_cluster\n                streamtransfer[\"port\"] = port\n                \n\n                if self.provon:\n                    \n                    #self.log(\"lnking Component trace\")\n                    streamtransfer['id'] = trace[\n                        'metadata'][\"streams\"][0][\"id\"]\n                    streamtransfer[\n                        \"TriggeredByProcessIterationID\"] = self.iterationId\n                    \n                    if port=='_d4p_state':\n                        #self.log(''' Building SELF Derivation '''+str(trace))\n                        self._updateState(kwargs['lookupterm'],trace[\n                        'metadata'][\"streams\"][0]['id'])\n                        streamtransfer['lookupterm']=kwargs['lookupterm']\n                        self.buildDerivation(streamtransfer,port='_d4p_state')\n                        \n                else:\n                    \n                    #self.log(\"Skip Component trace\")\n                    streamtransfer[\"id\"] = self.derivationIds[0][\"DerivedFromDatasetID\"]\n                    streamtransfer[\"TriggeredByProcessIterationID\"] = self.derivationIds[0][\"TriggeredByProcessIterationID\"]\n                    streamtransfer[\"up:assertionType\"] = \"up:Incomplete\"\n                    #self.log(streamtransfer)\n                    \n            except:\n                #self.log(traceback.format_exc())\n                pass\n            return streamtransfer\n\n        except Exception:\n            self.error += self.name + \" Writing output Error: %s\" % \\\n                traceback.format_exc()\n            raise\n\n    def preprocess(self):\n        if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n            self.provurl = urlparse(ProvenancePE.REPOS_URL)\n            #self.connection = httplib.HTTPConnection(\n            #                                         self.provurl.netloc)\n        self._preprocess()\n\n    def process(self, inputs):\n        self.feedbackIteration = False\n        self.void_invocation = True\n        self.iterationIndex += 1\n\n         \n        \n\n        if '_d4py_feedback' in inputs:\n\n            'state could be used here to track the occurring changes'\n            self.process_feedback(inputs['_d4py_feedback'])\n        else:\n            self.__processwrapper(inputs)\n\n        for x in inputs:\n            data=inputs[x]\n            if type(data)==dict and '_d4p' in data:\n                self.apply_derivation_rule('end_invocation_event',self.void_invocation,iport=x,data=data['_d4p'])   \n            else:\n                self.apply_derivation_rule('end_invocation_event',self.void_invocation,iport=x,data=data)  \n\n    def process_feedback(self, feedback):\n        self.feedbackIteration = True\n        self._process_feedback(feedback)\n\n    def removeDerivation(self,**kwargs):\n        if 'name' in kwargs:\n            id = self.getProvStateObjectId(kwargs['name'])\n            for j in self.derivationIds:\n\n                if j['DerivedFromDatasetID']==id:\n\n                    del self.derivationIds[self.derivationIds.index(j)]\n        else:\n            if 'port' in kwargs:\n                for j in self.derivationIds:\n\n                    if j['port']==kwargs['port']:\n\n                        del self.derivationIds[self.derivationIds.index(j)]\n\n    def sendProvToSensor(self, prov):\n        \n\n        self.bulk_prov.append(deepcopy(prov))\n\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\n            super(\n                                  ProvenancePE,\n                                  self).write(\n                                              OUTPUT_METADATA,\n                                              {'prov_cluster':self.prov_cluster,'provenance':deepcopy(self.bulk_prov)})\n\n             \n            self.bulk_prov[:]=[]\n\n        return None\n\n    def sendProvToService(self, prov):\n\n        #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\n\n        if isinstance(prov, list) and \"data\" in prov[0]:\n            prov = prov[0][\"data\"]\n\n        self.bulk_prov.append(deepcopy(prov))\n        \n        if len(self.bulk_prov) > ProvenancePE.BULK_SIZE:\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\n            params = urllib.urlencode({'prov': ujson.dumps(self.bulk_prov)})\n            headers = {\n                \"Content-type\": \"application\/x-www-form-urlencoded\",\n                \"Accept\": \"application\/json\"}\n            self.connection = httplib.HTTPConnection(\n                                                     self.provurl.netloc)\n            self.connection.request(\n                \"POST\", self.provurl.path, params, headers)\n            response = self.connection.getresponse()\n            #self.log(\"progress: \" + str((response.status, response.reason,response.read())))\n            #                             response, response.read())))\n\n            self.bulk_prov[:]=[]\n\n        return None\n\n    def setInputTypes(self, types):\n        '''\n        Sets the input types of this PE, in the form of a dictionary.\n        It is meant to be overridden, e.g. if output types depend on input.\n\n        .. note::\n\n            This method is always called before\n            :py:func:`~dispel4py.core.GenericPE.getOutputTypes`.\n\n        :param types: object types for each input stream\n        :type types: dictionary mapping input name to input type\n\n        Usage example::\n\n            pe.setInputTypes({'input1':['t1', 't2', 't3'], \\\n                              'input2':['t4', 't5']})\n        '''\n        pass\n\n    def setStateDerivations(self,terms):\n        self.stateDerivations=terms\n\n    def update_prov_state(\n            self,\n            lookupterm,\n            data,\n            location=\"\",\n            format=\"\",\n            metadata={},\n            ignore_inputs=False,\n            ignore_state=True,\n            stateless=False,\n            **kwargs\n    ):\n\n        self.endTime = datetime.datetime.utcnow()\n        self.stateful = True\n        self.ignore_inputs = ignore_inputs\n        self.ignore_state = ignore_state\n        self.addprov=True\n        kwargs['lookupterm']=lookupterm\n        #self.apply_derivation_rule('state', None)\n        if self.provon:\n            if data == None:\n                    self._updateState(lookupterm,self.derivationIds[len(self.derivationIds)-1][\"DerivedFromDatasetID\"])\n\n            else:\n                \n                if 'dep' in kwargs and kwargs['dep']!=None:\n                #self.removeDerivation(port='_d4p_state')\n                \n                    for d in kwargs['dep']:\n                        did=self.getProvStateObjectId(d)\n                    \n                        if did!=None:\n                            self.buildDerivation({'id':did,'TriggeredByProcessIterationID':self.iterationId,'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n                        #self.ignore_state = False\n                        #self.log(\"DERI \"+str(did))\n                        #self.log(\"DERI2 \"+str(self.derivationIds))\n                        #\n\n            \n                self.extractProvenance(data,\n                               location,\n                               format,\n                               metadata,\n                               output_port=\"_d4p_state\",\n                               **kwargs)\n\n         \n\n\n        self.ignore_inputs = False\n        self.ignore_state = False\n\n\n\n        if 'dep' in kwargs and kwargs['dep']!=None:\n            for d in kwargs['dep']:\n                self.removeDerivation(name=d)\n        \n\n        self.stateful  = False\n\n    def write(self, name, data, **kwargs):\n        self.void_invocation=False\n        dep = []\n\n        iport=None\n\n        for i in self.inputs:\n            iport=i\n\n        if 'metadata' in kwargs:\n            dep = self.apply_derivation_rule('write',True,oport=name,iport=iport,data=data,metadata=kwargs['metadata'])\n        else:\n            dep = self.apply_derivation_rule('write',True,oport=name,iport=iport,data=data)\n        \n        self.endTime = datetime.datetime.utcnow()\n\n       \n        \n        if 'dep' in kwargs and kwargs['dep']!=None: \n            for d in kwargs['dep']:\n                self.buildDerivation({'id':self.getProvStateObjectId(d),'TriggeredByProcessIterationID':self.iterationId, 'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n        elif len(self.stateDerivations) > 0:\n            for d in self.stateDerivations:\n                self.buildDerivation({'id':self.getProvStateObjectId(d),'TriggeredByProcessIterationID':self.iterationId, 'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n\n        if 'ignore_inputs' in kwargs:\n            self.ignore_inputs=kwargs['ignore_inputs']\n        \n       \n        \n        self.extractProvenance(data, output_port=name, **kwargs)\n\n        if 'dep' in kwargs and kwargs['dep']!=None:\n            for d in kwargs['dep']:\n                self.removeDerivation(name=d)\n        elif len(self.stateDerivations) > 0:\n            for d in self.stateDerivations:\n                self.removeDerivation(name=d)\n\n\n        self.stateDerivations=[]\n\n    def writeProvToFile(self, prov):\n        \n        if isinstance(prov, list) and \"data\" in prov[0]:\n            prov = prov[0][\"data\"]\n        \n         \n        #self.log('PROCESS: '+str(prov))\n        self.bulk_prov.append(prov)\n        \n        \n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\n            filep = open(\n                ProvenancePE.PROV_PATH +\n                \"\/bulk_\" +\n                self.makeProcessId(),\n                \"wr\")\n            #self.log('PROCESS: '+str(filep))\n            ujson.dump(self.bulk_prov, filep)\n            #filep.write(json.dumps(self.bulk_prov))\n            self.bulk_prov[:]=[]\n\n        return None\n\n    def writeResults(self, name, result):\n\n        #self.resetflow = True\n        self.apply_derivation_rule('write',True,data=result,oport=name)\n        self.void_invocation=False\n        \n        \n\n        if isinstance(result, dict) and '_d4p_prov' in result:\n            meta = result['_d4p_prov']\n            result = (result['_d4p_data'])\n\n            if 'error' in meta:\n                self.extractProvenance(result, output_port=name, **meta)\n            else:\n\n                self.extractProvenance(\n                    result, error=self.error, output_port=name, **meta)\n\n        else:\n            self.extractProvenance(result, error=self.error, output_port=name)\n\n","type":"(<class 'dispel4py.seismo.seismo.SeismoPE'>, <class 'test.misfit_processing.misfit_processing_prov.PyflexPE'>)","functionName":"PyflexPE"},"MatchComponents3":{"code":"    def __computewrapper(self, inputs):\n\n        try:\n            result = None\n\n            self.__markIteration()\n\n            if self.impcls is not None and isinstance(self, self.impcls):\n                try:\n                    if hasattr(self, 'params'):\n                        self.parameters = self.params\n                    result = self._process(inputs[self.impcls.INPUT_NAME])\n                    if result is not None:\n                        self.writeResults(self.impcls.OUTPUT_NAME, result)\n                except:\n                    result = self._process(inputs)\n            else:\n                result = self._process(inputs)\n\n            if result is not None:\n                return result\n\n        except Exception:\n            self.log(\" Compute Error: %s\" % traceback.format_exc())\n            self.error += \" Compute Error: %s\" % traceback.format_exc()\n            # self.endTime = datetime.datetime.utcnow()\n            self.writeResults('error', {'error': 'null'})\n\n    def __getUniqueId(self):\n        return socket.gethostname() + \"-\" + str(os.getpid()) + \\\n            \"-\" + str(uuid.uuid1())\n\n    def __importInputMetadata(self):\n        try:\n            self.inMetaStreams = self.input[\"metadata\"][\"streams\"]\n        except Exception:\n            None\n\n    def __markIteration(self):\n        self.startTime = datetime.datetime.utcnow()\n        self.iterationId = self.name + '-' + self.makeProcessId()\n\n    def __processwrapper(self, data):\n        try:\n\n            self.initParameters()\n\n            self.inputs = self.importInputData(data)\n            # self.__importInputMetadata()\n            return self.__computewrapper(self.inputs)\n\n        except:\n            self.log(traceback.format_exc())\n\n    def __init__(self,*args,**kwargs):\n        ProvenancePE.__init__(self,*args,**kwargs)\n        self.addNamespacePrefix(\"seis\",\"http:\/\/seis-prov.eu\/ns\/#\")\n\n    def _add_input(self, name, grouping=None, tuple_type=None):\n        '''\n        Declares an input for this PE.\n        This method may be used when initialising a PE instead of modifying\n        :py:attr:`~dispel4py.core.GenericPE.inputconnections` directly.\n\n        :param name: name of the input\n        :param grouping: the grouping type that this input expects (optional)\n        :param tuple_type: type of tuples accepted by this input (optional)\n        '''\n        self.inputconnections[name] = {NAME: name}\n        if grouping:\n            self.inputconnections[name][GROUPING] = grouping\n        if tuple_type:\n            self.inputconnections[name][TYPE] = tuple_type\n\n    def _add_output(self, name, tuple_type=None):\n        '''\n        Declares an output for this PE.\n        This method may be used when initialising a PE instead of modifying\n        :py:attr:`~dispel4py.core.GenericPE.outputconnections` directly.\n\n        :param name: name of the output\n        :param tuple_type: type of tuples produced by this output (optional)\n        '''\n        self.outputconnections[name] = {NAME: name}\n        if tuple_type:\n            self.outputconnections[name][TYPE] = tuple_type\n\n    def _postprocess(self):\n        None\n\n    def _preprocess(self):\n        self.instanceId = self.name + \"-Instance-\" + \\\n            \"-\" + self.makeProcessId()\n\n        super(ProvenancePE, self)._preprocess()\n\n    def _process(self, inputs):\n        ip = inputs['input'][0]\n        \n        component = ip[\"component\"]\n        output_folder = ip[\"output_folder\"]\n        image_string = ip[\"image_string\"]\n        image_type = inputs[\"input\"][1]\n        station_id = inputs[\"input\"][2]\n\n        key = (station_id, image_type)\n        self.log(key)\n        self.data[key][component] = image_string\n        if len(self.data[key]) != 3:\n            None\n            #self.update_prov_state(key,image_string,metadata={'component':component,'station_id': station_id,'component_number':len(self.data[key])},ignore_inputs=False, dep=[key])\n            \n        else:\n            value = self.data[key]\n            del self.data[key]\n         \n            #self.write('output',[station_id, image_type, value, output_folder],metadata={'station_id': station_id},dep=[key])\n            self.write('output',[station_id, image_type, value, output_folder],metadata={'station_id': station_id})\n\n    def _updateState(self,name,id):\n        if name in self.stateCollection:\n                self.stateCollectionId.remove(self.stateCollection[name])\n        self.stateCollection[name]=id\n        self.stateCollectionId.append(id)\n\n    def _write(self, name, data, **kwargs):\n        '''\n        This writes the 'data' to the output pipe with name 'name' of this PE.\n        '''\n         \n        try:\n            output = self.outputconnections[name]\n            output[WRITER].write(data)\n        except KeyError:\n            raise Exception(\"Can't write data: Unknown output connection\\\n                            '%s' for PE '%s'\" % (name, type(self).__name__))\n\n    def addNamespacePrefix(self,prefix,url):\n        self.ns.update({prefix:url})\n\n    def apply_derivation_rule(self,event,voidInvocation,oport=None,iport=None,data=None,metadata=None):\n       \n        #self.ignore_past_flow=False\n        #self.ignore_inputs=False\n        #self.stateful=False\n        iport=None\n\n        for i in self.inputs:\n            iport=i\n\n        #self.log(\"IPORT: \"+str(iport))\n        #Do Before Writing\n        if (event=='write'):\n            vv=str(abs(make_hash(tuple([self.getInputAt(port=iport,index=x) for x in self.inputconnections[iport]['grouping']]))))\n            self.log(\"LOOKUP: \"+str(vv))\n            self.setStateDerivations([vv])\n\n        if (event=='end_invocation_event' and voidInvocation==False):\n             self.discardInFlow()\n             self.discardState()\n\n        if (event=='end_invocation_event' and voidInvocation==True):\n            \n            if data!=None:\n                \n                vv=str(abs(make_hash(tuple([self.getInputAt(port=iport,index=x) for x in self.inputconnections[iport]['grouping']]))))\n                self.ignorePastFlow()\n                self.update_prov_state(vv,data,metadata={\"LOOKUP\":str(vv)},dep=[vv])\n                self.discardInFlow()\n                self.discardState()\n\n    def buildDerivation(self, data, port=\"\"):\n        \n        if data!=None and 'id' in data:\n\n            derivation = {'port': port, \n                          'DerivedFromDatasetID': data['id'], \n                          'TriggeredByProcessIterationID': data['TriggeredByProcessIterationID'], \n                          'prov_cluster': data['prov_cluster'],\n                          'iterationIndex':self.iterationIndex,\n                          \n\n\n\n                          }\n                          \n            if port==\"_d4p_state\": \n                derivation.update({'lookupterm':data['lookupterm']})\n                 \n\t\t    \n            if \"up:assertionType\" in data:\n                derivation.update({\"up:assertionType\":data[\"up:assertionType\"]})\n\n\n\n            self.derivationIds.append(derivation)\n\n        else:\n            \n            id=self.extractDataSourceId(data,port)\n            #traceback.print_exc(file=sys.stderr)\n            derivation = {'port': port, 'DerivedFromDatasetID':\n                          id, 'TriggeredByProcessIterationID':\n                          None, 'prov_cluster':\n                          None,\n                          'iterationIndex':self.iterationIndex\n                          }\n            self.derivationIds.append(derivation)\n            self.log(\"BUILDING INITIAL DERIVATION\")\n\n    def buildUserMetadata(self, data, **kwargs):\n        streamlist = list()\n\n        streamItem = {}\n        streammeta = []\n        settransfer=False\n        streammeta = self.extractItemMetadata(data,kwargs['output_port'])\n        \n        if not isinstance(streammeta, list):\n            streammeta = kwargs['metadata'] if isinstance(\n                kwargs['metadata'], list) else [kwargs['metadata']]\n        elif isinstance(streammeta, list):\n            try:\n                if isinstance(kwargs['metadata'], list):\n                    streammeta = streammeta + kwargs['metadata']\n                if isinstance(kwargs['metadata'], dict):\n                    for y in streammeta:\n                        y.update(kwargs['metadata'])\n            except:\n                traceback.print_exc(file=sys.stderr)\n                None\n        \n        if self.sel_rules!=None:\n            self.provon=self.checkSelectiveRule(streammeta)\n\n       \n        if not self.provon:\n            return streamItem\n        #self.log(kwargs)\n        streamItem.update({\"content\": streammeta,\n                           \"id\": self.getUniqueId(data,kwargs['output_port'],**kwargs),\n                           \"format\": \"\",\n                           \"location\": \"\",\n                           \"annotations\": [],\n                           \"port\": kwargs['output_port']})\n        # if (self.streamItemsControl!={,:\n        streamItem.update(kwargs['control'])\n        # if (self.streamItemsLocations!={,:\n        streamItem.update({\"location\": kwargs['location'],\n                          \"format\": kwargs['format']})\n        streamItem.update({\"size\": total_size(data)})\n        #streamItem.update({\"size\": 0})\n\n        if self.transfer_rules!=None:\n            settransfer=self.checkTransferRule(streammeta)\n\n\n        if settransfer:\n            streamItem[\"s-prov:immediateAccess\"]=True\n            streamItem[\"s-prov:first-known-destination\"]=self.transfer_rules[\"destination\"]\n\n        \n        \n        streamlist.append(streamItem)\n        return streamlist\n\n    def checkSelectiveRule(self,streammeta):\n        self.log(\"Checking Skip-Rules: \"+str(self.sel_rules))\n        rules=self.sel_rules[\"rules\"]\n\n        for key in rules:\n\n                for s in streammeta:\n                    if key in s: \n                        #self.log(\"A\"+str(self.sel_rules[key]))\n                        self.log(s[key]) \n                        self.log(type(s[key]))\n                         \n                        if '$eq' in rules[key] and s[key]==rules[key]['$eq']:\n                            return True\n                        elif '$gt' in rules[key] and '$lt' in rules[key]:\n                            if (s[key]>rules[key]['$gt'] and s[key]<rules[key]['$lt']):\n                                self.log(\"GT-LT\") \n                                return True\n                            else:\n                                return False\n                        elif '$gt' in rules[key] and s[key]>rules[key]['$gt']:\n                            self.log(\"GT\") \n                            return True\n                        elif '$lt' in rules[key] and s[key]<rules[key]['$lt']:\n                            self.log(\"LT\") \n                            return True\n                        else:\n                            return False\n        return self.provon\n\n    def checkTransferRule(self,streammeta):\n        self.log(\"Checking Transfer-Rules\")\n        for key in self.transfer_rules[\"rules\"]:\n                for s in streammeta:\n                    if key in s: \n                        #self.log(\"A\"+str(self.sel_rules[key]))\n                        self.log(s[key]) \n                        self.log(type(s[key]))\n                        \n                        if '$eq' in self.transfer_rules[\"rules\"][key] and s[key]==self.transfer_rules[\"rules\"][key]['$eq']:\n                             \n                            return True\n                        elif '$gt' in self.transfer_rules[\"rules\"][key] and '$lt' in self.transfer_rules[\"rules\"][key]:\n                            if (s[key]>self.transfer_rules[\"rules\"][key]['$gt'] and s[key]<self.transfer_rules[\"rules\"][key]['$lt']):\n                                self.log(\"GT-LT\")\n                                 \n                                return True\n                        elif '$gt' in self.transfer_rules[\"rules\"][key] and s[key]>self.transfer_rules[\"rules\"][key]['$gt']:\n                            self.log(\"GT\") \n                            \n                            return True\n                        elif '$lt' in self.transfer_rules[\"rules\"][key] and s[key]<self.transfer_rules[\"rules\"][key]['$lt']:\n                            self.log(\"LT\")\n                            \n                            return True\n                        else:\n                            return False\n        return False\n\n    def dicToKeyVal(self, dict, valueToString=False):\n        try:\n            alist = list()\n            for k, v in dict.iteritems():\n                adic = {}\n                adic.update({\"key\": str(k)})\n                if valueToString:\n                    adic.update({\"val\": str(v)})\n                else:\n\n                    try:\n                        v = num(v)\n                        adic.update({\"val\": v})\n                    except Exception:\n                        adic.update({\"val\": str(v)})\n\n                alist.append(adic)\n\n            return alist\n        except Exception as err:\n\n            self.error += self.name + \" dicToKeyVal output Error: \" + str(err)\n            sys.stderr.write(\n                'ERROR: ' +\n                self.name +\n                ' dicToKeyVal output Error: ' +\n                str(err))\n#                self.map.put(\"output\",\"\");\n            traceback.print_exc(file=sys.stderr)\n\n    def discardInFlow(self,wlength=None,discardState=False): \n        #self.log('BEFORE '+str(self.derivationIds))\n        \n        \n        if discardState==True:\n            if wlength==None:\n            #self.log(\"discarding\")\n                self.derivationIds=[]\n            else:\n                count=0\n                for x in self.derivationIds:\n                    if x!=None and x['port']!='_d4p_state' and count>=wlength-1:\n                        self.derivationIds.remove(x)\n                    count+=1\n                for x in self.derivationIds:\n                    if x!=None and x['port']=='_d4p_state':\n                        self.derivationIds.remove(x)\n                        \n\n\n\n        else:\n            maxit=0\n            state=None\n            #self.log(\"BEFORE\" +str(self.derivationIds))\n            for x in self.derivationIds:\n                 \n                if x!=None and x['port']=='_d4p_state' and x['iterationIndex']>=maxit:\n                    \n                    state=x\n                    maxit=x['iterationIndex']\n            \n            if wlength==None:\n                if state!=None:   \n                    self.derivationIds=[state]\n                else:\n                    self.derivationIds=[]\n            else:\n                count=0\n                for x in self.derivationIds:\n                    #self.log(\"COUNT: \"+str(count)+\" WLENTGH: \"+str(wlength))\n                    if x!=None and x['port']!='_d4p_state' and count>=wlength-1:\n                        #self.log(\"REMOVE: \"+str(x['iterationIndex']))\n                        del self.derivationIds[0]   \n                    count+=1\n\n               \n\n                if state!=None: \n                    self.derivationIds.append(state)\n\n    def discardState(self): \n        #self.log('BEFORE '+str(self.derivationIds))\n        \n        \n        derivations = [x for x in self.derivationIds if x['port']!='_d4p_state']\n        \n        self.derivationIds=derivations\n\n    def extractDataSourceId(self,data,port):\n        self.makeUniqueId(data,port)\n\n    def extractItemMetadata(self,data,port):\n        try:\n               \n            st=[]\n             \n            if type(data) == Trace:\n                st.append(data)\n                \n            elif type(data)==tuple:\n                for x in data:\n                    if type(x)==Stream:\n                        st=x\n            else:\n                st=data\n            streammeta=list()\n            for tr in st:\n                \n                metadic={}\n                metadic.update({\"prov:type\":\"waveform\"});    \n                metadic.update({\"id\":str(uuid.uuid1())});\n                \n                for attr, value in tr.stats.__dict__.iteritems():\n                    \n                    if attr==\"mseed\":\n                        mseed={}\n                        for a,v in value.__dict__.iteritems():\n                            try:\n                                if type(v)==UTCDateTime:\n                                    mseed.update({a:str(v)});\n                                else:\n                                    mseed.update({a:float(v)});\n                            except Exception,e:\n                                mseed.update({a:str(v)});\n                        metadic.update({\"mseed\":mseed});\n                    else:\n                        try:\n                            if type(value)==UTCDateTime:\n                                metadic.update({attr:str(value)});\n                            else:\n                                metadic.update({attr:float(value)});\n                        except Exception,e:\n                            metadic.update({attr:str(value)});\n                \n                streammeta.append(metadic);\n            \n            return streammeta   \n        except Exception, err:\n            self.log(\"Applying default metadata extraction\")\n            #self.error=self.error+\"Extract Metadata error: \"+str(traceback.format_exc())\n            return super(SeismoPE, self).extractItemMetadata(data,port);\n\n    def extractProvenance(\n            self,\n            data,\n            location=\"\",\n            format=\"\",\n            metadata={},\n            control={},\n            attributes={},\n            error=\"\",\n            output_port=\"\",\n            **kwargs):\n\n        self.error = error\n\n        if metadata==None:\n            metadata={}\n        elif isinstance(metadata, list):\n            metadata.append(attributes)\n        else:\n            metadata.update(attributes)\n\n        usermeta = {}\n\n        if 's-prov:skip' in control and bool(control['s-prov:skip']):\n            self.provon = False\n        else:\n            self.provon = True\n            usermeta= self.buildUserMetadata(\n                data,\n                location=location,\n                format=format,\n                metadata=metadata,\n                control=control,\n                attributes=attributes,\n                error=error,\n                output_port=output_port,\n                **kwargs)\n        \n         \n        \n        self.flushData(data, usermeta, output_port,**kwargs)\n\n        return usermeta\n\n    def flushData(self, data, metadata, port,**kwargs):\n        trace = {}\n        stream = data\n        try:\n            if self.provon:\n                self.endTime = datetime.datetime.utcnow()\n                trace = self.packageAll(metadata)\n            \n            stream = self.prepareOutputStream(data, trace, port,**kwargs)\n              \n            try:\n                if port is not None and port != '_d4p_state' \\\n                        and port != 'error':\n\n                    super(ProvenancePE, self).write(port, stream)\n#stream)\n\n            except:\n                self.log(traceback.format_exc())\n                'if cant write doesnt matter move on'\n                pass\n            try:\n                if self.provon:\n                    if (ProvenancePE.send_prov_to_sensor==True) or (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\n\n                            self.sendProvToSensor(trace['metadata'])\n                            \n                            \n                            #super(\n                            #      ProvenancePE,\n                            #      self).write(\n                            #                  OUTPUT_METADATA,\n                            #                  deepcopy(trace['metadata']))\n                            \n\n                    if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n                        \n                        self.sendProvToService(trace['metadata'])\n                    if self.save_mode==ProvenancePE.SAVE_MODE_FILE:\n                         self.writeProvToFile(trace['metadata'])\n                     \n            except:\n                self.log(traceback.format_exc())\n                'if cant write doesnt matter move on'\n                pass\n\n            return True\n\n        except Exception:\n            self.log(traceback.format_exc())\n            if self.provon:\n                self.error += \" FlushChunk Error: %s\" % traceback.format_exc()\n\n    def getDataStreams(self, inputs):\n        streams = {}\n        for inp in self.inputconnections:\n            if inp not in inputs:\n                continue\n            values = inputs[inp]\n            if isinstance(values, list):\n                data = values[0:]\n            else:\n                data = values\n            streams[\"streams\"].update({inp: data})\n        return streams\n\n    def getInputAt(self, port=\"input\", index=None):\n        if index==None:\n            return self.inputs[port]\n        else:\n            return self.inputs[port][index]\n\n    def getOutputTypes(self):\n        '''\n        Returns the output types of this PE, in the form of a dictionary.\n        This method may be overridden if output types are not static and\n        depend on input types.\n\n        .. note::\n\n            This method is only called after the input types have been\n            initialised in :py:func:`~dispel4py.core.GenericPE.setInputTypes`.\n\n        :rtype: a dictionary mapping each output name to its type\n\n        By default it returns a dictionary of the types defined in the\n        'outputconnections' instance variable.\n\n        Usage example::\n\n            def getOutputTypes(self):\n                output = { 'output1' : myInputs['input1'],\n                           'output2' : [ 'comment' ] }\n\n        '''\n        ret = {}\n        # print '%s: %s' % (self.id, self.outputconnections)\n        for name, output in self.outputconnections.items():\n            try:\n                ret[name] = output[TYPE]\n            except KeyError:\n                raise Exception(\"%s: No output type defined for '%s'\"\n                                % (self.id, name))\n        return ret\n\n    def getProvStateObjectId(self,name):\n        if name in self.stateCollection:\n            return self.stateCollection[name]\n        else:\n            return None\n\n    def getUniqueId(self,data,port,**kwargs):\n        data_id = self.makeUniqueId(data,port)\n        if 'name' in kwargs:\n            self._updateState(kwargs['name'],data_id)\n\n\n\n        return data_id\n\n    def ignorePastFlow(self):\n        self.ignore_past_flow=True\n\n    def ignoreState(self):\n        self.ignore_state=True\n\n    def importInputData(self, data):\n\n        inputs = {}\n\n        try:\n            if not isinstance(data, collections.Iterable):\n                return data\n            else:\n                for x in data:\n                    #self.log(data[x])\n                    self.buildDerivation(data[x], port=x)\n                    if type(data[x])==dict and '_d4p' in data[x]:\n                        inputs[x] = data[x]['_d4p']\n                    else:\n                        inputs[x] = data[x]\n                return inputs\n\n        except Exception:\n            self.output = \"\"\n            self.error += \"Reading Input Error: %s\" % traceback.format_exc()\n            raise\n\n    def initParameters(self):\n\n        self.error = ''\n        self.w3c_prov = {}\n        #self.resetflow = True\n        self.inMetaStreams = None\n        self.username = None\n        self.runId = None\n\n\n        try:\n                # self.iterationId = self.name + '-' + getUniqueId()\n            if \"username\" in self.controlParameters:\n                self.username = self.controlParameters[\"username\"]\n            if \"runId\" in self.controlParameters:\n                self.runId = self.controlParameters[\"runId\"]\n\n        except:\n                self.runId = \"\"\n                pass\n\n        self.outputdest = self.controlParameters[\n            'outputdest'] if 'outputdest' in self.controlParameters else 'None'\n        self.rootpath = self.controlParameters[\n            'inputrootpath'] \\\n            if 'inputrootpath' in self.controlParameters else 'None'\n        self.outputid = self.controlParameters[\n            'outputid'] \\\n            if 'outputid' in self.controlParameters else 'None'\n\n    def makeProcessId(self, **kwargs):\n        \n        return socket.gethostname() + \"-\" + \\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\n\n    def makeUniqueId(self,data,port):\n        #if ('data' in kwargs):\n        #    self.log(str(kwargs['data']))\n        \n        return socket.gethostname() + \"-\" + \\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\n\n    def packageAll (self, contentmeta):\n        metadata = {}\n        if self.provon:\n            try:\n\n                # identifies the actual iteration over the instance\n                metadata.update({'iterationId': self.iterationId,\n                # identifies the actual writing process'\n                'actedOnBehalfOf': self.behalfOf,\n                '_id': self.id + '_write_' + str(self.makeProcessId()),\n                'iterationIndex': self.iterationIndex,\n                'instanceId': self.instanceId,\n                'annotations': {}})\n\n                if self.feedbackIteration:\n                    metadata.update(\n                        {'_id': self.id + '_feedback_' + str(self.makeProcessId())})\n                elif self.stateful:\n                    metadata.update(\n                        {'_id': self.id + '_stateful_' + str(self.makeProcessId())})\n\n                else:\n                    metadata.update(\n                        {'_id': self.id + '_write_' + str(self.makeProcessId())})\n\n\n                metadata.update({'stateful': not self.resetflow,\n                'feedbackIteration': self.feedbackIteration,\n                'worker': socket.gethostname(),\n                'parameters': self.parameters,\n                'errors': self.error,\n                'pid': '%s' % os.getpid()})\n\n\n                 \n                if self.ignore_inputs==True:\n                    derivations = [x for x in self.derivationIds if x['port']=='_d4p_state' and x['DerivedFromDatasetID'] in self.stateCollectionId]\n                    metadata.update({'derivationIds': derivations})\n                    self.ignore_inputs = False\n                    \n                elif self.ignore_past_flow==True:\n                     \n                    derivations = [x for x in self.derivationIds if (x['iterationIndex'] == self.iterationIndex or x['port']=='_d4p_state')]\n                    metadata.update({'derivationIds': derivations})\n                    #self.log(\"IGNOREPAST \"+str(derivations))\n\n                elif self.ignore_state==True:\n                    \n                    derivations = [x for x in self.derivationIds if x['port']!='_d4p_state']\n                    metadata.update({'derivationIds': derivations})\n                    #self.log(\"In package \"+str(self.derivationIds))\n                    #self.ignore_past_flow = False\n                else:\n                     \n                    metadata.update({'derivationIds': self.derivationIds})\n                    self.ignore_past_flow = False\n\n\n                metadata.update({'name': self.name,\n                'runId': self.runId,\n                'username': self.username,\n                'startTime': str(self.startTime),\n                'endTime': str(self.endTime),\n                'type': 'lineage',\n\n                'streams': contentmeta,\n                'mapping': sys.argv[1]})\n                \n                if hasattr(self, 'prov_cluster'):\n                     \n                    metadata.update({'prov_cluster': self.prov_cluster})\n                \n\n                if self.creator is not None:\n                    metadata.update({'creator': self.creator})\n            except Exception:\n                self.error += \" Packaging Error: %s\" % traceback.format_exc()\n                self.log(traceback.format_exc())\n\n        output = {\n            \"metadata\": metadata,\n            \"error\": self.error,\n            #\"pid\": \"%s\" %\n            #os.getpid()\n             }\n\n\n        return output\n\n    def pe_init(self, *args, **kwargs):\n        #ProvenancePE.__init__(self,*args, **kwargs)\n\n        global _d4p_plan_sqn\n        self._add_input('_d4py_feedback', grouping='all')\n        self.stateCollection={}\n        self.stateCollectionId=[]\n        self.impcls = None\n        self.bulk_prov = []\n        self.stateful=False\n        self.stateDerivations=[]\n\n\n        if 'pe_class' in kwargs and kwargs['pe_class'] != GenericPE:\n            self.impcls = kwargs['pe_class']\n       \n        if 'sel_rules' in kwargs and self.name in kwargs['sel_rules']:\n            print(self.name+\" \"+str(kwargs['sel_rules'][self.name]))\n            self.sel_rules = kwargs['sel_rules'][self.name]\n        else:\n            self.sel_rules=None\n        \n        if 'transfer_rules' in kwargs and self.name in kwargs['transfer_rules']:\n            print(self.name+\" \"+str(kwargs['transfer_rules'][self.name]))\n            self.transfer_rules = kwargs['transfer_rules'][self.name]\n        else:\n            self.transfer_rules=None\n\n\n        if 'creator' not in kwargs:\n            self.creator = None\n        else:\n            self.creator = kwargs['creator']\n\n        self.error = ''\n\n        if not hasattr(self, 'parameters'):\n            self.parameters = {}\n        if not hasattr(self, 'controlParameters'):\n            self.controlParameters = {}\n\n        if 'controlParameters' in kwargs:\n            self.controlParameters = kwargs['controlParameters']\n\n        out_md = {}\n        out_md[NAME] = OUTPUT_METADATA\n\n        # self.outputconnections[OUTPUT_DATA] = out1\n        #print(OUTPUT_METADATA)\n        self._add_output(OUTPUT_METADATA)\n        ##self.outputconnections[OUTPUT_METADATA] = out_md\n        self.taskId = str(uuid.uuid1())\n\n        # self.appParameters = None\n        self.provon = True\n        \n\n        if 'save_mode' not in kwargs:\n            self.save_mode=ProvenancePE.SAVE_MODE_FILE\n        else:\n            self.save_mode=SAVE_MODE_FILE = kwargs['save_mode']\n\n        self.wcount=0\n        self.resetflow = False\n        self.stateUpdateIndex=0\n        self.ignore_inputs = False\n        self.ignore_state=False\n        self.ignore_past_flow = False\n        self.derivationIds = list()\n        self.iterationIndex = 0\n        \n        #name + '_' + str(_d4p_plan_sqn)\n        _d4p_plan_sqn = _d4p_plan_sqn + 1\n        self.countstatewrite=0\n        if not hasattr(self, 'comp_id'):\n            self.behalfOf=self.id\n        else:\n            self.behalfOf=self.comp_id\n        if not hasattr(self, 'prov_cluster'):\n            self.prov_cluster=self.behalfOf\n\n    def postprocess(self):\n\n        \n        if len(self.bulk_prov)>0:\n            \n            if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n                #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\n                params = urllib.urlencode({'prov': ujson.dumps(self.bulk_prov)})\n                headers = {\n                       \"Content-type\": \"application\/x-www-form-urlencoded\",\n                       \"Accept\": \"application\/json\"}\n                self.connection = httplib.HTTPConnection(\n                                                     self.provurl.netloc)\n                self.connection.request(\n                                    \"POST\",\n                                    self.provurl.path,\n                                    params,\n                                    headers)\n                response = self.connection.getresponse()\n                self.log(\"Postprocess: \" +\n                     str((response.status, response.reason, response.read())))\n#                    response.read())))\n                self.connection.close()\n                self.bulk_prov[:]=[]\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_FILE):\n                filep = open(ProvenancePE.PROV_PATH + \"\/bulk_\" + self.makeProcessId(), \"wr\")\n                ujson.dump(self.bulk_prov, filep)\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\n                super(\n                                  ProvenancePE,\n                                  self).write(\n                                              OUTPUT_METADATA,\n                                              {'prov_cluster':self.prov_cluster,'provenance':deepcopy(self.bulk_prov)})\n            #self.bulk_prov[:]=[]\n\n        self._postprocess()\n\n    def prepareOutputStream(self, data, trace,port,**kwargs):\n        try:\n            streamtransfer = {}\n            streamtransfer['_d4p'] = data\n            #self.log(\"PROVON: \"+str(self.provon))\n            \n            try:\n\n\n                streamtransfer[\"prov_cluster\"] = self.prov_cluster\n                streamtransfer[\"port\"] = port\n                \n\n                if self.provon:\n                    \n                    #self.log(\"lnking Component trace\")\n                    streamtransfer['id'] = trace[\n                        'metadata'][\"streams\"][0][\"id\"]\n                    streamtransfer[\n                        \"TriggeredByProcessIterationID\"] = self.iterationId\n                    \n                    if port=='_d4p_state':\n                        #self.log(''' Building SELF Derivation '''+str(trace))\n                        self._updateState(kwargs['lookupterm'],trace[\n                        'metadata'][\"streams\"][0]['id'])\n                        streamtransfer['lookupterm']=kwargs['lookupterm']\n                        self.buildDerivation(streamtransfer,port='_d4p_state')\n                        \n                else:\n                    \n                    #self.log(\"Skip Component trace\")\n                    streamtransfer[\"id\"] = self.derivationIds[0][\"DerivedFromDatasetID\"]\n                    streamtransfer[\"TriggeredByProcessIterationID\"] = self.derivationIds[0][\"TriggeredByProcessIterationID\"]\n                    streamtransfer[\"up:assertionType\"] = \"up:Incomplete\"\n                    #self.log(streamtransfer)\n                    \n            except:\n                #self.log(traceback.format_exc())\n                pass\n            return streamtransfer\n\n        except Exception:\n            self.error += self.name + \" Writing output Error: %s\" % \\\n                traceback.format_exc()\n            raise\n\n    def preprocess(self):\n        if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n            self.provurl = urlparse(ProvenancePE.REPOS_URL)\n            #self.connection = httplib.HTTPConnection(\n            #                                         self.provurl.netloc)\n        self._preprocess()\n\n    def process(self, inputs):\n        self.feedbackIteration = False\n        self.void_invocation = True\n        self.iterationIndex += 1\n\n         \n        \n\n        if '_d4py_feedback' in inputs:\n\n            'state could be used here to track the occurring changes'\n            self.process_feedback(inputs['_d4py_feedback'])\n        else:\n            self.__processwrapper(inputs)\n\n        for x in inputs:\n            data=inputs[x]\n            if type(data)==dict and '_d4p' in data:\n                self.apply_derivation_rule('end_invocation_event',self.void_invocation,iport=x,data=data['_d4p'])   \n            else:\n                self.apply_derivation_rule('end_invocation_event',self.void_invocation,iport=x,data=data)  \n\n    def process_feedback(self, feedback):\n        self.feedbackIteration = True\n        self._process_feedback(feedback)\n\n    def removeDerivation(self,**kwargs):\n        if 'name' in kwargs:\n            id = self.getProvStateObjectId(kwargs['name'])\n            for j in self.derivationIds:\n\n                if j['DerivedFromDatasetID']==id:\n\n                    del self.derivationIds[self.derivationIds.index(j)]\n        else:\n            if 'port' in kwargs:\n                for j in self.derivationIds:\n\n                    if j['port']==kwargs['port']:\n\n                        del self.derivationIds[self.derivationIds.index(j)]\n\n    def sendProvToSensor(self, prov):\n        \n\n        self.bulk_prov.append(deepcopy(prov))\n\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\n            super(\n                                  ProvenancePE,\n                                  self).write(\n                                              OUTPUT_METADATA,\n                                              {'prov_cluster':self.prov_cluster,'provenance':deepcopy(self.bulk_prov)})\n\n             \n            self.bulk_prov[:]=[]\n\n        return None\n\n    def sendProvToService(self, prov):\n\n        #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\n\n        if isinstance(prov, list) and \"data\" in prov[0]:\n            prov = prov[0][\"data\"]\n\n        self.bulk_prov.append(deepcopy(prov))\n        \n        if len(self.bulk_prov) > ProvenancePE.BULK_SIZE:\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\n            params = urllib.urlencode({'prov': ujson.dumps(self.bulk_prov)})\n            headers = {\n                \"Content-type\": \"application\/x-www-form-urlencoded\",\n                \"Accept\": \"application\/json\"}\n            self.connection = httplib.HTTPConnection(\n                                                     self.provurl.netloc)\n            self.connection.request(\n                \"POST\", self.provurl.path, params, headers)\n            response = self.connection.getresponse()\n            #self.log(\"progress: \" + str((response.status, response.reason,response.read())))\n            #                             response, response.read())))\n\n            self.bulk_prov[:]=[]\n\n        return None\n\n    def setInputTypes(self, types):\n        '''\n        Sets the input types of this PE, in the form of a dictionary.\n        It is meant to be overridden, e.g. if output types depend on input.\n\n        .. note::\n\n            This method is always called before\n            :py:func:`~dispel4py.core.GenericPE.getOutputTypes`.\n\n        :param types: object types for each input stream\n        :type types: dictionary mapping input name to input type\n\n        Usage example::\n\n            pe.setInputTypes({'input1':['t1', 't2', 't3'], \\\n                              'input2':['t4', 't5']})\n        '''\n        pass\n\n    def setStateDerivations(self,terms):\n        self.stateDerivations=terms\n\n    def update_prov_state(\n            self,\n            lookupterm,\n            data,\n            location=\"\",\n            format=\"\",\n            metadata={},\n            ignore_inputs=False,\n            ignore_state=True,\n            stateless=False,\n            **kwargs\n    ):\n\n        self.endTime = datetime.datetime.utcnow()\n        self.stateful = True\n        self.ignore_inputs = ignore_inputs\n        self.ignore_state = ignore_state\n        self.addprov=True\n        kwargs['lookupterm']=lookupterm\n        #self.apply_derivation_rule('state', None)\n        if self.provon:\n            if data == None:\n                    self._updateState(lookupterm,self.derivationIds[len(self.derivationIds)-1][\"DerivedFromDatasetID\"])\n\n            else:\n                \n                if 'dep' in kwargs and kwargs['dep']!=None:\n                #self.removeDerivation(port='_d4p_state')\n                \n                    for d in kwargs['dep']:\n                        did=self.getProvStateObjectId(d)\n                    \n                        if did!=None:\n                            self.buildDerivation({'id':did,'TriggeredByProcessIterationID':self.iterationId,'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n                        #self.ignore_state = False\n                        #self.log(\"DERI \"+str(did))\n                        #self.log(\"DERI2 \"+str(self.derivationIds))\n                        #\n\n            \n                self.extractProvenance(data,\n                               location,\n                               format,\n                               metadata,\n                               output_port=\"_d4p_state\",\n                               **kwargs)\n\n         \n\n\n        self.ignore_inputs = False\n        self.ignore_state = False\n\n\n\n        if 'dep' in kwargs and kwargs['dep']!=None:\n            for d in kwargs['dep']:\n                self.removeDerivation(name=d)\n        \n\n        self.stateful  = False\n\n    def write(self, name, data, **kwargs):\n        self.void_invocation=False\n        dep = []\n\n        iport=None\n\n        for i in self.inputs:\n            iport=i\n\n        if 'metadata' in kwargs:\n            dep = self.apply_derivation_rule('write',True,oport=name,iport=iport,data=data,metadata=kwargs['metadata'])\n        else:\n            dep = self.apply_derivation_rule('write',True,oport=name,iport=iport,data=data)\n        \n        self.endTime = datetime.datetime.utcnow()\n\n       \n        \n        if 'dep' in kwargs and kwargs['dep']!=None: \n            for d in kwargs['dep']:\n                self.buildDerivation({'id':self.getProvStateObjectId(d),'TriggeredByProcessIterationID':self.iterationId, 'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n        elif len(self.stateDerivations) > 0:\n            for d in self.stateDerivations:\n                self.buildDerivation({'id':self.getProvStateObjectId(d),'TriggeredByProcessIterationID':self.iterationId, 'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n\n        if 'ignore_inputs' in kwargs:\n            self.ignore_inputs=kwargs['ignore_inputs']\n        \n       \n        \n        self.extractProvenance(data, output_port=name, **kwargs)\n\n        if 'dep' in kwargs and kwargs['dep']!=None:\n            for d in kwargs['dep']:\n                self.removeDerivation(name=d)\n        elif len(self.stateDerivations) > 0:\n            for d in self.stateDerivations:\n                self.removeDerivation(name=d)\n\n\n        self.stateDerivations=[]\n\n    def writeProvToFile(self, prov):\n        \n        if isinstance(prov, list) and \"data\" in prov[0]:\n            prov = prov[0][\"data\"]\n        \n         \n        #self.log('PROCESS: '+str(prov))\n        self.bulk_prov.append(prov)\n        \n        \n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\n            filep = open(\n                ProvenancePE.PROV_PATH +\n                \"\/bulk_\" +\n                self.makeProcessId(),\n                \"wr\")\n            #self.log('PROCESS: '+str(filep))\n            ujson.dump(self.bulk_prov, filep)\n            #filep.write(json.dumps(self.bulk_prov))\n            self.bulk_prov[:]=[]\n\n        return None\n\n    def writeResults(self, name, result):\n\n        #self.resetflow = True\n        self.apply_derivation_rule('write',True,data=result,oport=name)\n        self.void_invocation=False\n        \n        \n\n        if isinstance(result, dict) and '_d4p_prov' in result:\n            meta = result['_d4p_prov']\n            result = (result['_d4p_data'])\n\n            if 'error' in meta:\n                self.extractProvenance(result, output_port=name, **meta)\n            else:\n\n                self.extractProvenance(\n                    result, error=self.error, output_port=name, **meta)\n\n        else:\n            self.extractProvenance(result, error=self.error, output_port=name)\n\n","type":"(<class 'dispel4py.seismo.seismo.SeismoPE'>, <class 'dispel4py.provenance.ASTGrouped'>, <class 'test.misfit_processing.misfit_processing_prov.MatchComponents'>)","functionName":"MatchComponents"},"streamProducer0":{"code":"    def __computewrapper(self, inputs):\n\n        try:\n            result = None\n\n            self.__markIteration()\n\n            if self.impcls is not None and isinstance(self, self.impcls):\n                try:\n                    if hasattr(self, 'params'):\n                        self.parameters = self.params\n                    result = self._process(inputs[self.impcls.INPUT_NAME])\n                    if result is not None:\n                        self.writeResults(self.impcls.OUTPUT_NAME, result)\n                except:\n                    result = self._process(inputs)\n            else:\n                result = self._process(inputs)\n\n            if result is not None:\n                return result\n\n        except Exception:\n            self.log(\" Compute Error: %s\" % traceback.format_exc())\n            self.error += \" Compute Error: %s\" % traceback.format_exc()\n            # self.endTime = datetime.datetime.utcnow()\n            self.writeResults('error', {'error': 'null'})\n\n    def __getUniqueId(self):\n        return socket.gethostname() + \"-\" + str(os.getpid()) + \\\n            \"-\" + str(uuid.uuid1())\n\n    def __importInputMetadata(self):\n        try:\n            self.inMetaStreams = self.input[\"metadata\"][\"streams\"]\n        except Exception:\n            None\n\n    def __markIteration(self):\n        self.startTime = datetime.datetime.utcnow()\n        self.iterationId = self.name + '-' + self.makeProcessId()\n\n    def __processwrapper(self, data):\n        try:\n\n            self.initParameters()\n\n            self.inputs = self.importInputData(data)\n            # self.__importInputMetadata()\n            return self.__computewrapper(self.inputs)\n\n        except:\n            self.log(traceback.format_exc())\n\n    def __init__(self,*args,**kwargs):\n        ProvenancePE.__init__(self,*args,**kwargs)\n        self.addNamespacePrefix(\"seis\",\"http:\/\/seis-prov.eu\/ns\/#\")\n\n    def _add_input(self, name, grouping=None, tuple_type=None):\n        '''\n        Declares an input for this PE.\n        This method may be used when initialising a PE instead of modifying\n        :py:attr:`~dispel4py.core.GenericPE.inputconnections` directly.\n\n        :param name: name of the input\n        :param grouping: the grouping type that this input expects (optional)\n        :param tuple_type: type of tuples accepted by this input (optional)\n        '''\n        self.inputconnections[name] = {NAME: name}\n        if grouping:\n            self.inputconnections[name][GROUPING] = grouping\n        if tuple_type:\n            self.inputconnections[name][TYPE] = tuple_type\n\n    def _add_output(self, name, tuple_type=None):\n        '''\n        Declares an output for this PE.\n        This method may be used when initialising a PE instead of modifying\n        :py:attr:`~dispel4py.core.GenericPE.outputconnections` directly.\n\n        :param name: name of the output\n        :param tuple_type: type of tuples produced by this output (optional)\n        '''\n        self.outputconnections[name] = {NAME: name}\n        if tuple_type:\n            self.outputconnections[name][TYPE] = tuple_type\n\n    def _postprocess(self):\n        None\n\n    def _preprocess(self):\n        self.instanceId = self.name + \"-Instance-\" + \\\n            \"-\" + self.makeProcessId()\n\n        super(ProvenancePE, self)._preprocess()\n\n    def _process(self, inputs):\n        self.log(\"INPUT: \"+str(inputs[\"input\"][\"data\"]))\n        data =inputs[\"input\"][\"data\"]\n        synth = inputs[\"input\"][\"synthetics\"]\n        stationxml = os.environ['STAGED_DATA']+'\/'+inputs[\"input\"][\"stationxml\"]\n        quakeml = inputs[\"input\"][\"quakeml\"]\n       \n        parameters = inputs[\"input\"][\"parameters\"]\n        event_id= inputs[\"input\"][\"event_id\"]\n        misfit_type = parameters[\"misfit_type\"]\n        output_folder = os.environ['STAGED_DATA']+'\/'+inputs[\"input\"][\"output_folder\"]+'\/'+misfit_type+'\/'\n        if not os.path.exists(output_folder):\n            os.makedirs(output_folder)\n\n        # Write to different output channels depending on the chosen type of\n        # misfit.\n        \n        if misfit_type in [\"pyflex\", \"pyflex_and_time_frequency\"]:\n            output_channel = \"output_pyflex\"\n        elif misfit_type == \"time_frequency\":\n            output_channel = \"output_time_frequency\"\n        #else:\n        #    raise NotImplementedError(\n        #        \"'misfit_type' must be one of 'pyflex', \"\n        #        \"'pyflex_and_time_frequency', or 'time_frequency'\")\n\n        data_st = obspy.Stream()\n        for d in data:\n            data_st += obspy.read(os.environ['STAGED_DATA']+'\/'+d)\n\n        synth_st = obspy.Stream()\n        for s in synth:\n            synth_st += obspy.read(os.environ['STAGED_DATA']+'\/'+s)\n\n        # Get all available components.\n        components = set([tr.stats.channel[-1] for tr in\n                          (data_st + synth_st)])\n        \n        \n        \n        for comp in components:\n            \n            \n            dic = self.extractItemMetadata(data_st.select(component=comp),None)\n            raw_data={}\n            \n            if len(dic)>0:\n                for key in dic[0]:\n                   raw_data[key+'_raw']=dic[0][key]\n                        \n            else:\n                self.error=self.error+' Problem extracting raw data for comp '+str(comp)+'and station: '+str(data_st)\n                \n                \n            dic = self.extractItemMetadata(synth_st.select(component=comp),None)\n            syn_data={}\n            if len(dic)>0:\n                for key in dic[0]:\n                    syn_data[key+'_syn']=dic[0][key]\n                \n            else:\n                self.error=self.error+' Problem extracting synth data for comp '+str(comp)+'and station: '+str(synth_st)\n                \n            provmet={ \"misfit_type\": misfit_type,'event_id':event_id}\n            provmet.update(raw_data)\n            provmet.update(syn_data)\n            self.parameters=parameters\n            self.log('COMP: '+comp)\n            self.log('ST: '+str(synth_st))\n            self.write(\n                output_channel,\n                {\"data_trace\": data_st.select(component=comp)[0],\n                 \"synthetic_trace\": synth_st.select(component=comp)[0],\n                 \"stationxml\": stationxml,\n                 \"quakeml\": quakeml,\n                 \"output_folder\": output_folder,\n                 \"misfit_type\": misfit_type,\n                 'event_id':event_id,\n                 \"parameters\": parameters},metadata = provmet)\n\n    def _updateState(self,name,id):\n        if name in self.stateCollection:\n                self.stateCollectionId.remove(self.stateCollection[name])\n        self.stateCollection[name]=id\n        self.stateCollectionId.append(id)\n\n    def _write(self, name, data, **kwargs):\n        '''\n        This writes the 'data' to the output pipe with name 'name' of this PE.\n        '''\n         \n        try:\n            output = self.outputconnections[name]\n            output[WRITER].write(data)\n        except KeyError:\n            raise Exception(\"Can't write data: Unknown output connection\\\n                            '%s' for PE '%s'\" % (name, type(self).__name__))\n\n    def addNamespacePrefix(self,prefix,url):\n        self.ns.update({prefix:url})\n\n    def apply_derivation_rule(self,event,voidInvocation,oport=None,iport=None,data=None,metadata=None):\n        \n        if (event=='end_invocation_event') and voidInvocation==True:\n            self.discardInFlow(discardState=True)\n        \n        if (event=='end_invocation_event') and voidInvocation==False:\n            self.discardInFlow(discardState=True)\n\n    def buildDerivation(self, data, port=\"\"):\n        \n        if data!=None and 'id' in data:\n\n            derivation = {'port': port, \n                          'DerivedFromDatasetID': data['id'], \n                          'TriggeredByProcessIterationID': data['TriggeredByProcessIterationID'], \n                          'prov_cluster': data['prov_cluster'],\n                          'iterationIndex':self.iterationIndex,\n                          \n\n\n\n                          }\n                          \n            if port==\"_d4p_state\": \n                derivation.update({'lookupterm':data['lookupterm']})\n                 \n\t\t    \n            if \"up:assertionType\" in data:\n                derivation.update({\"up:assertionType\":data[\"up:assertionType\"]})\n\n\n\n            self.derivationIds.append(derivation)\n\n        else:\n            \n            id=self.extractDataSourceId(data,port)\n            #traceback.print_exc(file=sys.stderr)\n            derivation = {'port': port, 'DerivedFromDatasetID':\n                          id, 'TriggeredByProcessIterationID':\n                          None, 'prov_cluster':\n                          None,\n                          'iterationIndex':self.iterationIndex\n                          }\n            self.derivationIds.append(derivation)\n            self.log(\"BUILDING INITIAL DERIVATION\")\n\n    def buildUserMetadata(self, data, **kwargs):\n        streamlist = list()\n\n        streamItem = {}\n        streammeta = []\n        settransfer=False\n        streammeta = self.extractItemMetadata(data,kwargs['output_port'])\n        \n        if not isinstance(streammeta, list):\n            streammeta = kwargs['metadata'] if isinstance(\n                kwargs['metadata'], list) else [kwargs['metadata']]\n        elif isinstance(streammeta, list):\n            try:\n                if isinstance(kwargs['metadata'], list):\n                    streammeta = streammeta + kwargs['metadata']\n                if isinstance(kwargs['metadata'], dict):\n                    for y in streammeta:\n                        y.update(kwargs['metadata'])\n            except:\n                traceback.print_exc(file=sys.stderr)\n                None\n        \n        if self.sel_rules!=None:\n            self.provon=self.checkSelectiveRule(streammeta)\n\n       \n        if not self.provon:\n            return streamItem\n        #self.log(kwargs)\n        streamItem.update({\"content\": streammeta,\n                           \"id\": self.getUniqueId(data,kwargs['output_port'],**kwargs),\n                           \"format\": \"\",\n                           \"location\": \"\",\n                           \"annotations\": [],\n                           \"port\": kwargs['output_port']})\n        # if (self.streamItemsControl!={,:\n        streamItem.update(kwargs['control'])\n        # if (self.streamItemsLocations!={,:\n        streamItem.update({\"location\": kwargs['location'],\n                          \"format\": kwargs['format']})\n        streamItem.update({\"size\": total_size(data)})\n        #streamItem.update({\"size\": 0})\n\n        if self.transfer_rules!=None:\n            settransfer=self.checkTransferRule(streammeta)\n\n\n        if settransfer:\n            streamItem[\"s-prov:immediateAccess\"]=True\n            streamItem[\"s-prov:first-known-destination\"]=self.transfer_rules[\"destination\"]\n\n        \n        \n        streamlist.append(streamItem)\n        return streamlist\n\n    def checkSelectiveRule(self,streammeta):\n        self.log(\"Checking Skip-Rules: \"+str(self.sel_rules))\n        rules=self.sel_rules[\"rules\"]\n\n        for key in rules:\n\n                for s in streammeta:\n                    if key in s: \n                        #self.log(\"A\"+str(self.sel_rules[key]))\n                        self.log(s[key]) \n                        self.log(type(s[key]))\n                         \n                        if '$eq' in rules[key] and s[key]==rules[key]['$eq']:\n                            return True\n                        elif '$gt' in rules[key] and '$lt' in rules[key]:\n                            if (s[key]>rules[key]['$gt'] and s[key]<rules[key]['$lt']):\n                                self.log(\"GT-LT\") \n                                return True\n                            else:\n                                return False\n                        elif '$gt' in rules[key] and s[key]>rules[key]['$gt']:\n                            self.log(\"GT\") \n                            return True\n                        elif '$lt' in rules[key] and s[key]<rules[key]['$lt']:\n                            self.log(\"LT\") \n                            return True\n                        else:\n                            return False\n        return self.provon\n\n    def checkTransferRule(self,streammeta):\n        self.log(\"Checking Transfer-Rules\")\n        for key in self.transfer_rules[\"rules\"]:\n                for s in streammeta:\n                    if key in s: \n                        #self.log(\"A\"+str(self.sel_rules[key]))\n                        self.log(s[key]) \n                        self.log(type(s[key]))\n                        \n                        if '$eq' in self.transfer_rules[\"rules\"][key] and s[key]==self.transfer_rules[\"rules\"][key]['$eq']:\n                             \n                            return True\n                        elif '$gt' in self.transfer_rules[\"rules\"][key] and '$lt' in self.transfer_rules[\"rules\"][key]:\n                            if (s[key]>self.transfer_rules[\"rules\"][key]['$gt'] and s[key]<self.transfer_rules[\"rules\"][key]['$lt']):\n                                self.log(\"GT-LT\")\n                                 \n                                return True\n                        elif '$gt' in self.transfer_rules[\"rules\"][key] and s[key]>self.transfer_rules[\"rules\"][key]['$gt']:\n                            self.log(\"GT\") \n                            \n                            return True\n                        elif '$lt' in self.transfer_rules[\"rules\"][key] and s[key]<self.transfer_rules[\"rules\"][key]['$lt']:\n                            self.log(\"LT\")\n                            \n                            return True\n                        else:\n                            return False\n        return False\n\n    def dicToKeyVal(self, dict, valueToString=False):\n        try:\n            alist = list()\n            for k, v in dict.iteritems():\n                adic = {}\n                adic.update({\"key\": str(k)})\n                if valueToString:\n                    adic.update({\"val\": str(v)})\n                else:\n\n                    try:\n                        v = num(v)\n                        adic.update({\"val\": v})\n                    except Exception:\n                        adic.update({\"val\": str(v)})\n\n                alist.append(adic)\n\n            return alist\n        except Exception as err:\n\n            self.error += self.name + \" dicToKeyVal output Error: \" + str(err)\n            sys.stderr.write(\n                'ERROR: ' +\n                self.name +\n                ' dicToKeyVal output Error: ' +\n                str(err))\n#                self.map.put(\"output\",\"\");\n            traceback.print_exc(file=sys.stderr)\n\n    def discardInFlow(self,wlength=None,discardState=False): \n        #self.log('BEFORE '+str(self.derivationIds))\n        \n        \n        if discardState==True:\n            if wlength==None:\n            #self.log(\"discarding\")\n                self.derivationIds=[]\n            else:\n                count=0\n                for x in self.derivationIds:\n                    if x!=None and x['port']!='_d4p_state' and count>=wlength-1:\n                        self.derivationIds.remove(x)\n                    count+=1\n                for x in self.derivationIds:\n                    if x!=None and x['port']=='_d4p_state':\n                        self.derivationIds.remove(x)\n                        \n\n\n\n        else:\n            maxit=0\n            state=None\n            #self.log(\"BEFORE\" +str(self.derivationIds))\n            for x in self.derivationIds:\n                 \n                if x!=None and x['port']=='_d4p_state' and x['iterationIndex']>=maxit:\n                    \n                    state=x\n                    maxit=x['iterationIndex']\n            \n            if wlength==None:\n                if state!=None:   \n                    self.derivationIds=[state]\n                else:\n                    self.derivationIds=[]\n            else:\n                count=0\n                for x in self.derivationIds:\n                    #self.log(\"COUNT: \"+str(count)+\" WLENTGH: \"+str(wlength))\n                    if x!=None and x['port']!='_d4p_state' and count>=wlength-1:\n                        #self.log(\"REMOVE: \"+str(x['iterationIndex']))\n                        del self.derivationIds[0]   \n                    count+=1\n\n               \n\n                if state!=None: \n                    self.derivationIds.append(state)\n\n    def discardState(self): \n        #self.log('BEFORE '+str(self.derivationIds))\n        \n        \n        derivations = [x for x in self.derivationIds if x['port']!='_d4p_state']\n        \n        self.derivationIds=derivations\n\n    def extractDataSourceId(self,data,port):\n        self.makeUniqueId(data,port)\n\n    def extractItemMetadata(self,data,port):\n        try:\n               \n            st=[]\n             \n            if type(data) == Trace:\n                st.append(data)\n                \n            elif type(data)==tuple:\n                for x in data:\n                    if type(x)==Stream:\n                        st=x\n            else:\n                st=data\n            streammeta=list()\n            for tr in st:\n                \n                metadic={}\n                metadic.update({\"prov:type\":\"waveform\"});    \n                metadic.update({\"id\":str(uuid.uuid1())});\n                \n                for attr, value in tr.stats.__dict__.iteritems():\n                    \n                    if attr==\"mseed\":\n                        mseed={}\n                        for a,v in value.__dict__.iteritems():\n                            try:\n                                if type(v)==UTCDateTime:\n                                    mseed.update({a:str(v)});\n                                else:\n                                    mseed.update({a:float(v)});\n                            except Exception,e:\n                                mseed.update({a:str(v)});\n                        metadic.update({\"mseed\":mseed});\n                    else:\n                        try:\n                            if type(value)==UTCDateTime:\n                                metadic.update({attr:str(value)});\n                            else:\n                                metadic.update({attr:float(value)});\n                        except Exception,e:\n                            metadic.update({attr:str(value)});\n                \n                streammeta.append(metadic);\n            \n            return streammeta   \n        except Exception, err:\n            self.log(\"Applying default metadata extraction\")\n            #self.error=self.error+\"Extract Metadata error: \"+str(traceback.format_exc())\n            return super(SeismoPE, self).extractItemMetadata(data,port);\n\n    def extractProvenance(\n            self,\n            data,\n            location=\"\",\n            format=\"\",\n            metadata={},\n            control={},\n            attributes={},\n            error=\"\",\n            output_port=\"\",\n            **kwargs):\n\n        self.error = error\n\n        if metadata==None:\n            metadata={}\n        elif isinstance(metadata, list):\n            metadata.append(attributes)\n        else:\n            metadata.update(attributes)\n\n        usermeta = {}\n\n        if 's-prov:skip' in control and bool(control['s-prov:skip']):\n            self.provon = False\n        else:\n            self.provon = True\n            usermeta= self.buildUserMetadata(\n                data,\n                location=location,\n                format=format,\n                metadata=metadata,\n                control=control,\n                attributes=attributes,\n                error=error,\n                output_port=output_port,\n                **kwargs)\n        \n         \n        \n        self.flushData(data, usermeta, output_port,**kwargs)\n\n        return usermeta\n\n    def flushData(self, data, metadata, port,**kwargs):\n        trace = {}\n        stream = data\n        try:\n            if self.provon:\n                self.endTime = datetime.datetime.utcnow()\n                trace = self.packageAll(metadata)\n            \n            stream = self.prepareOutputStream(data, trace, port,**kwargs)\n              \n            try:\n                if port is not None and port != '_d4p_state' \\\n                        and port != 'error':\n\n                    super(ProvenancePE, self).write(port, stream)\n#stream)\n\n            except:\n                self.log(traceback.format_exc())\n                'if cant write doesnt matter move on'\n                pass\n            try:\n                if self.provon:\n                    if (ProvenancePE.send_prov_to_sensor==True) or (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\n\n                            self.sendProvToSensor(trace['metadata'])\n                            \n                            \n                            #super(\n                            #      ProvenancePE,\n                            #      self).write(\n                            #                  OUTPUT_METADATA,\n                            #                  deepcopy(trace['metadata']))\n                            \n\n                    if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n                        \n                        self.sendProvToService(trace['metadata'])\n                    if self.save_mode==ProvenancePE.SAVE_MODE_FILE:\n                         self.writeProvToFile(trace['metadata'])\n                     \n            except:\n                self.log(traceback.format_exc())\n                'if cant write doesnt matter move on'\n                pass\n\n            return True\n\n        except Exception:\n            self.log(traceback.format_exc())\n            if self.provon:\n                self.error += \" FlushChunk Error: %s\" % traceback.format_exc()\n\n    def getDataStreams(self, inputs):\n        streams = {}\n        for inp in self.inputconnections:\n            if inp not in inputs:\n                continue\n            values = inputs[inp]\n            if isinstance(values, list):\n                data = values[0:]\n            else:\n                data = values\n            streams[\"streams\"].update({inp: data})\n        return streams\n\n    def getInputAt(self, port=\"input\", index=None):\n        if index==None:\n            return self.inputs[port]\n        else:\n            return self.inputs[port][index]\n\n    def getOutputTypes(self):\n        '''\n        Returns the output types of this PE, in the form of a dictionary.\n        This method may be overridden if output types are not static and\n        depend on input types.\n\n        .. note::\n\n            This method is only called after the input types have been\n            initialised in :py:func:`~dispel4py.core.GenericPE.setInputTypes`.\n\n        :rtype: a dictionary mapping each output name to its type\n\n        By default it returns a dictionary of the types defined in the\n        'outputconnections' instance variable.\n\n        Usage example::\n\n            def getOutputTypes(self):\n                output = { 'output1' : myInputs['input1'],\n                           'output2' : [ 'comment' ] }\n\n        '''\n        ret = {}\n        # print '%s: %s' % (self.id, self.outputconnections)\n        for name, output in self.outputconnections.items():\n            try:\n                ret[name] = output[TYPE]\n            except KeyError:\n                raise Exception(\"%s: No output type defined for '%s'\"\n                                % (self.id, name))\n        return ret\n\n    def getProvStateObjectId(self,name):\n        if name in self.stateCollection:\n            return self.stateCollection[name]\n        else:\n            return None\n\n    def getUniqueId(self,data,port,**kwargs):\n        data_id = self.makeUniqueId(data,port)\n        if 'name' in kwargs:\n            self._updateState(kwargs['name'],data_id)\n\n\n\n        return data_id\n\n    def ignorePastFlow(self):\n        self.ignore_past_flow=True\n\n    def ignoreState(self):\n        self.ignore_state=True\n\n    def importInputData(self, data):\n\n        inputs = {}\n\n        try:\n            if not isinstance(data, collections.Iterable):\n                return data\n            else:\n                for x in data:\n                    #self.log(data[x])\n                    self.buildDerivation(data[x], port=x)\n                    if type(data[x])==dict and '_d4p' in data[x]:\n                        inputs[x] = data[x]['_d4p']\n                    else:\n                        inputs[x] = data[x]\n                return inputs\n\n        except Exception:\n            self.output = \"\"\n            self.error += \"Reading Input Error: %s\" % traceback.format_exc()\n            raise\n\n    def initParameters(self):\n\n        self.error = ''\n        self.w3c_prov = {}\n        #self.resetflow = True\n        self.inMetaStreams = None\n        self.username = None\n        self.runId = None\n\n\n        try:\n                # self.iterationId = self.name + '-' + getUniqueId()\n            if \"username\" in self.controlParameters:\n                self.username = self.controlParameters[\"username\"]\n            if \"runId\" in self.controlParameters:\n                self.runId = self.controlParameters[\"runId\"]\n\n        except:\n                self.runId = \"\"\n                pass\n\n        self.outputdest = self.controlParameters[\n            'outputdest'] if 'outputdest' in self.controlParameters else 'None'\n        self.rootpath = self.controlParameters[\n            'inputrootpath'] \\\n            if 'inputrootpath' in self.controlParameters else 'None'\n        self.outputid = self.controlParameters[\n            'outputid'] \\\n            if 'outputid' in self.controlParameters else 'None'\n\n    def makeProcessId(self, **kwargs):\n        \n        return socket.gethostname() + \"-\" + \\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\n\n    def makeUniqueId(self,data,port):\n        #if ('data' in kwargs):\n        #    self.log(str(kwargs['data']))\n        \n        return socket.gethostname() + \"-\" + \\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\n\n    def packageAll (self, contentmeta):\n        metadata = {}\n        if self.provon:\n            try:\n\n                # identifies the actual iteration over the instance\n                metadata.update({'iterationId': self.iterationId,\n                # identifies the actual writing process'\n                'actedOnBehalfOf': self.behalfOf,\n                '_id': self.id + '_write_' + str(self.makeProcessId()),\n                'iterationIndex': self.iterationIndex,\n                'instanceId': self.instanceId,\n                'annotations': {}})\n\n                if self.feedbackIteration:\n                    metadata.update(\n                        {'_id': self.id + '_feedback_' + str(self.makeProcessId())})\n                elif self.stateful:\n                    metadata.update(\n                        {'_id': self.id + '_stateful_' + str(self.makeProcessId())})\n\n                else:\n                    metadata.update(\n                        {'_id': self.id + '_write_' + str(self.makeProcessId())})\n\n\n                metadata.update({'stateful': not self.resetflow,\n                'feedbackIteration': self.feedbackIteration,\n                'worker': socket.gethostname(),\n                'parameters': self.parameters,\n                'errors': self.error,\n                'pid': '%s' % os.getpid()})\n\n\n                 \n                if self.ignore_inputs==True:\n                    derivations = [x for x in self.derivationIds if x['port']=='_d4p_state' and x['DerivedFromDatasetID'] in self.stateCollectionId]\n                    metadata.update({'derivationIds': derivations})\n                    self.ignore_inputs = False\n                    \n                elif self.ignore_past_flow==True:\n                     \n                    derivations = [x for x in self.derivationIds if (x['iterationIndex'] == self.iterationIndex or x['port']=='_d4p_state')]\n                    metadata.update({'derivationIds': derivations})\n                    #self.log(\"IGNOREPAST \"+str(derivations))\n\n                elif self.ignore_state==True:\n                    \n                    derivations = [x for x in self.derivationIds if x['port']!='_d4p_state']\n                    metadata.update({'derivationIds': derivations})\n                    #self.log(\"In package \"+str(self.derivationIds))\n                    #self.ignore_past_flow = False\n                else:\n                     \n                    metadata.update({'derivationIds': self.derivationIds})\n                    self.ignore_past_flow = False\n\n\n                metadata.update({'name': self.name,\n                'runId': self.runId,\n                'username': self.username,\n                'startTime': str(self.startTime),\n                'endTime': str(self.endTime),\n                'type': 'lineage',\n\n                'streams': contentmeta,\n                'mapping': sys.argv[1]})\n                \n                if hasattr(self, 'prov_cluster'):\n                     \n                    metadata.update({'prov_cluster': self.prov_cluster})\n                \n\n                if self.creator is not None:\n                    metadata.update({'creator': self.creator})\n            except Exception:\n                self.error += \" Packaging Error: %s\" % traceback.format_exc()\n                self.log(traceback.format_exc())\n\n        output = {\n            \"metadata\": metadata,\n            \"error\": self.error,\n            #\"pid\": \"%s\" %\n            #os.getpid()\n             }\n\n\n        return output\n\n    def pe_init(self, *args, **kwargs):\n        #ProvenancePE.__init__(self,*args, **kwargs)\n\n        global _d4p_plan_sqn\n        self._add_input('_d4py_feedback', grouping='all')\n        self.stateCollection={}\n        self.stateCollectionId=[]\n        self.impcls = None\n        self.bulk_prov = []\n        self.stateful=False\n        self.stateDerivations=[]\n\n\n        if 'pe_class' in kwargs and kwargs['pe_class'] != GenericPE:\n            self.impcls = kwargs['pe_class']\n       \n        if 'sel_rules' in kwargs and self.name in kwargs['sel_rules']:\n            print(self.name+\" \"+str(kwargs['sel_rules'][self.name]))\n            self.sel_rules = kwargs['sel_rules'][self.name]\n        else:\n            self.sel_rules=None\n        \n        if 'transfer_rules' in kwargs and self.name in kwargs['transfer_rules']:\n            print(self.name+\" \"+str(kwargs['transfer_rules'][self.name]))\n            self.transfer_rules = kwargs['transfer_rules'][self.name]\n        else:\n            self.transfer_rules=None\n\n\n        if 'creator' not in kwargs:\n            self.creator = None\n        else:\n            self.creator = kwargs['creator']\n\n        self.error = ''\n\n        if not hasattr(self, 'parameters'):\n            self.parameters = {}\n        if not hasattr(self, 'controlParameters'):\n            self.controlParameters = {}\n\n        if 'controlParameters' in kwargs:\n            self.controlParameters = kwargs['controlParameters']\n\n        out_md = {}\n        out_md[NAME] = OUTPUT_METADATA\n\n        # self.outputconnections[OUTPUT_DATA] = out1\n        #print(OUTPUT_METADATA)\n        self._add_output(OUTPUT_METADATA)\n        ##self.outputconnections[OUTPUT_METADATA] = out_md\n        self.taskId = str(uuid.uuid1())\n\n        # self.appParameters = None\n        self.provon = True\n        \n\n        if 'save_mode' not in kwargs:\n            self.save_mode=ProvenancePE.SAVE_MODE_FILE\n        else:\n            self.save_mode=SAVE_MODE_FILE = kwargs['save_mode']\n\n        self.wcount=0\n        self.resetflow = False\n        self.stateUpdateIndex=0\n        self.ignore_inputs = False\n        self.ignore_state=False\n        self.ignore_past_flow = False\n        self.derivationIds = list()\n        self.iterationIndex = 0\n        \n        #name + '_' + str(_d4p_plan_sqn)\n        _d4p_plan_sqn = _d4p_plan_sqn + 1\n        self.countstatewrite=0\n        if not hasattr(self, 'comp_id'):\n            self.behalfOf=self.id\n        else:\n            self.behalfOf=self.comp_id\n        if not hasattr(self, 'prov_cluster'):\n            self.prov_cluster=self.behalfOf\n\n    def postprocess(self):\n\n        \n        if len(self.bulk_prov)>0:\n            \n            if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n                #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\n                params = urllib.urlencode({'prov': ujson.dumps(self.bulk_prov)})\n                headers = {\n                       \"Content-type\": \"application\/x-www-form-urlencoded\",\n                       \"Accept\": \"application\/json\"}\n                self.connection = httplib.HTTPConnection(\n                                                     self.provurl.netloc)\n                self.connection.request(\n                                    \"POST\",\n                                    self.provurl.path,\n                                    params,\n                                    headers)\n                response = self.connection.getresponse()\n                self.log(\"Postprocess: \" +\n                     str((response.status, response.reason, response.read())))\n#                    response.read())))\n                self.connection.close()\n                self.bulk_prov[:]=[]\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_FILE):\n                filep = open(ProvenancePE.PROV_PATH + \"\/bulk_\" + self.makeProcessId(), \"wr\")\n                ujson.dump(self.bulk_prov, filep)\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\n                super(\n                                  ProvenancePE,\n                                  self).write(\n                                              OUTPUT_METADATA,\n                                              {'prov_cluster':self.prov_cluster,'provenance':deepcopy(self.bulk_prov)})\n            #self.bulk_prov[:]=[]\n\n        self._postprocess()\n\n    def prepareOutputStream(self, data, trace,port,**kwargs):\n        try:\n            streamtransfer = {}\n            streamtransfer['_d4p'] = data\n            #self.log(\"PROVON: \"+str(self.provon))\n            \n            try:\n\n\n                streamtransfer[\"prov_cluster\"] = self.prov_cluster\n                streamtransfer[\"port\"] = port\n                \n\n                if self.provon:\n                    \n                    #self.log(\"lnking Component trace\")\n                    streamtransfer['id'] = trace[\n                        'metadata'][\"streams\"][0][\"id\"]\n                    streamtransfer[\n                        \"TriggeredByProcessIterationID\"] = self.iterationId\n                    \n                    if port=='_d4p_state':\n                        #self.log(''' Building SELF Derivation '''+str(trace))\n                        self._updateState(kwargs['lookupterm'],trace[\n                        'metadata'][\"streams\"][0]['id'])\n                        streamtransfer['lookupterm']=kwargs['lookupterm']\n                        self.buildDerivation(streamtransfer,port='_d4p_state')\n                        \n                else:\n                    \n                    #self.log(\"Skip Component trace\")\n                    streamtransfer[\"id\"] = self.derivationIds[0][\"DerivedFromDatasetID\"]\n                    streamtransfer[\"TriggeredByProcessIterationID\"] = self.derivationIds[0][\"TriggeredByProcessIterationID\"]\n                    streamtransfer[\"up:assertionType\"] = \"up:Incomplete\"\n                    #self.log(streamtransfer)\n                    \n            except:\n                #self.log(traceback.format_exc())\n                pass\n            return streamtransfer\n\n        except Exception:\n            self.error += self.name + \" Writing output Error: %s\" % \\\n                traceback.format_exc()\n            raise\n\n    def preprocess(self):\n        if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\n            self.provurl = urlparse(ProvenancePE.REPOS_URL)\n            #self.connection = httplib.HTTPConnection(\n            #                                         self.provurl.netloc)\n        self._preprocess()\n\n    def process(self, inputs):\n        self.feedbackIteration = False\n        self.void_invocation = True\n        self.iterationIndex += 1\n\n         \n        \n\n        if '_d4py_feedback' in inputs:\n\n            'state could be used here to track the occurring changes'\n            self.process_feedback(inputs['_d4py_feedback'])\n        else:\n            self.__processwrapper(inputs)\n\n        for x in inputs:\n            data=inputs[x]\n            if type(data)==dict and '_d4p' in data:\n                self.apply_derivation_rule('end_invocation_event',self.void_invocation,iport=x,data=data['_d4p'])   \n            else:\n                self.apply_derivation_rule('end_invocation_event',self.void_invocation,iport=x,data=data)  \n\n    def process_feedback(self, feedback):\n        self.feedbackIteration = True\n        self._process_feedback(feedback)\n\n    def removeDerivation(self,**kwargs):\n        if 'name' in kwargs:\n            id = self.getProvStateObjectId(kwargs['name'])\n            for j in self.derivationIds:\n\n                if j['DerivedFromDatasetID']==id:\n\n                    del self.derivationIds[self.derivationIds.index(j)]\n        else:\n            if 'port' in kwargs:\n                for j in self.derivationIds:\n\n                    if j['port']==kwargs['port']:\n\n                        del self.derivationIds[self.derivationIds.index(j)]\n\n    def sendProvToSensor(self, prov):\n        \n\n        self.bulk_prov.append(deepcopy(prov))\n\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\n            super(\n                                  ProvenancePE,\n                                  self).write(\n                                              OUTPUT_METADATA,\n                                              {'prov_cluster':self.prov_cluster,'provenance':deepcopy(self.bulk_prov)})\n\n             \n            self.bulk_prov[:]=[]\n\n        return None\n\n    def sendProvToService(self, prov):\n\n        #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\n\n        if isinstance(prov, list) and \"data\" in prov[0]:\n            prov = prov[0][\"data\"]\n\n        self.bulk_prov.append(deepcopy(prov))\n        \n        if len(self.bulk_prov) > ProvenancePE.BULK_SIZE:\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\n            params = urllib.urlencode({'prov': ujson.dumps(self.bulk_prov)})\n            headers = {\n                \"Content-type\": \"application\/x-www-form-urlencoded\",\n                \"Accept\": \"application\/json\"}\n            self.connection = httplib.HTTPConnection(\n                                                     self.provurl.netloc)\n            self.connection.request(\n                \"POST\", self.provurl.path, params, headers)\n            response = self.connection.getresponse()\n            #self.log(\"progress: \" + str((response.status, response.reason,response.read())))\n            #                             response, response.read())))\n\n            self.bulk_prov[:]=[]\n\n        return None\n\n    def setInputTypes(self, types):\n        '''\n        Sets the input types of this PE, in the form of a dictionary.\n        It is meant to be overridden, e.g. if output types depend on input.\n\n        .. note::\n\n            This method is always called before\n            :py:func:`~dispel4py.core.GenericPE.getOutputTypes`.\n\n        :param types: object types for each input stream\n        :type types: dictionary mapping input name to input type\n\n        Usage example::\n\n            pe.setInputTypes({'input1':['t1', 't2', 't3'], \\\n                              'input2':['t4', 't5']})\n        '''\n        pass\n\n    def setStateDerivations(self,terms):\n        self.stateDerivations=terms\n\n    def update_prov_state(\n            self,\n            lookupterm,\n            data,\n            location=\"\",\n            format=\"\",\n            metadata={},\n            ignore_inputs=False,\n            ignore_state=True,\n            stateless=False,\n            **kwargs\n    ):\n\n        self.endTime = datetime.datetime.utcnow()\n        self.stateful = True\n        self.ignore_inputs = ignore_inputs\n        self.ignore_state = ignore_state\n        self.addprov=True\n        kwargs['lookupterm']=lookupterm\n        #self.apply_derivation_rule('state', None)\n        if self.provon:\n            if data == None:\n                    self._updateState(lookupterm,self.derivationIds[len(self.derivationIds)-1][\"DerivedFromDatasetID\"])\n\n            else:\n                \n                if 'dep' in kwargs and kwargs['dep']!=None:\n                #self.removeDerivation(port='_d4p_state')\n                \n                    for d in kwargs['dep']:\n                        did=self.getProvStateObjectId(d)\n                    \n                        if did!=None:\n                            self.buildDerivation({'id':did,'TriggeredByProcessIterationID':self.iterationId,'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n                        #self.ignore_state = False\n                        #self.log(\"DERI \"+str(did))\n                        #self.log(\"DERI2 \"+str(self.derivationIds))\n                        #\n\n            \n                self.extractProvenance(data,\n                               location,\n                               format,\n                               metadata,\n                               output_port=\"_d4p_state\",\n                               **kwargs)\n\n         \n\n\n        self.ignore_inputs = False\n        self.ignore_state = False\n\n\n\n        if 'dep' in kwargs and kwargs['dep']!=None:\n            for d in kwargs['dep']:\n                self.removeDerivation(name=d)\n        \n\n        self.stateful  = False\n\n    def write(self, name, data, **kwargs):\n        self.void_invocation=False\n        dep = []\n\n        iport=None\n\n        for i in self.inputs:\n            iport=i\n\n        if 'metadata' in kwargs:\n            dep = self.apply_derivation_rule('write',True,oport=name,iport=iport,data=data,metadata=kwargs['metadata'])\n        else:\n            dep = self.apply_derivation_rule('write',True,oport=name,iport=iport,data=data)\n        \n        self.endTime = datetime.datetime.utcnow()\n\n       \n        \n        if 'dep' in kwargs and kwargs['dep']!=None: \n            for d in kwargs['dep']:\n                self.buildDerivation({'id':self.getProvStateObjectId(d),'TriggeredByProcessIterationID':self.iterationId, 'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n        elif len(self.stateDerivations) > 0:\n            for d in self.stateDerivations:\n                self.buildDerivation({'id':self.getProvStateObjectId(d),'TriggeredByProcessIterationID':self.iterationId, 'prov_cluster':self.prov_cluster, 'lookupterm':d}, port=\"_d4p_state\")\n\n        if 'ignore_inputs' in kwargs:\n            self.ignore_inputs=kwargs['ignore_inputs']\n        \n       \n        \n        self.extractProvenance(data, output_port=name, **kwargs)\n\n        if 'dep' in kwargs and kwargs['dep']!=None:\n            for d in kwargs['dep']:\n                self.removeDerivation(name=d)\n        elif len(self.stateDerivations) > 0:\n            for d in self.stateDerivations:\n                self.removeDerivation(name=d)\n\n\n        self.stateDerivations=[]\n\n    def writeProvToFile(self, prov):\n        \n        if isinstance(prov, list) and \"data\" in prov[0]:\n            prov = prov[0][\"data\"]\n        \n         \n        #self.log('PROCESS: '+str(prov))\n        self.bulk_prov.append(prov)\n        \n        \n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\n            filep = open(\n                ProvenancePE.PROV_PATH +\n                \"\/bulk_\" +\n                self.makeProcessId(),\n                \"wr\")\n            #self.log('PROCESS: '+str(filep))\n            ujson.dump(self.bulk_prov, filep)\n            #filep.write(json.dumps(self.bulk_prov))\n            self.bulk_prov[:]=[]\n\n        return None\n\n    def writeResults(self, name, result):\n\n        #self.resetflow = True\n        self.apply_derivation_rule('write',True,data=result,oport=name)\n        self.void_invocation=False\n        \n        \n\n        if isinstance(result, dict) and '_d4p_prov' in result:\n            meta = result['_d4p_prov']\n            result = (result['_d4p_data'])\n\n            if 'error' in meta:\n                self.extractProvenance(result, output_port=name, **meta)\n            else:\n\n                self.extractProvenance(\n                    result, error=self.error, output_port=name, **meta)\n\n        else:\n            self.extractProvenance(result, error=self.error, output_port=name)\n\n","type":"(<class 'dispel4py.seismo.seismo.SeismoPE'>, <class 'test.misfit_processing.misfit_processing_prov.StreamProducer'>)","functionName":"streamProducer"}},"system_id":"xxxx","runId":"MISFIT_VERCE_orfeus-as-90123-b86d5f73-7f97-11e8-aa71-f45c89acf865","startTime":"2018-07-04 14:37:04.811675","input":[{"test":"1","blah":"3"}],"ns":{"seis":"http:\/\/seis-prov.eu\/ns\/#"},"type":"workflow_run","workflowName":"misfit"}]